{"meta":{"title":"Lee's Blog","subtitle":"","description":"","author":"unknown","url":"http://ctrl98.github.io","root":"/"},"pages":[{"title":"about","date":"2020-02-25T04:54:31.018Z","updated":"2020-02-25T04:54:31.018Z","comments":true,"path":"about/index.html","permalink":"http://ctrl98.github.io/about/index.html","excerpt":"","text":""},{"title":"All categories","date":"2020-02-25T04:47:45.380Z","updated":"2020-02-25T04:47:45.380Z","comments":true,"path":"categories/index.html","permalink":"http://ctrl98.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-25T04:55:08.804Z","updated":"2020-02-25T04:55:08.804Z","comments":true,"path":"tags/index.html","permalink":"http://ctrl98.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring Cloud Netflix核心组件介绍及搭建","slug":"SpringBoot-Netflix1","date":"2020-03-08T08:08:24.000Z","updated":"2020-03-08T08:11:58.120Z","comments":true,"path":"2020/03/08/SpringBoot-Netflix1/","link":"","permalink":"http://ctrl98.github.io/2020/03/08/SpringBoot-Netflix1/","excerpt":"","text":"单体应用存在的问题(耦合度过高) 随着业务的发展，开发变得越来越复杂。 修改，新增某个功能，需要对整个系统进行测试，重新部署。 一个模块出现了问题，很可能导致整个系统崩溃。 多个开发团队同时对数据进行管理，容易发生安全漏洞。 各个模块使用同一种技术开发，各个模块很难根据实际情况选择更合适的技术架构，局限性大。 模块内容过于复杂，如果员工离职，可能需要很长时间才能完成工作交接。 分布式、集群 集群：一台服务器无法负荷高并发的数据访问，那么就设置多几台服务器一起分担压力。(物理、运维层面) 分布式：将一个复杂的问题拆分成若干个小问题，将一个大型的项目架构拆分成若干个微服务来协同完成。(软件设计、开发层面)，分别有不同的人来完成每一个微服务，最终将所有服务进行整合。 Spring Cloud Netflix核心组件 服务治理 Eureka 负载均衡 Ribbon 负载均衡 Feign 服务网关 Zuul 服务跟踪 Zipkin 服务监控 Actuator 服务配置 Config 服务熔断 Hystrix Spring Cloud Eureka 简介：Eureka是 Netflix 开源的基于REST的服务治理解决方案，Spring Cloud 集成了Eureka，提供了服务注册和 服务发现的功能，可以和基于Spring Boot 搭建的微服务应用轻松整合，开箱即用，二次封装形成Spring Cloud Eureka Eureka server：注册中心 Eureka Client：服务提供者、服务消费者，所有要进⾏注册的微服务通过 Eureka Client 连接到 Eureka Server，完成注册。 如何去理解这三者之间的关系：比如说一个外卖订餐平台，商家需要在这个平台注册了才能提供服务，客户需要注册账号才能在商家提供的外卖服务进行下单销费。 分布式系统架构中，每个微服务在启动时，将自己的信息存储在注册中心，叫做服务注册。 服务消费者从注册中心获取服务提供者的网络信息，通过该信息调用服务，叫做服务发现。 Eureka Server代码实现 第一步创建一个maven父工程 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 解决 JDK 9 以上没有 JAXB API 的问题 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt; &lt;version&gt;2.3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步在父工程下创建maven子工程—eureka server pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第三步在module—eureka server创建配置文件 application.yml ，添加eureka server相关配置。 12345678server: port: 8071eureka: client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://localhost:8071/eureka/ 属性说明： server.port：当前eureka的服务端口 eureka.client.register-with-eureka：是否将当前的eureka server服务作为客户端进行注册 eureka.client.fetch-registry：是否获取其他eureka server服务的数据 eureka.client.service-url.defaultZone：注册中心访问地址 第四步在eureka server模块创建启动类 12345678910111213package eureka.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class,args); &#125;&#125; ​ 注解说明 @SpringBootApplication：声明Spring Boot入口程序 @EnableEurekaServer：声明该类是一个Eureka Server 微服务，提供服务注册和服务发现功能，即注册中心 到这里可以访问：http://localhost:8071/eureka 来查看注册中心的微服务信息 Eureka Client 代码实现 在父工程的基础上创建Module—eureka client 在pom.xml文件添加： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Module—eureka client创建配置⽂件 application.yml，添加 Eureka Client 相关配置 1234567891011server: port: 8010spring: application: name: serverProvidereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性说明： spring.application.name：当前服务注册在 Eureka Server 上的名称 eureka.instance.prefer-ip-address：是否将当前服务的 IP 注册到 Eureka Server 创建启动类---------ServerProviderApplication.java 123456@SpringBootApplicationpublic class ServerProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServerProviderApplication.class,args); &#125;&#125; 下面在Module—eureka client模块下实现简单业务测试 在Module—eureka client模块下创建实体类 12345678910111213141516package eurekaclient.lee.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private Integer id; private String name; private Integer age;&#125; 创建业务接口类 1234567891011package eurekaclient.lee.repository;import eurekaclient.lee.entity.Student;import java.util.Collection;public interface StudentRepository &#123; public Collection&lt;Student&gt; findAll(); public Student findById(Integer id); public void saveOrUpdate(Student student); public void deleteById(Integer id);&#125; 创建业务接口实现类 123456789101112131415161718192021222324252627282930313233343536373839404142package eurekaclient.lee.repository.Impl;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.stereotype.Repository;import java.util.Collection;import java.util.HashMap;import java.util.Map;@Repositorypublic class StudentRepositoryImpl implements StudentRepository &#123; private static Map&lt;Integer,Student&gt; studentMap; static &#123; studentMap = new HashMap&lt;&gt;(); studentMap.put(1,new Student(1,\"张三\",22)); studentMap.put(2,new Student(2,\"李四\",23)); studentMap.put(3,new Student(3,\"王五\",34)); &#125; @Override public Collection&lt;Student&gt; findAll() &#123; return studentMap.values(); &#125; @Override public Student findById(Integer id) &#123; return studentMap.get(id); &#125; @Override public void saveOrUpdate(Student student) &#123; studentMap.put(student.getId(),student); &#125; @Override public void deleteById(Integer id) &#123; studentMap.remove(id); &#125;&#125; 创建控制类 123456789101112131415161718192021222324252627282930313233343536373839404142package eurekaclient.lee.controller;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentController &#123; @Autowired private StudentRepository repository; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return repository.findAll(); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return repository.findById(id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @PutMapping(\"/update\") public void update(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; repository.deleteById(id); &#125;&#125; 到这里可以访问： http://localhost:8010/student/findAll 等接口访问数据进行测试，此时该服务已经注册在服务注册中心 RestTemplate的使用 什么是RestTemplate RestTemplate 是 Spring 框架提供的基于 REST 的服务组件，底层是对 HTTP 请求及响应进⾏了封装， 提供了很多访问 RETS 服务的⽅法，可以简化代码开发。 如何使⽤ RestTemplate？ 在父工程创建maven工程(new Module)—resttemplate，在其pom.xml中不需要添加额外依赖，因为父工程中已有springboot的依赖，所以其子工程(Module)自然也是一个springboot工程。 创建实体类 12345678910111213141516package resttemplate.lee.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private Integer id; private String name; private Integer age;&#125; 创建controller 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package resttemplate.lee.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import resttemplate.lee.entity.Student;import java.util.Collection;@org.springframework.web.bind.annotation.RestController@RequestMapping(\"/rest\")public class RestController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); &#125; @GetMapping(\"/findAllSec\") public Collection&lt;Student&gt; findAllSec()&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id).getBody(); &#125; @GetMapping(\"/findByIdSec/&#123;id&#125;\") public Student findByIdSec(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); &#125; @PutMapping(\"update\") public void update(@RequestBody Student student)&#123; restTemplate.put(\"http://localhost:8010/student/update\",student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; restTemplate.delete(\"http://localhost:8010/student/deleteById/&#123;id&#125;\",id); &#125;&#125; 创建启动类---------RestTemplateApplication.java 123456789101112131415161718package resttemplate.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RestTemplateApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RestTemplateApplication.class,args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 这个只是简单测试RestTemplate的用法，并不涉及到微服务，为下面实现服务消费者Consumer预热，启动RestTemplateApplication的时候端口默认为8080，所以可以通过访问：http://localhost:8080/rest/findAll 等接口访问数据，此时的数据访问调用的是Eureka Client中的数据。 服务消费者Consumer 在父工程中创建module—consumer 在pom.xml添加 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在module中创建配置文件 application.yml 1234567891011server: port: 8020spring: application: name: consumereureka: client: service-url: defaultZone: http://loaclhost:8071/eureka/ instance: prefer-ip-address: true 创建启动类---------ConsumerApplication.java 123456789101112131415161718package consumer.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class,args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 创建实体类（同上） 创建controller 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package consumer.lee.controller;import consumer.lee.entity.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import java.util.Collection;@RestController@RequestMapping(\"/consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); &#125; @GetMapping(\"/findAllSec\") public Collection&lt;Student&gt; findAllSec()&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id).getBody(); &#125; @GetMapping(\"/findByIdSec/&#123;id&#125;\") public Student findByIdSec(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); &#125; @PutMapping(\"update\") public void update(@RequestBody Student student)&#123; restTemplate.put(\"http://localhost:8010/student/update\",student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; restTemplate.delete(\"http://localhost:8010/student/deleteById/&#123;id&#125;\",id); &#125;&#125; 到此服务消费者创建完成，其实和上面的resttemplate差不多，此模块是在注册中心注册过的，在这里你可以访问 http://localhost:8020/consumer/findAll 等接口访问Eureka Client中的数据。 服务网关Zuul Spring Cloud 集成了 Zuul 组件，实现服务⽹关。 什么是Zuul? Zuul 是 Netflix 提供的⼀个开源的 API ⽹关服务器，是客户端和⽹站后端所有请求的中间层，对外开放 ⼀个 API，将所有请求导⼊统⼀的⼊⼝，屏蔽了服务端的具体实现逻辑，Zuul 可以实现反向代理的功 能，在⽹关内部实现动态路由、身份认证、IP 过滤、数据监控等。 在父工程基础上再创建module pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8030spring: application: name: gatewayeureka: client: service-url: dedaultZone: http://localhost:8071/eureka/zuul: routes: serverProvider: /p/** 属性说明 zuul.routes.serverProvider：给服务提供者 provider 设置映射，这里的 serverProvider是Eureka Client在注册中心注册的服务名称，即访问其服务提供者模块，只需在结构访问地址加上/p/即可 创建启动类 12345678910111213package zuul.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@EnableZuulProxy@EnableAutoConfigurationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125; 注解解释 @EnableZuulProxy：包含了 @EnableZuulServer，设置该类是⽹关的启动类。 @EnableAutoConfiguration：可以帮助 Spring Boot 应⽤将所有符合条件的 @Configuration 配 置加载到当前 Spring Boot 创建并使⽤的 IoC 容器中。 Zuul ⾃带了负载均衡功能，provider 创建多个实例(即多个启动类，修改配置文件的端口)，每个实例提供不同的请求，修改 provider（即eureka client中的） 的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package eurekaclient.lee.controller;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentController &#123; @Autowired private StudentRepository repository; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return repository.findAll(); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return repository.findById(id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @PutMapping(\"/update\") public void update(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; repository.deleteById(id); &#125; @GetMapping(\"/index\") public String index()&#123; return \"当前端口：\" + this.port; &#125;&#125; 到这里网关服务基本实现，你只需要访问：http://localhost:8030/p/student/findAll 等接口也是可以访问到服务提供者中的数据。 Ribbon 负载均衡 什么是 Ribbon？ Spring Cloud Ribbon 是⼀个负载均衡解决⽅案，Ribbon 是 Netflix 发布的负载均衡器，Spring Cloud Ribbon 是基于 Netflix Ribbon 实现的，是⼀个⽤于对 HTTP 请求进⾏控制的负载均衡客户端。 在注册中⼼对 Ribbon 进⾏注册之后，Ribbon 就可以基于某种负载均衡算法，如轮询、随机、加权轮 询、加权随机等⾃动帮助服务消费者调⽤接⼝，开发者也可以根据具体需求⾃定义 Ribbon 负载均衡算 法。实际开发中，Spring Cloud Ribbon 需要结合 Spring Cloud Eureka 来使⽤，Eureka Server 提供 所有可以调⽤的服务提供者列表，Ribbon 基于特定的负载均衡算法从这些服务提供者中选择要调⽤的 具体实例。 在父工程上创建Module 在pom.xml文件中添加 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Module中创建配置文件 application.yml 1234567891011server: port: 8040spring: application: name: ribboneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 创建启动类------RibbonApplication.Java 1234567891011121314151617181920package ribbon.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonApplication.class,args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 注解说明 @LoadBalanced：声明⼀个基于 Ribbon 的负载均衡。 创建实体类(同上) 创建controller 12345678910111213141516171819202122232425262728package ribbon.lee.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import ribbon.lee.entity.Student;import java.util.Collection;@RestController@RequestMapping(\"/ribbon\")public class RibbonController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForObject(\"http://serverProvider/student/findAll\",Collection.class); &#125; @GetMapping(\"/index\") public String index()&#123; return restTemplate.getForObject(\"http://serverProvider/student/index\",String.class); &#125;&#125; 到此ribbon负载均衡基本实现，你可以访问：http://localhost:8040/ribbon/findAll 来访问服务提供者的数据。 Feign 负载均衡 什么是 Feign？ 与 Ribbon ⼀样，Feign 也是由 Netflix 提供的，Feign 是⼀个声明式、模版化的 Web Service 客户端， 它简化了开发者编写 Web 服务客户端的操作，开发者可以通过简单的接⼝和注解来调⽤ HTTP API， Spring Cloud Feign，它整合了 Ribbon 和 Hystrix，具有可插拔、基于注解、负载均衡、服务熔断等⼀ 系列便捷功能。 相⽐较于 Ribbon + RestTemplate 的⽅式，Feign ⼤⼤简化了代码的开发，Feign ⽀持多种注解，包括 Feign 注解、JAX-RS 注解、Spring MVC 注解等，Spring Cloud 对 Feing 进⾏了优化，整合了 Ribbon 和 Eureka，从⽽让 Feign 的使⽤更加⽅便。 Ribbon 和 Feign 的区别 Ribbon 是⼀个通⽤的 HTTP 客户端⼯具，Feign 是基于 Ribbon 实现的。 Feign 的特点 Feign 是⼀个声明式的 Web Service 客户端。 ⽀持 Feign 注解、Spring MVC 注解、JAX-RS 注解。 Feign 基于 Ribbon 实现，使⽤起来更加简单。 Feign 集成了 Hystrix，具备服务熔断的功能。 在父工程的基础上创建module—feign，在pom.xml中添加 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建该模板的配置文件：application.yml 1234567891011server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 实体类也要复制过来 创建启动类---------FeignApplication.java 12345678910111213package feign.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClientspublic class FeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignApplication.class,args); &#125;&#125; 创建声明式接口---------FeignProviderClient 1234567891011121314151617package feign.lee.feign;import feign.lee.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\")public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 创建控制器 12345678910111213141516171819202122232425262728package feign.lee.controller;import feign.lee.entity.Student;import feign.lee.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/feign\")public class FeignController &#123; @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return feignProviderClient.findAll(); &#125; @GetMapping(\"/index\") public String index()&#123; return feignProviderClient.index(); &#125;&#125; 到这里可以通过：http://localhost:8050/feign/findAll 来访问eureka client中的数据。和上面的Ribbon实现的功能是一样的，但是过程是不一样的。 Feign 中的熔断机制（因为Feign 集成了 Hystrix） 比如说一个功能需要多个微服务共同完成，但是其中一个微服务崩了，导致无法完成任务，如果没有熔断机制，前端就会显示报错，用户友好度不够好，用户也看不懂。 比如说把上面开启好的两个服务提供者eureka client关了，只留下eureka注册中心和feign，然后再次访问http://localhost:8050/feign/findAll或者是http://localhost:8050/feign/index 就会报500的错误。 服务熔断，application.yml 添加熔断机制。 1234567891011121314server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: true feign.hystrix.enabled：是否开启熔断器。 创建 FeignProviderClient 接⼝的实现类 FeignError，定义容错处理逻辑，通过 @Component 注 解将 FeignError 实例注⼊ IoC 容器中。 1234567891011121314151617181920package feign.lee.feign.impl;import feign.lee.entity.Student;import feign.lee.feign.FeignProviderClient;import org.springframework.stereotype.Component;import java.util.Collection;@Componentpublic class FeignError implements FeignProviderClient &#123; @Override public Collection&lt;Student&gt; findAll() &#123; return null; &#125; @Override public String index() &#123; return \"当前服务器正在维护中。。。。。。\"; &#125;&#125; 在 FeignProviderClient 定义处通过 @FeignClient 的 fallback 属性设置映射。 123456789101112131415161718package feign.lee.feign;import feign.lee.entity.Student;import feign.lee.feign.impl.FeignError;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\",fallback = FeignError.class)public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 到这里，当你再次访问http://localhost:8050/feign/index 的时候就提示 “当前服务器正在维护中。。。。。。”。 Hystrix 容错机制 什么是Hystrix容错机制 在不改变各个微服务调⽤关系的前提下，针对错误情况进⾏预先处理。(类似于电路的保险丝) 设计原则 服务隔离机制 服务降级机制 熔断机制 提供实时的监控和报警功能 提供实时的配置修改功能 Hystrix 数据监控需要结合 Spring Boot Actuator 来使⽤，Actuator 提供了对服务的健康健康、数据统 计，可以通过 hystrix.stream 节点获取监控的请求数据，提供了可视化的监控界⾯。 在父工程的基础上再创建module—hystrix，pom.xml添加依赖 12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8060spring: application: name: hystrixeureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: truemanagement: endpoints: web: exposure: include: 'hystrix.stream' 创建启动类---------HystrixApplication.java 1234567891011121314151617package hystrix.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClients@EnableCircuitBreaker@EnableHystrixDashboardpublic class HystrixApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HystrixApplication.class,args); &#125;&#125; 注解解释 @EnableCircuitBreaker：声明启⽤数据监控 @EnableHystrixDashboard：声明启⽤可视化数据监控 添加Student实体类 添加feign模块中的FeignProviderClient接口类 1234567891011121314151617package hystrix.lee.feign;import hystrix.lee.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\")public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 添加控制类 12345678910111213141516171819202122232425262728package hystrix.lee.controller;import hystrix.lee.entity.Student;import hystrix.lee.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/hystrix\")public class HystrixController &#123; @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return feignProviderClient.findAll(); &#125; @GetMapping(\"/index\") public String index()&#123; return feignProviderClient.index(); &#125;&#125; 到这里只是演示了hystrix对数据请求进行监控的功能，hystrix的熔断机制在Feign中已经演示过。然后启动注册中心，启动一个服务提供者eureka client，最后再启动hystrix，先访问 http://localhost:8060/actuator/hystrix.stream 查看hystrix对求情的监控，这个时候因为没有发生对提供者的请求，所以没有监控到数据，一直在ping: 然后再访问： http://localhost:8060/hystrix/index ，你会发现ping: 出现了数据。 当然这个网页看着监控的数据显示不是和友好，所以我们这里使用的是 hystrix-dashboard仪表盘来查看，访问： http://localhost:8060/hystrix ，然后把 http://localhost:8060/actuator/hystrix.stream地址复制过来，自己起一个监控的名字，点击Monitor Stream,就有一个可视化仪表盘了。 Spring Cloud 配置中⼼ Spring Cloud Config，通过服务端可以为多个客户端提供配置服务。Spring Cloud Config 可以将配置 ⽂件存储在本地，也可以将配置⽂件存储在远程 Git 仓库，创建 Config Server，通过它管理所有微服务的配置 ⽂件。 本地文件系统 在父工程的基础上创建module—nativeconfigserver，pom.xml添加以下 123456789&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8072spring: application: name: nativeconfigserver profiles: active: native cloud: config: server: native: search-locations: classpath:/shared 属性说明 profiles.active：配置⽂件的获取⽅式，这里的native指本地获取 cloud.config.server.native.search-locations：本地配置⽂件存放的路径 在resources 路径下创建 shared ⽂件夹，并在此路径下创建 configclient-dev.yml。 123server: port: 8070foo: foo version 1 创建启动类---------NativeConfigServerApplication.java 12345678910111213package config.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class NativeConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NativeConfigServerApplication.class,args); &#125;&#125; 注解说明 @EnableConfigServer：声明该module为配置中⼼。 以上配置文件的服务已经创建完成，下面开始创建一个congifclient来读取上面我们创建的configserver中的configclient-dev文件的内容。 创建客户端读取本地配置中⼼的配置⽂件 在父工程的基础上创建module—nativeconfigclient，pom.xml文件添加依赖： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 bookstrap.yml ，注意这里的文件名，不再是application。 123456789spring: application: name: configclient profiles: active: dev cloud: config: uri: http://localhost:8072 fail-fast: true 属性说明 cloud.config.uri：本地 Config Server 的访问路径 cloud.config.fail-fase：设置客户端优先判断 Config Server 获取是否正常 通过 spring.application.name 结合 spring.profiles.active 拼接⽬标配置⽂件名(如上拼接的结果：configclient-dev)，configclient-dev.yml，去 Config Server 中查找该⽂件。 创建启动类---------NativeConfigClientApplication.java 1234567891011package configclient.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class NativeConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NativeConfigClientApplication.class,args); &#125;&#125; 创建controller 12345678910111213141516171819202122package configclient.lee.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/native\")public class ConfigClientCtroller &#123; @Value(\"$&#123;server.port&#125;\") private String port; @Value(\"$&#123;foo&#125;\") private String foo; @GetMapping(\"/index\") public String index()&#123; return this.port+ \" - \"+this.foo; &#125;&#125; 到此获取配置文件中心的客户端已创建完成，访问的端口号为要获取的配置文件中的端口号，即：8070，所以该客户端的访问地址为： http://localhost:8070/native/index ，之后网页显示配置中心shared下的文件的内容。 Spring Cloud Config 远程配置 在工程中创建配置⽂件，上传⾄ GitHub（创建config文件夹，然后在里面创建configclient.yml文件） 123456789server: port: 8070spring: application: name: configclienteureka: client: service-url: defaultZone: http://localhost:8071/eureka/ 创建一个githubconfigserver子工程，其pom.xml添加： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011121314151617181920server: port: 8888spring: application: name: configserver cloud: config: server: git: uri: https://github.com/Ctrl08/SpringCloud_Learn.git search-paths: config username: 123456 password: 123456 label: mastereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ # instance:# prefer-ip-address: true 创建启动类---------GithubConfigServerApplication.java 12345678910111213package githubconfig.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class GithubConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GithubConfigServerApplication.class,args); &#125;&#125; 到这里配置中心服务端已创建完成 创建客户端读取远程配置中⼼的配置⽂件 在父工程中创建maven工程，githubconfigclient，pom.xml文件添加依赖 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建bootstrap.yml配置文件 1234567891011121314spring: cloud: config: name: configclient label: master discovery: enabled: true service-id: configservereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性解释 spring.cloud.config.name：当前服务注册在 Eureka Server 上的名称，与远程仓库的配置⽂件名 对应 spring.cloud.config.label：Git Repository 的分⽀ spring.cloud.config.discovery.enabled：是否开启 Config 服务发现⽀持 spring.cloud.config.discovery.service-id：配置中⼼在 Eureka Server 上注册的名称 创建启动类---------GithubConfigClientApplication.java 1234567891011package configclient.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GithubConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GithubConfigClientApplication.class,args); &#125;&#125; 创建控制器 12345678910111213141516171819package configclient.lee.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/hello\")public class HelloController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/index\") public String index()&#123; return this.port; &#125;&#125; 到此远程配置中心基本创建完成，可以通过访问：http://localhost:8070/hello/index 查看client通过远程获取配置中心所设置的端口号。 服务跟踪 Zipkin Spring Cloud Zipkin 对请求进行跟踪 Zipkin 是⼀个可以采集并且跟踪分布式系统中请求数据的组件，让开发者可以更加直观的监控到请求在 各个微服务所耗费的时间等，Zipkin：Zipkin Server(请求数据跟踪)、Zipkin Client(数据的展示)。 创建服务跟踪 Zipkin Server 在父工程创建maven子工程，pom.xml文件添加依赖： 1234567891011121314151617181920&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12server: port: 9090 创建服务端启动类---------ZipkinServerApplication.java 12345678910111213package zipkin.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import zipkin.server.internal.EnableZipkinServer;@SpringBootApplication@EnableZipkinServerpublic class ZipkinServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinServerApplication.class,args); &#125;&#125; 注解说明 @EnableZipkinServer：声明启动 Zipkin Server 到这里Zipkin Server创建完成。 创建服务跟踪 Zipkin Client 在父工程创建maven子工程，pom.xml添加依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8090spring: application: name: zipkinclient sleuth: web: client: enabled: true sampler: probability: 1.0 zipkin: base-url: http://localhost:9090/eureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性说明 spring.sleuth.web.client.enabled：设置开启请求跟踪 spring.sleuth.sampler.probability：设置采样⽐例，默认是 1.0 srping.zipkin.base-url：Zipkin Server 地址 创建启动类---------ZipkinClientApplication.java 1234567891011package zipkinclient;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ZipkinClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinClientApplication.class,args); &#125;&#125; 创建控制器controller 12345678910111213141516171819package zipkinclient.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/zipkin\")public class ZipkinController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/index\") public String index()&#123; return this.port; &#125;&#125; 到这里基本完成Zipkin的创建。 启动注册中心、zipkin server和zipkin client，访问：http://localhost:9090/zipkin即可进入数据请求监控的ui界面，点击 Find Traces 按钮即可开启跟踪请求，另开一个浏览页，访问：http://localhost:8090/zipkin/index，再回头看看刚才的页面，刷新页面就可以看到有请求发生并且追踪到了。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Redis实现一个简单的分布锁","slug":"Redis3","date":"2020-03-08T01:41:07.000Z","updated":"2020-03-08T04:06:13.246Z","comments":true,"path":"2020/03/08/Redis3/","link":"","permalink":"http://ctrl98.github.io/2020/03/08/Redis3/","excerpt":"","text":"什么是分布式锁 分布式锁在分布式系统中非常常见，比如对公共资源进行操作。 如卖车票，同一时刻只能有一个节点将某个特定座位的票卖出去；如避免缓存失效带来的大量请求访问数据库的问题 分布式锁需要解决的问题 互斥性：任意时刻只能有一个客户端获取锁 安全性：锁只能被持有该锁的客户端删除 死锁：某个客户端获取到锁，因某些原因宕机，使得其他客户端再也获取不了 容错：某个redis节点宕机，客户端仍然可以获取锁 实现 SETNX key value：如果key不存在，则创建并赋值 时间复杂度：o(1) 返回值：成功返回1，失败返回0 该操作是原子性的 123456789127.0.0.1:6379&gt; get locknx(nil)127.0.0.1:6379&gt; setnx locknx test(integer) 1127.0.0.1:6379&gt; setnx locknx task(integer) 0127.0.0.1:6379&gt; get locknx&quot;test&quot;127.0.0.1:6379&gt; 开始设置成功，说明目前该线程没有被占用，可以执行目前的代码块，如果设置失败，说明该线程目前被其他程序占用该资源，等待设置成功后再释放。。。 发现再后续再赋值locknx的时候失败了，说明此时该值是长期有效的。 如何解决setnx长期有效的问题 EXPIRE key seconds 设置key的生存时间，当key过期时，会被删除 1234567127.0.0.1:6379&gt; expire locknx 2(integer) 1127.0.0.1:6379&gt; setnx locknx task(integer) 1127.0.0.1:6379&gt; get locknx&quot;task&quot;127.0.0.1:6379&gt; 发现再设置的时候已经成功了 在实际代码中可以进行对返回值的判断： 12345678RedisService redisService = SpringUtils.getBean(RedisService.Class);long status = redisService.setnx(key,\"1\");if (status == 1)&#123; redisService.expire(key,expire) //执行独占资源逻辑 doOcuppieWork();&#125; 当有客户端请求该资源时发现status的值为0，说明有程序在占用该资源，后面的就不能执行了，线程进入阻塞，直到status的返回值为1为止。 然后这段程序会有风险，如果程序在执行完setnx后直接挂掉了，并没有进入到expire设置时间，这样key就永远不会过期，一直被占用着，导致其他程序再也获取不了该线程。 解决 将setnx和expire柔和在一起 SET key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置键的过期时间为second秒 PX milliseconds：设置键的过期时间为second毫秒 NX：只有键不存在时，才对键进行设置操作 XX：只有键已经存在时，才对键进行设置操作 SET操作返回值，成功ok，失败返回nil 1234567127.0.0.1:6379&gt; set locktarget 12345 ex 10 nxOK127.0.0.1:6379&gt; set locktarget 1234 ex 10 nx(nil)127.0.0.1:6379&gt; set locktarget 54321 ex 10 nxOK127.0.0.1:6379&gt; 过了10秒之后发现设置成功，符合redis的原子性操作。 因此伪代码也可以设置成： 123456RedisService redisService = SpringUtils.getBean(RedisService.Class);String result = redisService.set(lockkey,requestId,SET_NOT_EXIST,SET_WITH_EXPIRE_TIME,expiretime);if (\"ok\".equals(result))&#123; //执行独占资源逻辑 doOcuppieWork();&#125; 这样就能保证分布式锁操作的原子性了。 大量的key同时过期的注意事项 集中过期，由于清除大量过期的key很耗时，会出现卡顿现象 解决：在设置key的过期时间的时候，给每个key加上随机值","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Redis主从、哨兵及集群模式的配置","slug":"Redis2","date":"2020-03-07T13:02:19.000Z","updated":"2020-03-08T01:44:30.300Z","comments":true,"path":"2020/03/07/Redis2/","link":"","permalink":"http://ctrl98.github.io/2020/03/07/Redis2/","excerpt":"","text":"redis主从模式的配置 redis单例提供了一种数据缓存方式和丰富的数据操作api ，但是把数据完全存储再单个redis中会有两个问题：数据备份和数据量大造成性能低下。主从模式出现就是为了解决单例所带来的问题。 主从模式指： 使用一个redis实例作为主机，其余的实例作为备份机。主机和从机的数据完全一致。主机支持数据的写入和读取等各项操作，而从机则只支持与主机数据的同步和读取，也就是说，客户端可以将数据写入到主机，由主机自动将数据的写入操作同步到从机。 主从模式很好的解决了数据备份问题，并且由于主从服务数据几乎是一致的，因而可以将写入数据的命令发送给主机执行，而读取数据的命令发送给不同的从机执行，从而达到读写分离的目的。如下图的主机和三个从机。 至此redis主从模式的配置可以理解为多个不同的redis实例通过一定的配置告知其相互之间的主从关系。 主从模式的配置主要的配置点有两个： 当前实例端口号和当前实例是主机还是从机，是从机的话其主机的ip和端口是什么？ 一般的redis目录下的redis.conf保存的是默认配置，尽量不要对其进行修改. 这里我们复制三份redis.conf文件，分别命名为6379.conf，6380.conf和6381.conf 6379.conf的配置： 12bind 127.0.0.1port 6379 6380.conf和6381.conf的配置： 123bind 127.0.0.1port 6380slaveof 127.0.0.1 6379 123bind 127.0.0.1port 6381slaveof 127.0.0.1 6379 可以看到，端口为6380和6381的实例被配置为端口为6379的实例的从机。 配置完成后使用redis-server分别执行如下命令启动三个实例： 123.\\redis-server 6379.conf.\\redis-server 6380.conf.\\redis-server 6381.conf 启动之后分别开启三个命令行工具(即redis客户端)分别执行以下命令连接redis实例： 123.\\redis-cli -p 6379.\\redis-cli -p 6380.\\redis-cli -p 6381 分别在三个命令行工具中执行一个get命令，获取键名为msg的数据，如下所示： 12127.0.0.1:6379&gt; get msg(nil) 12127.0.0.1:6380&gt; get msg(nil) 12127.0.0.1:6381&gt; get msg(nil) 可以看到，在三个redis实例中都不存在键为msg的数据，现在我们在主机6379上设置一个键为msg的数据，如下所示： 12127.0.0.1:6379&gt; set msg &quot;hello&quot;OK 可以看到设置成功了，此时我们在6380和6381的实例上执行get msg的命令，如下所示： 12127.0.0.1:6380&gt; get msg&quot;hello&quot; 12127.0.0.1:6381&gt; get msg&quot;hello&quot; 可以看到，虽然我们只是在6379的实例上设置了msg这条数据，但是在6380和6381的实例上也存有了相应的数据，说明我们成功配置了redis的主从模式。另外，如果不在配置文件中指定主从节点的关系，也可以在启动相关redis实例之后使用slaveof命令来指定当前节点称为某个节点的从节点，如： 1127.0.0.1:6380&gt; slaveof 127.0.0.1 6379 redis中sentinel(哨兵)配置 redis主从模式解决了数据备份和单例可能存在的性能问题，但是其也引入了新的问题。 主从模式配置的几个实例，每个实例都会有不同的IP(如果在不同机器上)和端口号，从上面可知，主从模式将读写分配给不同的实例进行从而提高吞吐量，但是也会有另外一个问题，因为每个客户端连接redis都指定了IP和端口号，如果所连接的redis因故障下线，就只能手动去更改客户端配置重新连接，另外如果是主节点故障，那么那些从节点的同步会中断，也需要人工去转移工作。 为了解决以上问题，redis在2.8版本正式推出sentinel(哨兵)架构。 每个sentinel节点其实就是一个redis实例。与主从节点不同的是sentinel节点作用是用于监控redis数据节点的，而sentinel节点集合则表示监控一组主从redis实例多个sentinel监控节点的集合。 比如有主节点master和从节点slave-1、slave-2，为了监控这三个主从节点，这里配置N个sentinel节点sentinel-1，sentinel-2，...，sentinel-N。 对于一组主从节点，sentinel只是在其外部额外添加的一组用于监控作用的redis实例。在主从节点和sentinel节点集合配置好之后，sentinel节点之间会相互发送消息，以检测其余sentinel节点是否正常工作，并且sentinel节点也会向主从节点发送消息，以检测监控的主从节点是否正常工作。 前面讲到，sentinel架构的主要作用是解决主从模式下主节点的故障转移工作的。这里如果主节点因为故障下线，那么某个sentinel节点发送检测消息给主节点时，如果在指定时间内收不到回复，那么该sentinel就会主观的判断该主节点已经下线，那么其会发送消息给其余的sentinel节点，询问其是否“认为”该主节点已下线，其余的sentinel收到消息后也会发送检测消息给主节点。 如果其认为该主节点已经下线，那么其会回复向其询问的sentinel节点，告知其也认为主节点已经下线，当该sentinel节点最先收到超过指定数目（配置文件中配置的数目和当前sentinel节点集合数的一半，这里两个数目的较大值）的sentinel节点回复说当前主节点已下线，那么其就会对主节点进行故障转移工作，故障转移的基本思路是在从节点中选取某个从节点向其发送slaveof no one（假设选取的从节点为127.0.0.1:6380），使其称为独立的节点（也就是新的主节点），然后sentinel向其余的从节点发送slaveof 127.0.0.1 6380命令使它们重新成为新的主节点的从节点。 重新分配之后sentinel节点集合还会继续监控已经下线的主节点（假设为127.0.0.1:6379），如果其重新上线，那么sentinel会向其发送slaveof命令，使其成为新的主机点的从节点，如此故障转移工作完成。 简单来说就是：当redis服务为主从的时候如果主节点挂掉，则会选取一个从节点为master，当以前的master重启之后不再是master而为slave。 创建并修改sentinel.conf 复制三个配置文件：sentinel-26379.conf，sentinel-26380.conf和sentinel-26381.conf。分别按照如下示例编辑这三个配置文件 123456789101112131415port 26379 daemonize yes logfile &quot;26379.log&quot; dir &#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000sentinel myid mm55d2d712b1f3f312b637f9b546f00cdcedc787#port 26379#sentinel monitor mymaster 127.0.0.1 6379 2#sentinel down-after-milliseconds mymaster 5000#sentinel failover-timeout mymaster 15000#sentinel myid 88a3f92f656984fd84c183b6b183d5d264ddc485 属性说明 port：当前Sentinel服务运行的端口 sentinel monitor mymaster 127.0.0.1 6379 2：Sentinel去监视一个名为mymaster的主redis实例，这个主实例的IP地址为本机地址127.0.0.1，端口号为6379，而将这个主实例判断为失效至少需要2个 Sentinel进程的同意，只要同意Sentinel的数量不达标，自动failover就不会执行 sentinel down-after-milliseconds mymaster 5000：指定了Sentinel认为Redis实例已经失效所需的毫秒数。当 实例超过该时间没有返回PING，或者直接返回错误，那么Sentinel将这个实例标记为主观下线。只有一个 Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移：只有在足够数量的Sentinel都将一个实例标记为主观下线之后，实例才会被标记为客观下线，这时自动故障迁移才会执行 sentinel failover-timeout mymaster 15000：如果在该时间（ms）内未能完成failover操作，则认为该failover失败 myid：区分每个监控的哨兵的身份 分别使用三个配置文件使用如下命令启用sentinel 123.&#x2F;src&#x2F;redis-sentinel sentinel-26379.conf.&#x2F;src&#x2F;redis-sentinel sentinel-26380.conf.&#x2F;src&#x2F;redis-sentinel sentinel-26381.conf 由于sentinel节点也是一个redis实例，因而我们可以通过如下命令使用redis-cli连接sentinel节点： 1.&#x2F;src&#x2F;redis-cli -p 26379 连上sentinel节点之后我们可以通过如下命令查看sentinel状态： 1127.0.0.1:26379&gt; info sentinel 结果如下： 1234567# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;127.0.0.1:6379,slaves&#x3D;2,sentinels&#x3D;3 可以看到，sentinel检测到主从节点总共有三个，其中一个主节点，两个从节点，并且sentinel节点总共也有三个。启动完成之后，我们可以通过主动下线主节点来模拟sentinel的故障转移过程。首先我们连接上端口为6379的主节点，使用如下命令查看主从节点状态： 1127.0.0.1:6379&gt; info replication 结果如下： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;45616,lag&#x3D;1slave1:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;45616,lag&#x3D;1master_repl_offset:45616repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:45615 可以看到，当前主节点有两个从节点，端口分别为6380和6381。然后我们对主节点执行如下命令： 1127.0.0.1:6379&gt; shutdown save 然后我们连接上端口号为6380的从节点，并执行如下命令： 1127.0.0.1:6380&gt; info replication 结果如下： 123456789# Replicationrole:masterconnected_slaves:1slave0:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;12344,lag&#x3D;0master_repl_offset:12477repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:12476 可以看到，当端口为6379的实例下线之后，端口为6380的实例被重新竞选为新的主节点，并且端口为6381的实例被设置为6380的实例的从节点。如果我们此时重新启用端口为6379的节点，然后再查看主从状态，结果如下： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;59918,lag&#x3D;0slave1:ip&#x3D;127.0.0.1,port&#x3D;6379,state&#x3D;online,offset&#x3D;59918,lag&#x3D;1master_repl_offset:60051repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:60050 可以看到，端口为6379的redis实例重新连接后，sentinel节点检测到其重新连接，那么对其发送命令，使其成为新的主节点的从节点。 redis集群的配置 redis集群是在redis 3.0版本推出的一个功能，其有效的解决了redis在分布式方面的需求。当遇到单机内存，并发和流量瓶颈等问题时，可采用Cluster方案达到负载均衡的目的。并且从另一方面讲，redis中sentinel有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。 对于redis集群的配置，首先将redis安装目录下的redis.conf文件复制六份，分别取名为：cluster-6379.conf、cluster-6380.conf、cluster-6381.conf、cluster-6382.conf、cluster-6383.conf、cluster-6384.conf。对于一个高可用的集群方案，集群每个节点都将为其分配一个从节点，以防止数据节点因为故障下线，这里使用六份配置文件定义六个redis实例，其中三个作为主节点，剩余三个分别作为其从节点。对于这六份配置文件，以其中一份为例，以下是其需要修改的参数： 12345678port 6379cluster-enabled yescluster-node-timeout 15000cluster-config-file &quot;nodes-6379.conf&quot;pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pidlogfile &quot;cluster-6379.log&quot;dbfilename dump-cluster-6379.rdbappendfilename &quot;appendonly-cluster-6379.aof&quot; 对于其余的配置文件，只需要将其中对应项的端口号和带有端口号的文件名修改为当前要指定的端口号和端口号的文件名即可。配置文件配置好之后使用如下命令启动集群中的每个实例： 123456.&#x2F;src&#x2F;redis-server cluster-6379.conf.&#x2F;src&#x2F;redis-server cluster-6380.conf.&#x2F;src&#x2F;redis-server cluster-6381.conf.&#x2F;src&#x2F;redis-server cluster-6382.conf.&#x2F;src&#x2F;redis-server cluster-6383.conf.&#x2F;src&#x2F;redis-server cluster-6384.conf 仔细阅读上述配置文件可发现，当前配置和启动过程中并没有指定这六个实例的主从关系，也没有对16384个槽位进行分配。因而我们还需要进行进一步的配置，槽位的分配和主从关系的设定有两种方式进行，一种是使用redis-cli连接到集群节点上后使用cluster meet命令连接其他的节点，如我们首先执行如下命令连接到6379端口的节点： 1.&#x2F;src&#x2F;redis-cli -p 6379 连接上后使用cluster meet命令分别连接其余节点： 12345127.0.0.1:6379&gt;cluster meet 127.0.0.1 6380127.0.0.1:6379&gt;cluster meet 127.0.0.1 6381127.0.0.1:6379&gt;cluster meet 127.0.0.1 6382127.0.0.1:6379&gt;cluster meet 127.0.0.1 6383127.0.0.1:6379&gt;cluster meet 127.0.0.1 6384 连接好后可以使用cluster nodes命令查看当前集群状态： 1234567127.0.0.1:6379&gt; cluster nodes4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1:6384 master - 0 1468073975551 5 connectedcfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1:6379 myself,master - 0 0 0 connectedbe9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1:6383 master - 0 1468073978579 4 connected40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1:6382 master - 0 1468073980598 3 connected8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1:6380 master - 0 1468073974541 1 connected40b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1:6381 master - 0 1468073979589 2 connected 可以看到配置的六个节点都已经加入到了集群中，但是其现在还不能使用，因为还没有将16384个槽分配到集群节点中。虚拟槽的分配可以使用redis-cli分别连接到6379，6380和6381端口的节点中，然后分别执行如下命令： 123127.0.0.1:6379&gt;cluster addslots &#123;0...5461&#125;127.0.0.1:6380&gt;cluster addslots &#123;5462...10922&#125;127.0.0.1:6381&gt;cluster addslots &#123;10923...16383&#125; 添加完槽位后可使用cluster info命令查看当前集群状态： 123456789101112127.0.0.1:6379&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:5cluster_my_epoch:0cluster_stats_messages_sent:4874cluster_stats_messages_received:4726 这里我们将16384个虚拟槽位分配给了三个节点，而剩余的三个节点我们通过如下命令将其配置为这三个节点的从节点，从而达到高可用的目的： 123456127.0.0.1:6382&gt;cluster replicate cfb28ef1deee4e0fa78da86abe5d24566744411eOK127.0.0.1:6383&gt;cluster replicate 8e41673d59c9568aa9d29fb174ce733345b3e8f1OK127.0.0.1:6384&gt;cluster replicate 40b8d09d44294d2e23c7c768efc8fcd153446746OK 如此，所有的集群节点都配置完毕，并且处于可用状态。这里可以使用cluster nodes命令查看当前节点的状态： 1234567127.0.0.1:6379&gt; cluster nodes4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1:6384 slave 40b8d09d44294d2e23c7c768efc8fcd153446746 0 1468076865939 5 connectedcfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1:6379 myself,master - 0 0 0 connected 0-5461be9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1:6383 slave 8e41673d59c9568aa9d29fb174ce733345b3e8f1 0 1468076868966 4 connected40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1:6382 slave cfb28ef1deee4e0fa78da86abe5d24566744411e 0 1468076869976 3 connected8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1:6380 master - 0 1468076870987 1 connected 5462-1092240b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1:6381 master - 0 1468076867957 2 connected 10923-16383 我们使用redis-cli使用如下命令连接集群： 1.&#x2F;src&#x2F;redis-cli -c -p 6380 注意连接集群模式的redis实例时需要加上参数-c，表示连接的是集群模式的实例。连接上后执行get命令： 123127.0.0.1:6380&gt; get hello-&gt; Redirected to slot [866] located at 127.0.0.1:6379(nil) 可以看到，在6380端口的实例上执行get命令时，其首先会为当前的键通过一致哈希算法计算其所在的槽位，并且判断该槽位不在当前redis实例中，因而重定向到目标实例上执行该命令，最后发现没有该键对应的值，因而返回了一个（nil）。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Redis数据缓存 基础知识","slug":"Redis1","date":"2020-03-06T01:12:22.000Z","updated":"2020-03-08T07:47:46.848Z","comments":true,"path":"2020/03/06/Redis1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Redis1/","excerpt":"","text":"主流应用架构 穿透查询：请求数据的时候先到缓存层查询数据，当缓存层没有数据，在穿透到存储层查询 回种：穿透查询完成后再缓存到缓存区 熔断：当存储层挂了之后，会自动从缓存层获取并返回数据，无论有没有获取到数据都返回 缓存中间件——Memcache和Redis的区别 Memcache：代码层次类似Hash 优缺点： 支持简单数据类型 不支持数据持久化存储 不支持主从 不支持分片(把数据库打碎的过程，将大数据分布到各个物理节点上) Redis 优缺点： 数据类型丰富 支持数据持久化存储 支持主从 支持分片(3.0版本后) 为什么Redis能这么快？ 100000+QPS（QPS即query per second，每秒内查询次数） 完全基于内存，绝大部分请求时纯粹的内存操作，执行效率高 数据结构简单，对数据操作也简单 采用单线程，单线程也能处理高并发请求，想多核也可以启动多实例 使用多路复用I/O复用模型，非阻塞IO redis单例的安装及配置使用 win10本地安装redis服务 进入根目录，配置redis.windows.conf： 添加配置需要密码验证 requirepass 123456 修改 appendonly 为yes 开启aof日志防止数据丢失 根目录处以管理员身份打开cmd 输入启动命令启动服务端： 12.\\redis-server.exe redis.windows.conf###注意如果提示错误，把前面的.\\请去掉再回车试试 如果需要按照指定的配置文件来启动，可在redis-server.exe后接上配置文件名 : 1.\\redis-server.exe redis1.conf 再打开一个cmd窗口启动客户端： 1.\\redis-cli.exe 然后输入认证密码命令连接服务： 1auth 123456 显示ok即连接成功，输入ping测试看是否返回pong。 如果需要连接指定ip和端口的客户端，可以使用如下方式 : 1.\\redis-cli.exe -h 127.0.0.1 -p 6379 Redis数据类型 String类型 redis最基本的数据类型，k-v存储，最大能存储512M，二进制安全(即可以包含任何数据，如jpg图片、序列化对象…) 简单操作 1234567891011121314151617127.0.0.1:6379&gt; set name &quot;redis&quot;OK127.0.0.1:6379&gt; get name&quot;redis&quot;127.0.0.1:6379&gt; set name &quot;memocache&quot;OK127.0.0.1:6379&gt; get name&quot;memocache&quot;127.0.0.1:6379&gt; set count 1OK127.0.0.1:6379&gt; get count&quot;1&quot;127.0.0.1:6379&gt; incr count(integer) 2127.0.0.1:6379&gt; get count&quot;2&quot;127.0.0.1:6379&gt; Hash类型 string元素组成的字典，适合用于存储对象 简单操作 1234567891011127.0.0.1:6379&gt; hmset lilei name &quot;lilei&quot; age 18 title &quot;senior&quot;OK127.0.0.1:6379&gt; hget lilei age&quot;18&quot;127.0.0.1:6379&gt; hget lilei title&quot;senior&quot;127.0.0.1:6379&gt; hset lilei title &quot;collge&quot;(integer) 0127.0.0.1:6379&gt; hget lilei title&quot;collge&quot;127.0.0.1:6379&gt; List类型 列表，按照String元素插入顺序排序，可以添加元素到列表的头部或尾部，元素先进后出，(最新排行榜) 简单操作 1234567891011127.0.0.1:6379&gt; lpush mylist aaa(integer) 1127.0.0.1:6379&gt; lpush mylist bbb(integer) 2127.0.0.1:6379&gt; lpush mylist ccc(integer) 3127.0.0.1:6379&gt; lrange mylist 0 101) &quot;ccc&quot;2) &quot;bbb&quot;3) &quot;aaa&quot;127.0.0.1:6379&gt; Set类型 String元素组成的无须集合，通过哈希表表现，不允许重复，(微博的互相关注) 简单操作 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; sadd myset 111(integer) 1127.0.0.1:6379&gt; sadd myset 222(integer) 1127.0.0.1:6379&gt; sadd myset 333(integer) 1127.0.0.1:6379&gt; sadd myset 333(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;111&quot;2) &quot;222&quot;3) &quot;333&quot;127.0.0.1:6379&gt; sadd myset abc(integer) 1127.0.0.1:6379&gt; sadd myset abd(integer) 1127.0.0.1:6379&gt; sadd myset abb(integer) 1127.0.0.1:6379&gt; sadd myset abd(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;abc&quot;2) &quot;222&quot;3) &quot;abd&quot;4) &quot;abb&quot;5) &quot;333&quot;6) &quot;111&quot;127.0.0.1:6379&gt; Sorted Set类型 通过分数score来为集合中的成员进行从小到大排序，去重 简单操作 12345678910111213141516127.0.0.1:6379&gt; zadd myzset 3 abc(integer) 1127.0.0.1:6379&gt; zadd myzset 1 abd(integer) 1127.0.0.1:6379&gt; zadd myzset 2 abb(integer) 1127.0.0.1:6379&gt; zadd myzset 2 abb(integer) 0127.0.0.1:6379&gt; zadd myzset 1 bgg(integer) 1127.0.0.1:6379&gt; zrangebyscore myzset 0 101) &quot;abd&quot;2) &quot;bgg&quot;3) &quot;abb&quot;4) &quot;abc&quot;127.0.0.1:6379&gt; 缓存雪崩 什么是缓存雪崩？ 如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩 由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。 有什么解决方案来防止缓存雪崩？ 加锁排队 mutex互斥锁解决，Redis的SETNX去set一个mutex key，当操作返回成功时，再进行加载数据库的操作并回设缓存，否则，就重试整个get缓存的方法 数据预热 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据。可以通过缓存reload机制，预先去更新缓存，在即将发生大并发访问前手动触发加载缓存不同的key。 双层缓存策略 C1为原始缓存，C2为拷贝缓存，C1失效时，可以访问C2，C1缓存失效时间设置为短期，C2设置为长期 定时更新缓存策略 实效性要求不高的缓存，容器启动初始化加载，采用定时任务更新或移除缓存 设置不同的过期时间，让缓存失效的时间点尽量均匀 缓存击穿 什么是缓存击穿？ 在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 会带来什么问题 会造成某一时刻数据库请求量过大，压力剧增。 如何解决 上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它，其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。 缓存穿透 什么是缓存穿透？ 缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到对应key的value，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库。 有什么解决方案来防止缓存穿透？ 缓存空值 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障）我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过5分钟。通过这个设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库。 采用布隆过滤器BloomFilter 优势：占用内存空间很小，位存储；性能特别高，使用key的hash判断key存不存在 将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力 在缓存之前在加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查询缓存，缓存中没有再去查询数据库","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Mysql 基础知识（一）","slug":"Mysql1","date":"2020-03-06T01:05:41.000Z","updated":"2020-03-06T01:07:55.074Z","comments":true,"path":"2020/03/06/Mysql1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Mysql1/","excerpt":"","text":"where子句 **where：**数据库中常用的是where关键字，用于在初始表中筛选查询。它是一个约束声明，用于约束数据，在返回结果集之前起作用。 **group by:**对select查询出来的结果集按照某个字段或者表达式进行分组，获得一组组的集合，然后从每组中取出一个指定字段或者表达式的值。 **having：**用于对where和group by查询出来的分组经行过滤，查出满足条件的分组结果。它是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作。 执行顺序 select –&gt;where –&gt; group by–&gt; having–&gt;order by update 当我们需要将字段中的特定字符串批量修改为其他字符串时，可已使用以下操作： 12UPDATE runoob_tbl SET runoob_title &#x3D; REPLACE(runoob_title, &#39;C++&#39;, &#39;Python&#39;) where runoob_id &#x3D; 3; delete delete，drop，truncate 都有删除表的作用，区别在于： 1、delete 和 truncate 仅仅删除表数据，drop 连表数据和表结构一起删除，打个比方，delete 是单杀，truncate 是团灭，drop 是把电脑摔了。 2、delete 是 DML 语句，操作完以后如果没有不想提交事务还可以回滚，truncate 和 drop 是 DDL 语句，操作完马上生效，不能回滚，打个比方，delete 是发微信说分手，后悔还可以撤回，truncate 和 drop 是直接扇耳光说滚，不能反悔。 3、执行的速度上，drop&gt;truncate&gt;delete，打个比方，drop 是神舟火箭，truncate 是和谐号动车，delete 是自行车。 like子句 LIKE 子句中使用百分号 **%**字符来表示任意字符，类似于UNIX或正则表达式中的星号 ***** 如果没有使用百分号 %, LIKE 子句与等号 = 的效果是一样的 like 匹配/模糊匹配，会与 % 和 _ 结合使用： 123456&#39;%a&#39; &#x2F;&#x2F;以a结尾的数据&#39;a%&#39; &#x2F;&#x2F;以a开头的数据&#39;%a%&#39; &#x2F;&#x2F;含有a的数据&#39;_a_&#39; &#x2F;&#x2F;三位且中间字母是a的&#39;_a&#39; &#x2F;&#x2F;两位且结尾字母是a的&#39;a_&#39; &#x2F;&#x2F;两位且开头字母是a的 union 操作符 UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。 union 实例： 1SELECT country FROM Websites UNION SELECT country FROM apps ORDER BY country 查两张表中的同一个字段的不同值都查询出来（去重） union all 实例： 1SELECT country FROM Websites UNION ALL SELECT country FROM apps ORDER BY country 查两张表中的同一个字段的相同的值都查出来（不去重） order by 子句排序 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列 。 1SELECT * from runoob_tbl ORDER BY submission_date ASC; 拼音排序 字符集采用的是 gbk(汉字编码字符集) ，直接 order by就行 字符集采用的是 utf8(万国码) ， 先对字段进行转码然后排序 ORDER BY CONVERT(runoob_title using gbk); group up 子句 例如： 将数据表按名字进行分组，并统计每个人有多少条记录 1SELECT name, COUNT(*) FROM employee_tbl GROUP BY name; with rollup 可以实现在分组统计数据基础上再进行相同的统计（SUM,AVG,COUNT…） 1SELECT name, SUM(singin) as singin_count FROM employee_tbl GROUP BY name WITH ROLLUP; join 连接 需要从多个数据表中读取数据，JOIN 在两个或多个表中查询数据 INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录 比如：读取runoob_tbl表中所有runoob_author字段在tcount_tbl表对应的runoob_count字段值 语法举例：Select A.Name from A INNER JOIN B ON A.id =B.id 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a INNER JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; 等价于： 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a, tcount_tbl b WHERE a.runoob_author &#x3D; b.runoob_author; **LEFT JOIN（左连接）：**获取左表所有记录，即使右表没有对应匹配的记录 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a LEFT JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a RIGHT JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; alter 删除表字段 1ALTER TABLE testalter_tbl DROP i; 添加表字段 1ALTER TABLE testalter_tbl ADD i INT; 修改表字段类型及名称： MODIFY 或 CHANGE 子句 ​ 把字段 c 的类型从 CHAR(1) 改为 CHAR(10) 1ALTER TABLE testalter_tbl MODIFY c CHAR(10); ​ 使用 CHANGE 子句, 语法有很大的不同。 在 CHANGE 关键字之后，紧跟着的是你要修改的字段名，然后指定新字段名及类型 1ALTER TABLE testalter_tbl CHANGE i j BIGINT; 修改表名 1ALTER TABLE testalter_tbl RENAME TO alter_tbl;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://ctrl98.github.io/tags/MySQL/"}]},{"title":"Git Bash基础操作","slug":"Git1","date":"2020-03-06T00:48:45.000Z","updated":"2020-03-06T00:59:41.270Z","comments":true,"path":"2020/03/06/Git1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Git1/","excerpt":"","text":"Git基本操作 安装： 根据系统自己选择下载傻瓜式安装 配置： 用户名： 1$ git config --global user.name &quot;你的账号&quot; 邮箱： 1$ git config --global user.email &quot;你的邮箱账号&quot; 查看全局配置命令： 1$ cat ~&#x2F;.gitconfig 初始化： 新建一个文件夹，再当前目录下打开git bash 执行命令： 1$ git init 查看状态： 在当前目录新建一个README.md文档； 查看当前git仓库状态： 1$ git status 提交新建文档到缓存区命令： 1$ git add README.md 再次查看当前git仓库状态： 截图中也提示，如果想取消本次提交，可执行： 1$ git rm --cached README.md 提交新文件到暂存区： 提交命令： 1$ git add README.md 当前目录下全部文件都提交： 1$ git add -A 提交新内容到git本地仓库： 提交命令： 1$ git commit -m &quot;add README.md&quot; m：message，输入你本次提交的内容或日志 设置要提交到的远程仓库： 先到自己的github创建新的空白远程仓库； 命令： 1$ git remote add origin https:&#x2F;&#x2F;github.com&#x2F;ctrl98&#x2F;git-test.git 查看当前远程仓库的信息： 1$ git remote -v 提交新内容到远程仓库命令： 1$ git push -u origin master 参数说明： -u：第一次提交的时候加上这个属性，以后提交只需要输入：git push即可 -origin：远端链接的名字，创建远程仓库时默认 -master：仓库主干分支 克隆远程仓库项目到本地： 命令： 1$ git clone https:&#x2F;&#x2F;github.com&#x2F;ctrl98&#x2F;git-test.git 更新远程仓库代码到本地： 远程仓库做了修改，本地仓库还是旧的，可执行拉取命令： 1$ git pull Git分支 分支互相独立，互不影响 创建新的分支： 1$ git branch feature1 查看当前分支列表： 1$ git branch 切换分支： 1$ git checkout feature1 查看当前分析目录信息，可发现有master主干上的文件： 在feature1分支下创建a.txt文件，并编辑文件内容：this is a.txt，保存并退出。 commit feature1的文件到本地仓库中。 再创建一个新的分支并切换到该分支： 1$ git checkout -d feature2 查看一下该分支的目录文件信息，发现有master的README.md文档和feature1的a.txt文档，也就是说是基于feature1的，新分支的内容是基于上个分支的内容。 查看文件内容命令： 1$ cat a.txt 分支简单合并 合并命令： 1$ git merge 分支名称 创建并切换到分支feature3: 1$ git checkout -b feature3 新建b.txt文件，并编写内容：hello world： 12touch b.txt;vi b.txt 提交该文件到本地仓库中： 12git add b.txtgit commit -m &quot;add b.txt&quot; 切换回master主分支中： 1$ git checkout master 删除feature3分支： 1$ git branch -d feature3 发现无法删除，因为feature3中本地仓库中有提交，提示你要么合并该分支到master，要么就强制删除分支 合并feature3到master主分支，Head指针执行master： 1$ git merge feature3 提示合并成功 远程仓库创建分支显示 切换到需要再远程仓库中显示的分支： 1$ git checkout feature1 输入设置命令： 1$ git push origin feature1 这个时候远程仓库就会有一个feature1分支显示 也可以起别名： 1$ git push origin feature1:f1 删除远程仓库分支 本地git命令行切换到要删除远程的分支 输入删除命令： 1git push origin :feature1 查看Git日志 命令： 1git log 更简洁地查看： 1git log --oneline 如果提交次数多的话，还可以指定查看最新的提交范围： 1git log --oneline -5 想要查看某一次提交了什么新的内容，可以先复制日志对应的ID，然后执行： 1git show +id 合并操作 清空上面创建的分支，只留下master –ff 方式 创建并切换至f1分支 创建fa.txt文件并提交到本地仓库 查看日志： 1git log --oneline 发现指针HEAD指向了f1 切换回master分支进行合并 (默认使用 --ff 模式) ： 12git checkout mastergit merge f1 此时使用的是 fast-forward 方式合并策略，也就是默认的 --ff 模式，可以通过 git merge --help查看相关模式， 这种方式不会创建一个新的commit，只会显示f1分支提交的message。 –no-ff 方式 保证了原有开发的提交量的完整性 切换回f1分支 创建fb.txt文件并提交到本地仓库： 123touch fb.txtgit add fb.txtgit commit -m &quot;add fb.txt&quot; 切换回master分支进行合并： 12git checkout mastergit merge f1 --no-ff 这个时候会进入一个界面，产生了一条message，叫 Merge branch ‘f1’，我们可以修改这个message，默认不修改，保存退出，这个时候发行合并的策略变为：Merge made by the ‘recursive’ strategy，此时查看log日志会出现拐弯现象，把f1的commit和合并时的message两个commit都显示出来了。 提交到远程仓库，并创建远程仓库分支f1： 12git pushgit push origin f1:f1 打开github的远程仓库，添加master下的a.txt文件内容： 1update 这个时候远程仓库是最新的版本，本地是较旧的版本 回到本地仓库，同步远程master分支的内容到本地： 1git pull 切换到f1分支，f1分支想要拿到master的最新版本，需要merger一下master，才能和master保持同步： 1git merge master 再查看一下日志，发现日志对于本次同步只显示了一条 update a.txt 的信息，并没有出现拐弯 这个时候master有人作了修改，且回到master分支： 12345git checkout mastertouch m1.txtgit add m1.txtgit commit -m &quot;add m1.txt&quot;git log --oneline rebase命令 再回到f1分支，如果我们使用git rebase命令来合并，将f1这个分支移动到master分支的最后一次提交，会把master所有提交并入过来： 12git rebase masterll 再次查看log日志，会发现在f1中会产生一条新的提交，叫&quot;add m1.txt&quot;，重写了项目的提交历史，并且不会带来一条 merge 的commit. rebase最大的好处： 就是使得提交的历史不会出现分叉，项目提交历史看着非常整齐，他不会像 git merge 那样引入一条分叉 **rebase的不好：**安全性和可跟踪性，不要在master上使用rebase命令，rebase命令他不是合并操作，而是复制操作，而merge命令是把两个分支的内容合并到一起。 简单处理合并冲突 在f1分支基础上再创建一个f2分支，并随便修改一下a.txt的内容，保存退出提交到本地仓库： 12git checkout -b f2vi a.txt 回到f1分支，同样修改a.txt文件内容并提交到本地仓库： 12git chrckout f1vi a.txt 再次回到f2分支，这个时候想拉取一下f1同学写的代码： 12git checkout f2git merge f1 这个时候会出现文件冲突，需要解决冲突，查看一下a.txt文件： 1cat a.txt 发现文件内容很乱，显示两个分支上对这个文件的不同修改的内容，要么使用f1的要么使用f2的，然后修改a.txt，就会看到刚才查看到的内容： 1vi a.txt 这样修改很麻烦，实际开发中会用工具下来修改 使用mergetool命令来检测冲突并解决冲突： 1git mergetool 再次回车使用vimdiff来解决冲突，把不需要保留的内容删除，然后保存退出，再看一下a.txt文件： 1cat a.txt 发现内容已经修改为刚才保留下来的内容，然后再commit一下： 1git commit -m &quot;update a.txt&quot; Git的回滚撤销 git reset 分支名^ 回到上一次提交的版本，他只是把HEAD指针移动了，并没有删除东西，默认是–mixed模式（本次提交的东西从暂存区撤销，但仍留在工作区中），在master分支下： 123touch hello.javagit add hello.javagit commit -m &quot;add hello.java&quot; 此时查看log，会发现已经有本条提交记录，这个时候想回退上个版本： 1git reset master^ # ^符号代表上一次的意思 查看状态： 1git status 发现hello.java文件处于未提交状态 同样也可以直接： 1git reset 版本码(查看每条日志前的唯一标识) hard模式简单粗暴，直接还原上个版本的东西，暂存区、工作目录都清空本次更新的内容： 1git reset --hard 版本号 git revert 此次操作之前和之后的commit和history都会保留，并且把这次撤销作为一次最新的提交，用新的commit来回滚上一个版本； 1git revert 版本号 执行后会产生一次commit，填写提交的message，直接保存退出，他就把删除了revert那个版本的东西，比如那次提交是新建了一个文件，执行revert后，那个文件就不存在，但是那次提交commit的message就更新为 revert … 所以，在公共分支上使用 git revert，会把提交的信息记录保存下来，可以回溯，在其他分支，可以直接 git reset回退 Git 工作基本流程 最后附上Git命令大全","categories":[{"name":"Git","slug":"Git","permalink":"http://ctrl98.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://ctrl98.github.io/tags/Git/"},{"name":"版本控制工具","slug":"版本控制工具","permalink":"http://ctrl98.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"使用Dockerfile创建镜像","slug":"Docker6","date":"2020-02-27T05:43:51.000Z","updated":"2020-02-27T06:38:09.608Z","comments":true,"path":"2020/02/27/Docker6/","link":"","permalink":"http://ctrl98.github.io/2020/02/27/Docker6/","excerpt":"","text":"什么是Dockerfile文件 Dockerfile文件其实就是一个文本文件，由一系列命令和参数构成，Docker可以读取Dockerfile文件并根据Dockerfile文件的描述构建镜像。 Dockerfile文件内容一般为4个部分 基础镜像信息 维护者信息 镜像操作命令 容器启动时执行的命令 Dockerfile常用命令 命令 作用 FROM image_name:tag 定义了使用哪个基础镜像启动构建流程 MAINTAINER user_name 声明镜像的创建者 EVN key value 声明环境变量(可以多条) RUN command 是Dockerfile核心部分(可以写多条) ADD source_dir/file dest_dir/file 将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压 COPY source_dir/file dest_dir/file 和上一条一样，不同的是不自动解压 WORKDIR path_dir 设置工作目录 目标 使用Dockerfile构建一个包含jdk11环境的centos7镜像。 分析： ​ 假设以centos7作为基础镜像，添加jdk11并构建一个包含jdk1.8的centos7新镜像，使用Dockerfile可以实现。 步骤： 拉取centos7镜像 上传jdk11压缩包 编写Dockerfile文件 构建镜像 测试（基于新镜像创建并启动容器，测试jdk版本） 拉取centos7镜像 这个不作过多解释，直接使用 docker pull centos:7命令拉取。 上传jdk文件到宿主机 创建目录： 1mkdir &#x2F;usr&#x2F;local&#x2F;dockerjdk11 使用 WinSCP 软件来上传本地电脑文件到虚拟机centos系统dockerjdk11目录下，也不作过多解释，下载软件后直接输入虚拟机的IP地址，用户名和密码即可登录，端口默认是 22； 编写Dockerfile文件 在/usr/local/dockerjdk11目录下使用vi命令进行编写： 1vi Dockerfile 内容为： 123456789FROM centos:7MAINTAINER 23h59m59sWORKDIR &#x2F;usrRUN mkdir &#x2F;usr&#x2F;local&#x2F;javaADD jdk-11.0.5_linux-x64_bin.tar.gz &#x2F;usr&#x2F;local&#x2F;java&#x2F;ENV JAVA_HOME &#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk-11.0.5ENV JRE_HOME $JAVA_HOME&#x2F;jreENV CLASSPATH $JAVA_HOME&#x2F;lib&#x2F;dt.jar:JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;lib:$CLASSPATHENV PATH $JAVA_HOME&#x2F;bin:$PATH 按Esc键，然后英文状态下输入 : 键，然后紧接着输入 wq 保存并退出。 构建镜像 输入构建镜像命令： 1docker build -t&#x3D;&#39;jdk11&#39; . -t：要构建的镜像的名称 .：这个点不能省略，表示当前目录下 等到successfully 查看当前镜像列表是否构建成功： 1docker images 测试（基于新镜像创建并启动容器，测试jdk版本） 基于构建的新镜像jdk11创建并启动容器： 1docker run -it --name&#x3D;newtestjdk11 jdk11 &#x2F;bin&#x2F;bash 创建成功后自动进入该容器，测试jdk版本： 1java -version 发现显示jdk的版本为11.0.5","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker容器的备份、迁移与恢复","slug":"Docker5","date":"2020-02-27T04:13:17.000Z","updated":"2020-02-27T05:08:04.763Z","comments":true,"path":"2020/02/27/Docker5/","link":"","permalink":"http://ctrl98.github.io/2020/02/27/Docker5/","excerpt":"","text":"容器的备份、迁移与恢复 其中涉及到的命令： docker commit：将容器保存为镜像 docker save：将镜像备份为tar文件 docker load：根据tar文件恢复为镜像 容器备份 目标：能够将服务器A的某个容器保存为镜像，备份成tar文件，迁移到服务器B恢复镜像再启动以恢复的镜像作为基础的容器来运行。 需求：在当前的容器中安装了各种组件，期望在其他服务器上也能快速拥有该容器的一切环境。 可以将当前的容器制作为一个镜像，再将该镜像复制到其他服务器，其他服务器再基于镜像运行容器。 镜像制作 将容器保存为一个镜像，通过 commit命令： 1docker commit myredis myredis 第一个mytomcat：容器名称 第二个mytomcat：创建的镜像名称 查看镜像列表是否制作成功： 1docker images 成功制作 备份镜像 通过save命令，在当前目录下保存tar文件： 1docker save -o myredis.tar(生成的文件名) myredis(要备份的镜像名) 通过ll命令查看当前路径下的文件，发现已有myredis.tar文件： 迁移镜像 由于环境限制，只能通过 docker rm命令 把本机的myredis容器删除，从而 使用 docker rmi命令 把上面制作的myredis镜像删除，模拟另一台服务器，实际环境可以把tar文件复制到另一台服务器。 恢复镜像 在当前目录下拿到了tar文件 通过 docker load命令恢复镜像： 1docker load -i myredis.tar(镜像备份的名称) 恢复之后可以查看一下镜像列表： 基于镜像运行容器 创建基于刚才恢复的myredis镜像的容器： 1docker run -di --name&#x3D;myredis -p 6379:6379 myredis 执行之后查看容器列表： 迁移成功。","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker部署Tomcat容器","slug":"Docker4","date":"2020-02-26T11:58:21.000Z","updated":"2020-02-26T12:23:52.774Z","comments":true,"path":"2020/02/26/Docker4/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker4/","excerpt":"","text":"分析 创建容器的时候对容器中的webapps目录（存放web项目的目录）进行目录挂载，发布web项目只需要把项目上传到宿主机的挂载目录即可，tomcat会自动解压包。 拉取Tomcat镜像 拉取镜像的时候不指定版本号，默认下载tomcat最新版的，这里默认就行。 拉取Tomcat镜像： 1docker pull tomcat 等待Pull complete： 查看镜像列表： 1docker images 拉取成功 创建并启动Tomcat容器 执行一下命令进行创建： 1docker run -di --name&#x3D;mytomcat -p 9000:8080 -v &#x2F;usr&#x2F;local&#x2F;mytomcat&#x2F;webapps:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps tomcat 属性解释： -di：创建守护式容器 –name：容器名字 -p：端口映射 -v：目录挂载（映射） 注意 创建容器的时候如出现ipv4的警告信息： 修改配置文件： 1vi &#x2F;etc&#x2F;sysctl.conf 在这文件上添加： 1net.ipv4.ip_forward&#x3D;1 重启网络： 1systemctl restart network 查看一下容器列表： 1docker ps 创建成功","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"},{"name":"Tomcat","slug":"容器引擎/Tomcat","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/Tomcat/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker部署mysql Navicat远程连接","slug":"Docker3","date":"2020-02-26T10:53:17.000Z","updated":"2020-02-26T12:01:13.768Z","comments":true,"path":"2020/02/26/Docker3/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker3/","excerpt":"","text":"拉取Mysql5.7镜像 这里拉取的Mysql版本是5.7版本 这里不再作搜索，直接拉取： 1docker pull centos&#x2F;mysql-57-centos7 查看镜像列表： 1docker images -----------------------------------------拉取成功------------------------------------------- 创建并启动Mysql守护式容器 1docker run -di --name&#x3D;mysql5.7 -p 4100:3306 -e MYSQL_ROOT_PASSWORD&#x3D;root centos&#x2F;mysql-57-centos7 -di：守护式容器 –name：容器名称 -p：端口映射，前面的是宿主机，后面是容器的端口 -e：设置密码 centos/mysql-57-centos7：基于哪个镜像创建 镜像创建成功，进入该容器，输入用户名，密码不用输直接回车（我也不是很清楚为什么）： 1docker exec -it mysql5.7 &#x2F;bin&#x2F;bash 想要让外部工具连接Mysql容器，需要给用户权限： 1grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; ; 等待Query OK后，再刷新权限： 1flush privileges; 使用Navicat12工具测试连接 打开软件，点击左上角的连接，选择Mysql -连接名：随意 -主机：宿主机的IP地址 -密码：你创建容器时设置的密码 输入之后点击测试连接： 提示连接成功","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"},{"name":"MySQL","slug":"容器引擎/MySQL","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/MySQL/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker基础知识之镜像与容器","slug":"Docker2","date":"2020-02-26T02:26:40.000Z","updated":"2020-02-27T04:10:33.214Z","comments":true,"path":"2020/02/26/Docker2/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker2/","excerpt":"","text":"废话不多说，前提条件是你的电脑已安装Docker和完成了基本的配置，还没有的话开车送你去Docker基础知识 Docker镜像 容器的运行是建立在镜像基础之上，当然前提是docker服务已启动。 先用 查看镜像 的命令查看一下本机有什么镜像，不出意外应该啥也没有： 1docker images 镜像没有没关系，从共有仓库 拉取镜像 下来就行了，先来搜索你需要拉取的镜像，比如我们想搜索一个centos7的镜像： 1docker search +你要搜索的镜像名称(如：centos7) 搜索出来的结果： 搜索到之后就拉取我们需要的镜像，比如我们拉取一个centos7镜像： 1docker pull centos:7(镜像的名字:版本号)&#x2F;(若不指定版本号，默认拉取最新版本) 过了一小会之后就会提示 Pull complete，说明拉取成功。 这时候我们再回头使用查看镜像的命令就会看到centos7的镜像了： 镜像可以拉取当然也可以删除： 1docker rmi centos(要删除的镜像名或者镜像id) 或者哪天不开心想把全部镜像删了： 1docker rmi &#96;docker images -q&#96; Docker容器 首先我们要知道docker容器分为两种，一种是 交互式容器，一种是 守护式容器，实际开发中一般采用守护式容器。 两者本质区别 交互式容器随容器的创建、启动而启动，随容器的退出而关闭。 守护式容器随容器的创建、启动而启动，但退出容器后，容器依然在后台运行。 上面我们已经拉取了centos7镜像，下面我们先了解一下创建容器的相关命令属性： 属性 说明 -i 表示运行 -t 表示容器启动后会进入其命令行，加入这两个参数后，容器创建就能登录进去，即分配一个伪终端 –name 为创建容器的名字 -v 表示目录挂载、映射关系 -d 在run后面加上-d参数，则会创建一个守护式容器在后台运行 -p 表示端口映射 -e 表示添加环境变量 查看容器命令（只能查出正在运行的容器）： 1docker ps 查看全部容器命令： 1docker ps -a 查看容器的IP地址： 1docker inspect 容器名字或id 创建一个交互式容器： 1docker run -it --name&#x3D;mycentos7 centos:7 &#x2F;bin&#x2F;bash 执行后会自动进入我们所创建好的容器—mycentos7，使用 ll 命令，然后退出就会回到本机： 创建一个守护式容器： 1docker run -di --name&#x3D;mycentos2 centos:7 创建成功后查看一下容器列表，发现已经在后台运行了： 下面进入该容器看看（exec表示进入的意思）： 1docker exec -it mycentos2 &#x2F;bin&#x2F;bash 可以看出来和交互式容器没什么区别，当我们执行 exit 命令退出该容器后，再查看一下容器列表，发现该容器依旧在后台运行，刚才创建的交互式容器可以通过 docker ps -a命令查看。 停止守护式容器运行： 1docker stop 容器名称或者id 启动容器： 1docker start 容器名称或者id 目录挂载 将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器 创建映射目录 1mkdir &#x2F;usr&#x2F;local&#x2F;test 创建并启动一个守护式容器并挂载test目录： 1docker run -di -v &#x2F;usr&#x2F;local&#x2F;test:&#x2F;usr&#x2F;local&#x2F;test --name&#x3D;mycentos3 centos:7 查看容器列表： 我们在宿主机的test目录下新建一个文件： 1touch test.txt 然后进入 mycentos3容器： 1docker exec -it mycentos3 &#x2F;bin&#x2F;bash 进入test目录下查看文件信息： 1cd &#x2F;usr&#x2F;local&#x2F;test 发现在宿主机创建的test.txt文件也同样被创建在容器中挂载的目录下。 删除容器 1docker rm 容器名称 (注意，正在运行中的容器是无法删除的)","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker基础知识","slug":"Docker1","date":"2020-02-25T07:46:30.000Z","updated":"2020-02-26T09:33:27.998Z","comments":true,"path":"2020/02/25/Docker1/","link":"","permalink":"http://ctrl98.github.io/2020/02/25/Docker1/","excerpt":"","text":"Docker 什么是Docker 百度百科：Docker容器是一个应用容器引擎， 让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 linux 或 Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 说白了就是把应用（项目）部署到Docker容器中运行，就好像放在真实的物理机上运行一样，不用担心开发环境和生产环境的不一致。 为什么要使用Docker Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多 。 性能很高 ， 系统的开销尽量小 。 环境一致，让开发人员专注于开发。 应用迁移更便捷。 应用更好维护。 应用场景 web应用的自动打包和发布 自动化测试 可持续集成 安装各种组件 Docker的组成部分 Docker客户端：个人电脑安装的docker软件、用来连接操作docker。 Docker守护进程：例如有容器A、镜像1 （容器时基于镜像来运行的,镜像相当于类，容器则是类的实例）。 Docker镜像：从docker仓库中拉去过来，而docker仓库又分共有(docker hub)和私有仓库。 以下以 centOS7 系统为基础环境讲述 卸载旧的版本 如果你的系统中已经有旧版本，那么就卸载他吧， 较旧的 Docker 版本称为 docker 或 docker-engine，卸载后记得要删除相关依赖项。 更新 yum 源： 1sudo yum update 查看已安装软件是否有Docker： 1yum list installed 或者直接查看有没有安装Docker： 1yum list installed | grep docker 如果有的话卸载及相关依赖： 1yum -y remove docker.x86_64#软件名看你自己的 安装Docker社区版(个人和中小型企业基本够用) 安装先安装需要的软件包： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源： 1sudo yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo 如果返回结果如下图表明设置成功： 安装docker： 1sudo yum install -y docker-ce 如果返回结果如下图表明安装成功： 查看docker安装版本： 1docker -v 配置Docker镜像源 创建文件夹： 1mkdir &#x2F;etc&#x2F;docker 使用一下命令编辑内容并创建文件—daemon.json 1cd &#x2F;etc&#x2F;docker 1vi daemon.json 文件内容为： 1&#123;&quot;registry-mirrors&quot;:[&quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;]&#125; 镜像也可以用自己的阿里云镜像加速(建议) 编辑完后，按 Esc键，然后按 :，输入 wq，保存文件并退出。 在/etc/docker目录下使用 ll命令查看文件是否创建成功？ Docker基础命令 下面我们来了解一下docker的基础命令 首先是启动docker服务： 1systemctl start docker 停止docker服务： 1systemctl stop docker 查看docker当前状态： 1systemctl status docker 重启docker服务： 1systemctl restart docker 把docker服务设置成开机自动启动： 1systemctl enable docker 到这里说明你已经距离入门还有一大段距离~~~干巴爹斯！！！！","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"第一篇博客文章","slug":"First-Blog","date":"2020-02-25T06:41:43.000Z","updated":"2020-02-26T09:38:25.146Z","comments":true,"path":"2020/02/25/First-Blog/","link":"","permalink":"http://ctrl98.github.io/2020/02/25/First-Blog/","excerpt":"","text":"关于 其实很早就想着有一个属于自己的博客网站，来记录一下自己的学习过程和生活琐事，把自己学习到的知识写下来，算是给自己的一个总结和交代。然后也可以把自己生活上遇到的愉快的、难忘的或是不愉快的事情记录下来，以后当自己翻看自己写过的记录过的东西，也不失为一份回忆。","categories":[{"name":"生活","slug":"生活","permalink":"http://ctrl98.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"个人","slug":"个人","permalink":"http://ctrl98.github.io/tags/%E4%B8%AA%E4%BA%BA/"}]}]}