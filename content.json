{"meta":{"title":"Lee's Notes","subtitle":"","description":"","author":"unknown","url":"http://ctrl98.github.io","root":"/"},"pages":[{"title":"tags","date":"2020-02-25T04:55:08.804Z","updated":"2020-02-25T04:55:08.804Z","comments":true,"path":"tags/index.html","permalink":"http://ctrl98.github.io/tags/index.html","excerpt":"","text":""},{"title":"About","date":"2020-03-09T06:03:39.247Z","updated":"2020-03-09T06:03:39.247Z","comments":true,"path":"about/index.html","permalink":"http://ctrl98.github.io/about/index.html","excerpt":"","text":""},{"title":"All categories","date":"2020-02-25T04:47:45.380Z","updated":"2020-02-25T04:47:45.380Z","comments":true,"path":"categories/index.html","permalink":"http://ctrl98.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis 持久化方式","slug":"Redis4","date":"2020-03-25T10:36:33.000Z","updated":"2020-03-25T11:20:24.571Z","comments":true,"path":"2020/03/25/Redis4/","link":"","permalink":"http://ctrl98.github.io/2020/03/25/Redis4/","excerpt":"","text":"持久化方式之RDB RDB（快照）持久化：保存某个时间点的全量数据快照 我们以window为例，查看redis的配置文件信息 redis.window.conf 文件。 RDB配置 搜索查找关键词 save 查看相关快照策略： save 上面的 900 表示900秒后，会进行一次快照备份。 如果写入数大于10，就会在300秒进行快照备份，以此类推。 stop-writes-on-bgsave-error 该配置默认是 yes 开启，表示备份出错的时候，主进程就拒绝写入操作，这样做是为了保护数据持久化的一致性 rdbcompression 该配置默认开启，备份的时候将rdb文件压缩后再作保存。 如果禁用RDB配置，只需在图一的 save 后面添加： 1save &quot;&quot; 在与配置文件的目录下，你会发现有一个叫 dump.rdb 的文件，这个就是用来储存数据的，里面都是乱码。 手动触发RDB操作 1、通过 save 命令：阻塞Redis的服务进程，知道RDB文件被创建完毕。 2、通过 BGSAVE 命令：Fork出一个子进程来创建RDB文件，不阻塞服务器进程。 把原来的dump.rdb 的文件删除，连接redis的客户端，执行 save 命令，客户端处于卡顿状态，隔了一会就会返回 ok，再次查看文件列表，会发现多出一个 dump.rdb 的文件 再次把dump.rdb 的文件删除，执行 lastsave ，他会返回一串数字，就是上次执行save命令的时间。执行 bgsave 命令，客户端会立马返回 saving started，并没有卡顿。 自动触发RDB持久化 根据redis.conf配置里的 SAVE m n定时触发（用的是BGSAVE） 主从复制时，主节点自动触发 执行Debug Reload 执行ShutDown且没有开启AOF持久化 持久化方式之AOF AOF（Append-Only-File）持久化：保存写状态 记录下除了查询以外的所有变更数据库状态的指令 以append的形式追加到AOF文件中（增量） 配置 该方式默认是关闭的，找到配置文件的 appendonly 属性，把 no 改成 yes 即生效。 上图中，表示每一秒会把redis的数据内容写入aof文件，改完后重启服务。 RDB和AOF的优缺点 RDB 优点：全量数据快照，文件小，恢复快 缺点：无法保证最近一次快照之后的数据 AOF 优点：可读性高，适合保存增量数据，数据不易丢失 缺点：文件体积大，恢复时间长 RDB-AOF混合持久化方式 redis4.0后退出的方式，并且作为默认的方式，结合了两种方式的优点。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Java 多线程与并发基础原理一","slug":"Java多线程与并发1","date":"2020-03-24T02:33:16.000Z","updated":"2020-03-24T08:08:03.670Z","comments":true,"path":"2020/03/24/Java多线程与并发1/","link":"","permalink":"http://ctrl98.github.io/2020/03/24/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%911/","excerpt":"","text":"进程与线程的区别 注意：Oracle官方公布将支持jdk8版本到2025年、支持jdk11版本到2026年，一般不用jdk9或者10，因为官方对其支持周期时间短。 定义 进程 每个进程对应一个程序，每个进程对应一定的内存地址空间，并且只能使用它自己的内存空间，各个进程间互不干扰，并且保存了每个进程的运行状态，为进程切换提供可能，比如电脑运行多个软件且来换切换应用。 进程让操作系统的并发成为了可能，虽然并发从宏观上看，由多个任务在执行，但是事实上对于单核CPU机器来讲，任意一个时刻，只能有一个任务在占用CPU资源。而让用户看起来像同一时刻并发执行多个任务的原因是单核CPU分配给单一任务的时间片很短，切换的频次高，造成了并发执行的假象。 线程 随着电脑的普及，人们对实时性的要求越来越高，因为一个进程在一定的时间内只做一件事情，如果一个进程有多个子任务，只能逐个地去执行这些子任务，而子任务往往不存在顺序上的依赖，所以是可以并发执行的。所以人们就发明了线程，让每个线程去执行每个子任务，这样一个进程就包括了多个线程，每个线程负责每一个独立的子任务，力求达到实时性的效果。线程让进程的内部并发成为可能。 区别 进程是资源分配的最小单位，线程是CPU调度的最先单位 进程有独立的地址空间，相互不影响，线程没有 线程属于某个进程，共享其资源 Thread的start方法和run方法的区别 在main函数主线程中创建一个Thread对象，并编写run方法： 12345678910111213141516public class ThreadTest&#123; private static void attack()&#123; System.out.println(\"正在运行中----\"); System.out.println(\"current Thread is \" + Thread.currentThread().getName()); &#125; public static void main(String[] args)&#123; Thread t = new Thread()&#123; public void run()&#123; attack(); &#125; &#125;; System.out.println(\"current main Thread is \" + Thread.currentThread().getName()); t.run(); &#125;&#125; 执行后结果可发现： 123current main Thread is main正在运行中----current Thread is main 线程调用run方法，只会在主线程中上执行该方法，并不会创建新的线程。 当线程对象调用start方法时： 12345678910111213141516public class ThreadTest&#123; private static void attack()&#123; System.out.println(\"正在运行中----\"); System.out.println(\"current Thread is \" + Thread.currentThread().getName()); &#125; public static void main(String[] args)&#123; Thread t = new Thread()&#123; public void run()&#123; attack(); &#125; &#125;; System.out.println(\"current main Thread is \" + Thread.currentThread().getName()); t.start(); &#125;&#125; 执行后结果可发现： 123current main Thread is main正在运行中----current Thread is Thread-0 线程调用start方法，会在主线程中创建新的线程去执行Thread的run。 查看start的源码方法，在jdk中发现，是jvm的jvm_startThread方法。 Thread和Runnable是什么关系 实际上，Thread是一个类，而Runnable是一个接口，两个都可以创建新的线程。 我们用Thread来创建一个线程来看看： 12345678910111213141516public class MyThread &#123; public static void main(String[] args) &#123; ThreadA threadA = new ThreadA(); threadA.start(); &#125;&#125;class ThreadA extends Thread &#123; @Override public void run() &#123; System.out.println(\"run is running\"); super.run(); &#125;&#125; ThreadA类继承Thread类，并覆写其run方法，在主线程上开启新的线程。 我们看看Thread类的源码发现： 12publicclass Thread implements Runnable Thread类是通过实现Runnable接口来重写run方法，然后Thread本身就包含很多方法。 我们用Runnable来创建新线程看看： 123456789101112131415161718public class MyRunnable &#123; public static void main(String[] args) &#123; ThreadB threadB = new ThreadB(); Thread thread = new Thread(threadB); thread.start(); &#125;&#125;class ThreadB implements Runnable &#123; @Override public void run() &#123; System.out.println(\"runnable is running\"); &#125;&#125; ThreadB类实现Runnable接口并重写其run方法，然后通过Thread类中的 Thread(Runnable target) 构造方法传入一个Runnable对象来创建线程。 关系：Thread是实现Runnable接口的类，为run方法提供多线程 线程的状态 五个状态 新建（new）：创建后尚未启动的线程 就绪（Runnable）：调用start方法后，等待获取CPU的使用权 运行（Running）：成功获取CPU使用权 阻塞（Blocked）：被人为挂起或耗时处理进入阻塞，当阻塞消除后进入就绪状态 结束（Termeinated）：调用了stop()方法或者run方法执行完毕 sleep和wait的区别 基本差别： sleep是Thread类的方法，wait是Object类中定义的方法 sleep方法可以在任何地方使用 wait方法只能在synchronized方法或synchronized块中使用 wait方法如不传参数，会进入无限期等待状态 最主要的本质区别： Thread.sleep只会让出CPU，不会导致锁行为的改变 Object.wait不仅让出CPU，还会释放已经占有的同步资源锁 下面举一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.thread;public class WaitSleepDemo &#123; public static void main(String[] args) &#123; final Object lock = new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"thread a is waiting to get lock\"); synchronized (lock) &#123; try &#123; System.out.println(\"thread a get lock\"); Thread.sleep(20); System.out.println(\"thread a do wait method\"); lock.wait(1000); System.out.println(\"thread a is done\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); //为了确保两个线程按顺序执行，让主线程休眠10毫秒 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"thread b is waiting to get lock\"); synchronized (lock) &#123; try &#123; System.out.println(\"thread b get lock\"); System.out.println(\"thread b is sleeping 10ms\"); Thread.sleep(10); System.out.println(\"thread b is done\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 打印的结果为： 12345678thread a is waiting to get lockthread a get lockthread b is waiting to get lockthread a do wait methodthread b get lockthread b is sleeping 10msthread b is donethread a is done 说明： 1、当创建并执行线程a时，线程a执行run方法，打印 thread a is waiting to get lock ，获取锁后打印 thread a get lock 2、线程a调用sleep方法让出CPU使用权，此时线程b被创建并且执行，线程b执行run方法打印 thread b is waiting to get lock，由于线程a调用的是sleep方法，没有释放锁，线程b获取不了锁，因此线程b进入阻塞 3、线程a获得CPU使用权，打印 thread a do wait method，调用Object对象的wait方法后，线程a让出CPU使用权并且释放锁 4、此时CPU执行线程b，线程b获取锁后打印 thread b get lock ，接着打印 thread b is sleeping 10ms，进入休眠状态，让出CPU使用权，注意此时也没有释放锁，所以线程a还是处于阻塞状态，线程b再获得使用权，打印 thread b is done ，线程b执行结束后释放锁，紧接着线程a才再次获得锁，打印出 thread a is done。 notify和notifyall的区别 notify是Object类中的定义一个方法，用于唤醒某个处于无限期等待的线程。 修改上面的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.thread;public class WaitSleepDemo &#123; public static void main(String[] args) &#123; final Object lock &#x3D; new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;thread a is waiting to get lock&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;thread a get lock&quot;); Thread.sleep(20); System.out.println(&quot;thread a do wait method&quot;); lock.wait(); System.out.println(&quot;thread a is done&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#x2F;&#x2F;为了确保两个线程按顺序执行，让主线程休眠10毫秒 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;thread b is waiting to get lock&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;thread b get lock&quot;); System.out.println(&quot;thread b is sleeping 10ms&quot;); Thread.sleep(10); System.out.println(&quot;thread b is done&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 主要是把 wait 方法的参数去掉，再次执行，会发现线程b执行完毕后，线程a一直处于无限等待中，需要把它唤醒才能接着执行线程a剩下的代码，在线程b执行结束后调用notify或者是notifyAll方法： 1lock.notify(); 执行后发现程序都执行完毕了，说明唤醒成功。这两个方法有什么不同呢？ 区别 先了解两个概念： 锁池EntryList 等待池WaitSet notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁 notify只会随机选取一个处于等待池的线程进入锁池去竞争获取锁 yield函数 概念 当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意让出CPU使用权的暗示，但是线程调度器可能会忽视这个暗示。 下面举个例子： 12345678910111213141516171819202122232425package org.thread;public class YieldDemo &#123; public static void main(String[] args) &#123; Runnable yieldTask = new Runnable() &#123; @Override public void run() &#123; for (int i = 1; i &lt;= 10; i++) &#123; System.out.println(Thread.currentThread().getName() + i); if (i == 5) &#123; Thread.yield(); &#125; &#125; &#125; &#125;; Thread t1 = new Thread(yieldTask,\"Thread-A \"); Thread t2 = new Thread(yieldTask,\"Thread-B \"); t1.start(); t2.start(); &#125;&#125; 从打印的内容来看，无论哪个线程打印到5的时候，该线程时随机让出CPU的使用权的，并不是每次都会让出。 interrupt函数 如何去中断线程 已经被抛弃的方法： 通过调用stop方法停止线程，不安全且暴力。 通过调用suspend方法停止线程 通过调用resume方法停止线程 目前使用的方法： 调用interrupt()方法，通知线程应该中断。 如果线程处于被阻塞状态，那么该线程将立即退出被阻塞状态，并且抛出一个InterruptedException异常 如果线程处于正常活动状态，那么会将该线程的中断标志设置为true，被设置中断标志的线程将继续正常运行，不受影响。 需要被调用的线程配合中断 在正常运行任务时，经常检查本线程的中断标志，如果时true，则立即自行停止线程。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://ctrl98.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java多线程","slug":"Java多线程","permalink":"http://ctrl98.github.io/tags/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"http://ctrl98.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Spring Cloud Alibaba 异步通信","slug":"Spring-Cloud-Alibaba4","date":"2020-03-15T06:48:20.000Z","updated":"2020-03-16T10:45:33.101Z","comments":true,"path":"2020/03/15/Spring-Cloud-Alibaba4/","link":"","permalink":"http://ctrl98.github.io/2020/03/15/Spring-Cloud-Alibaba4/","excerpt":"","text":"消息队列的流派 什么是 MQ Message Queue（MQ），消息队列中间件。很多人都说：MQ 通过将消息的发送和接收分离来实现应用程序的异步和解偶，这个给人的直觉是——MQ 是异步的，用来解耦的，但是这个只是 MQ 的效果而不是目的。MQ 真正的目的是为了通讯，屏蔽底层复杂的通讯协议，定义了一套应用层的、更加简单的通讯协议。一个分布式系统中两个模块之间通讯要么是 HTTP，要么是自己开发的 TCP，但是这两种协议其实都是原始的协议。HTTP 协议很难实现两端通讯——模块 A 可以调用 B，B 也可以主动调用 A，如果要做到这个两端都要背上 WebServer，而且还不支持长连接（HTTP 2.0 的库根本找不到）。TCP 就更加原始了，粘包、心跳、私有的协议，想一想头皮就发麻。MQ 所要做的就是在这些协议之上构建一个简单的“协议”——生产者/消费者模型。MQ 带给我的“协议”不是具体的通讯协议，而是更高层次通讯模型。它定义了两个对象——发送数据的叫生产者；接收数据的叫消费者， 提供一个 SDK 让我们可以定义自己的生产者和消费者实现消息通讯而无视底层通讯协议。 有 Broker 的 MQ 这个流派通常有一台服务器作为 Broker，所有的消息都通过它中转。生产者把消息发送给它就结束自己的任务了，Broker 则把消息主动推送给消费者（或者消费者主动轮询） 重 Topic kafka、JMS（ActiveMQ）就属于这个流派，生产者会发送 key 和数据到 Broker，由 Broker 比较 key 之后决定给哪个消费者。这种模式是我们最常见的模式，是我们对 MQ 最多的印象。在这种模式下一个 topic 往往是一个比较大的概念，甚至一个系统中就可能只有一个 topic，topic 某种意义上就是 queue，生产者发送 key 相当于说：“hi，把数据放到 key 的队列中” 。 如上图所示，Broker 定义了三个队列，key1，key2，key3，生产者发送数据的时候会发送 key1 和 data，Broker 在推送数据的时候则推送 data（也可能把 key 带上）。 虽然架构一样但是 kafka 的性能要比 jms 的性能不知道高到多少倍，所以基本这种类型的 MQ 只有 kafka 一种备选方案。如果你需要一条暴力的数据流（在乎性能而非灵活性）那么 kafka 是最好的选择。 轻 Topic 这种的代表是 RabbitMQ（或者说是 AMQP）。生产者发送 key 和数据，消费者定义订阅的队列，Broker 收到数据之后会通过一定的逻辑计算出 key 对应的队列，然后把数据交给队列。 这种模式下解耦了 key 和 queue，在这种架构中 queue 是非常轻量级的（在 RabbitMQ 中它的上限取决于你的内存），消费者关心的只是自己的 queue；生产者不必关心数据最终给谁只要指定 key 就行了，中间的那层映射在 AMQP 中叫 exchange（交换机）。 AMQP 中有四种 exchange Direct exchange：key 就等于 queue Fanout exchange：无视 key，给所有的 queue 都来一份 Topic exchange：key 可以用“宽字符”模糊匹配 queue Headers exchange：无视 key，通过查看消息的头部元数据来决定发给那个 queue（AMQP 头部元数据非常丰富而且可以自定义） 这种结构的架构给通讯带来了很大的灵活性，我们能想到的通讯方式都可以用这四种 exchange 表达出来。如果你需要一个企业数据总线（在乎灵活性）那么 RabbitMQ 绝对的值得一用。 无 Broker 的 MQ 无 Broker 的 MQ 的代表是 ZeroMQ。该作者非常睿智，他非常敏锐的意识到——MQ 是更高级的 Socket，它是解决通讯问题的。所以 ZeroMQ 被设计成了一个“库”而不是一个中间件，这种实现也可以达到——没有 Broker 的目的。 节点之间通讯的消息都是发送到彼此的队列中，每个节点都既是生产者又是消费者。ZeroMQ 做的事情就是封装出一套类似于 Socket 的 API 可以完成发送数据，读取数据 ZeroMQ 其实就是一个跨语言的、重量级的 Actor 模型邮箱库。你可以把自己的程序想象成一个 Actor，ZeroMQ 就是提供邮箱功能的库；ZeroMQ 可以实现同一台机器的 RPC 通讯也可以实现不同机器的 TCP、UDP 通讯，如果你需要一个强大的、灵活、野蛮的通讯能力，别犹豫 ZeroMQ。 附：Queue 和 Topic 的区别 Queue： 一个发布者发布消息，下面的接收者按队列顺序接收，比如发布了 10 个消息，两个接收者 A,B 那就是 A,B 总共 会收到 10 条消息，不重复。 Topic： 一个发布者发布消息，有两个接收者 A,B 来订阅，那么发布了 10 条消息，A,B 各收到 10 条消息。 类型 Topic Queue 概要 Publish Subscribe Messaging 发布订阅消息 Point-to-Point 点对点 有无状态 Topic 数据默认不落地，是无状态的。 Queue 数据默认会在 MQ 服务器上以文件形式保存，比如 ActiveMQ 一般保存在 $AMQ_HOME\\data\\kr-store\\data 下面。也可以配置成 DB 存储。 完整性保障 并不保证 Publisher 发布的每条数据，Subscriber 都能接受到。 Queue 保证每条数据都能被 Receiver 接收。 消息是否会丢失 一般来说 Publisher 发布消息到某一个 Topic 时，只有正在监听该 Topic 地址的 Sub 能够接收到消息；如果没有 Sub 在监听，该 Topic 就丢失了。 Sender 发送消息到目标 Queue，Receiver 可以异步接收这个 Queue 上的消息。Queue 上的消息如果暂时没有 Receiver 来取，也不会丢失。 消息发布接收策略 一对多的消息发布接收策略，监听同一个 Topic 地址的多个 Sub 都能收到 Publisher 发送的消息。Sub 接收完通知 MQ 服务器 一对一的消息发布接收策略，一个 Sender 发送的消息，只能有一个 Receiver 接收。Receiver 接收完后，通知 MQ 服务器已接收，MQ 服务器对 Queue 里的消息采取删除或其他操作。 RocketMQ 概述 阿里巴巴写的一个MQ，他的前身是activeMQ，RocketMQ是Apache的一个项目，但是写代码的是阿里巴巴。消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下优势： 削峰填谷： 主要解决瞬时写压力大于应用服务能力导致消息丢失、系统奔溃等问题 系统解耦： 解决不同重要程度、不同能力级别系统之间依赖导致一死全死 提升性能： 当存在一对多调用时，可以发一条消息给消息系统，让消息系统通知相关系统 蓄流压测： 线上有些链路不好压测，可以通过堆积一定量消息再放开来压测 RocketMQ Apache Alibaba RocketMQ 是一个消息中间件。消息中间件中有两个角色：消息生产者和消息消费者。RocketMQ 里同样有这两个概念，消息生产者负责创建消息并发送到 RocketMQ 服务器，RocketMQ 服务器会将消息持久化到磁盘，消息消费者从 RocketMQ 服务器拉取消息并提交给应用消费。 RocketMQ 特点 RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： 支持严格的消息顺序 支持 Topic 与 Queue 两种模式 亿级消息堆积能力 比较友好的分布式特性 同时支持 Push 与 Pull 方式消费消息 历经多次天猫双十一海量消息考验 RocketMQ 优势 目前主流的 MQ 主要是 RocketMQ、kafka、RabbitMQ，其主要优势有： 支持事务型消息（消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 不支持） 支持结合 RocketMQ 的多个系统之间数据最终一致性（多方事务，二方事务是前提） 支持 18 个级别的延迟消息（RabbitMQ 和 Kafka 不支持） 支持指定次数和时间间隔的失败消息重发（Kafka 不支持，RabbitMQ 需要手动确认） 支持 Consumer 端 Tag 过滤，减少不必要的网络传输（RabbitMQ 和 Kafka 不支持） 支持重复消费（RabbitMQ 不支持，Kafka 支持） 消息队列对比参照表 基于 Docker 安装 RocketMQ rocketmq需要三个容器，server、broker和console docker-compose启动 简单粗暴，如果你的虚拟机安装了docker-compose，那就很方便了，直接构建服务和容器。 docker-compose.yaml 使用docker-compose来直接构建三个所需容器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455version: '3.5'services: rmqnamesrv: image: foxiswho/rocketmq:server container_name: rmqnamesrv ports: - 9876:9876 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store networks: rmq: aliases: - rmqnamesrv rmqbroker: image: foxiswho/rocketmq:broker container_name: rmqbroker ports: - 10909:10909 - 10911:10911 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store - ./data/brokerconf/broker.conf:/etc/rocketmq/broker.conf environment: NAMESRV_ADDR: \"rmqnamesrv:9876\" JAVA_OPTS: \" -Duser.home=/opt\" JAVA_OPT_EXT: \"-server -Xms128m -Xmx128m -Xmn128m\" command: mqbroker -c /etc/rocketmq/broker.conf depends_on: - rmqnamesrv networks: rmq: aliases: - rmqbroker rmqconsole: image: styletang/rocketmq-console-ng container_name: rmqconsole ports: - 8080:8080 environment: JAVA_OPTS: \"-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" depends_on: - rmqnamesrv networks: rmq: aliases: - rmqconsolenetworks: rmq: name: rmq driver: bridge broker.conf RocketMQ Broker 需要一个配置文件，按照上面的 Compose 配置，我们需要在 ./data/brokerconf/ 目录下创建一个名为 broker.conf 的配置文件，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# 所属集群名字brokerClusterName&#x3D;DefaultCluster# broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a,# 在 broker-b.properties 使用: broker-bbrokerName&#x3D;broker-a# 0 表示 Master，&gt; 0 表示 SlavebrokerId&#x3D;0# nameServer地址，分号分割# namesrvAddr&#x3D;rocketmq-nameserver1:9876;rocketmq-nameserver2:9876# 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;192.168.0.120:10909&gt; failed# 解决方式1 加上一句 producer.setVipChannelEnabled(false);，解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP# brokerIP1&#x3D;192.168.0.253# 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums&#x3D;4# 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，falseautoCreateTopicEnable&#x3D;true# 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup&#x3D;true# Broker 对外服务的监听端口listenPort&#x3D;10911# 删除文件时间点，默认凌晨4点deleteWhen&#x3D;04# 文件保留时间，默认48小时fileReservedTime&#x3D;120# commitLog 每个文件的大小默认1GmapedFileSizeCommitLog&#x3D;1073741824# ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整mapedFileSizeConsumeQueue&#x3D;300000# destroyMapedFileIntervalForcibly&#x3D;120000# redeleteHangedFileInterval&#x3D;120000# 检测物理文件磁盘空间diskMaxUsedSpaceRatio&#x3D;88# 存储路径# storePathRootDir&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store# commitLog 存储路径# storePathCommitLog&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;commitlog# 消费队列存储# storePathConsumeQueue&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;consumequeue# 消息索引存储路径# storePathIndex&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;index# checkpoint 文件存储路径# storeCheckpoint&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;checkpoint# abort 文件存储路径# abortFile&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;abort# 限制的消息大小maxMessageSize&#x3D;65536# flushCommitLogLeastPages&#x3D;4# flushConsumeQueueLeastPages&#x3D;2# flushCommitLogThoroughInterval&#x3D;10000# flushConsumeQueueThoroughInterval&#x3D;60000# Broker 的角色# - ASYNC_MASTER 异步复制Master# - SYNC_MASTER 同步双写Master# - SLAVEbrokerRole&#x3D;ASYNC_MASTER# 刷盘方式# - ASYNC_FLUSH 异步刷盘# - SYNC_FLUSH 同步刷盘flushDiskType&#x3D;ASYNC_FLUSH# 发消息线程池数量# sendMessageThreadPoolNums&#x3D;128# 拉消息线程池数量# pullMessageThreadPoolNums&#x3D;128 直接访问 http://rmqIP:8080 登入控制台，即可看到控制台界面。 镜像拉取启动 这里因为本虚拟机无法安装 docker-compose，所以采用一个个镜像拉取启动。 使用centos7查找镜像： 1docker search rocketmq 这里选取 foxiswho/rocketmq，查看该镜像的所有版本： 123curl https:&#x2F;&#x2F;registry.hub.docker.com&#x2F;v1&#x2F;repositories&#x2F;foxiswho&#x2F;rocketmq&#x2F;tags\\| tr -d &#39;[\\[\\]&quot; ]&#39; | tr &#39;&#125;&#39; &#39;\\n&#39;\\| awk -F: -v image&#x3D;&#39;foxiswho&#x2F;rocketmq&#39; &#39;&#123;if(NR!&#x3D;NF &amp;&amp; $3 !&#x3D; &quot;&quot;)&#123;printf(&quot;%s:%s\\n&quot;,image,$3)&#125;&#125;&#39; 如想查看其他镜像的所包含的所有版本，把’foxiswho/rocketmq’换成你想查的镜像名称即可。 我们需要该镜像里的 foxiswho/rocketmq:server-4.5.1 和 foxiswho/rocketmq:broker-4.5.1 两版本。 启动Server 这里不用拉取镜像，直接创建server容器： 1docker run -d -p 9876:9876 --name rmqserver foxiswho&#x2F;rocketmq:server-4.5.1 启动Broker 在以下目录创建一个配置文件目录进行文件挂载： 12cd &#x2F;usr&#x2F;localmkdir conf 构建broker容器： 12345docker run -di -p 10911:10911 -p 10909:10909\\ --name rmqbroker --link rmqserver:namesrv\\ -e &quot;NAMESRV_ADDR&#x3D;namesrv:9876&quot; -e &quot;JAVA_OPTS&#x3D;-Duser.home&#x3D;&#x2F;opt&quot;\\ -e &quot;JAVA_OPT_EXT&#x3D;-server -Xms128m -Xmx128m&quot;\\ foxiswho&#x2F;rocketmq:broker-4.5.1 其中 /conf/broker.conf.old为容器中的配置文件目录，把该文件内容换成上面broker.conf的配置文件即可。 构建console控制台界面 1234docker run -di --name rmqconsole -p 8180:8080 --link rmqserver:namesrv\\ -e &quot;JAVA_OPTS&#x3D;-Drocketmq.namesrv.addr&#x3D;namesrv:9876\\ -Dcom.rocketmq.sendMessageWithVIPChannel&#x3D;false&quot;\\ -t styletang&#x2F;rocketmq-console-ng 访问：宿主机ip:8180 即可访问。 RocketMQ 生产者 概述 RocketMQ 是一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 整个项目都基于 Spring Cloud，故采用 Spring Cloud Stream 完成一次发布和订阅。 官方教程 Spring Cloud Stream Spring Cloud Stream 是一个用于构建基于消息的微服务应用框架。它基于 Spring Boot 来创建具有生产级别的单机 Spring 应用，并且使用 Spring Integration 与 Broker 进行连接。 Spring Cloud Stream 提供了消息中间件配置的统一抽象，推出了 publish-subscribe、consumer groups、partition 这些统一的概念。 Spring Cloud Stream 内部有两个概念： Binder： 跟外部消息中间件集成的组件，用来创建 Binding，各消息中间件都有自己的 Binder 实现。 Binding： 包括 Input Binding 和 Output Binding。 Binding 在消息中间件与应用程序提供的 Provider 和 Consumer 之间提供了一个桥梁，实现了开发者只需使用应用程序的 Provider 或 Consumer 生产或消费数据即可，屏蔽了开发者与底层消息中间件的接触。 解决连接超时问题 在上面部署broker的时候，此时 RocketMQ Broker 暴露的地址和端口(10909，10911)是基于容器的，会导致我们开发机无法连接，从而引发 org.apache.rocketmq.remoting.exception.RemotingTooMuchRequestException: sendDefaultImpl call timeout 异常 注意下图中的 IP 地址，这个是容器的 IP，开发机与容器不在一个局域网所以无法连接。 解决方案是在 broker.conf 配置文件中增加 brokerIP1=宿主机IP 即可。 1docker exec -it rmqbroker &#x2F;bin&#x2F;bash 找到broker.conf文件： 1cd &#x2F;etc&#x2F;rocketmq 在broker.conf文件添加以下内容： 1brokerIP1&#x3D;宿主机ip 创建rocketmq服务提供者 在项目中创建一个名为spring-cloud-alibaba-rocketmq-provider的module，pom文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-rocketmq-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-rocketmq-provider&lt;/name&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.rocketmq.provider.RocketMQProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-stream-rocketmq 依赖。 创建配置文件： 12345678910111213spring: cloud: stream: bindings: output: &#123;destination: test-topic, content-type: application/json&#125; rocketmq: binder: namesrv-addr: 宿主机ip:9876 application: name: rockermq-providerserver: port: 9093 创建启动类： 1234567891011121314151617181920212223242526272829303132package org.lee.spring.cloud.alibaba.rocketmq.provider;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.CommandLineRunner;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Source;import org.springframework.messaging.MessageChannel;import org.springframework.messaging.support.MessageBuilder;@SpringBootApplication@EnableBinding(&#123; Source.class &#125;)public class RocketMQProviderApplication implements CommandLineRunner &#123; @Autowired private MessageChannel output; // 获取name为output的binding public static void main(String[] args) &#123; SpringApplication.run(RocketMQProviderApplication.class,args); &#125; /** * 该接口的实现方法在springboot应用启动时自动执行，只用来测试demo使用 * @param args * @throws Exception */ @Override public void run(String... args) throws Exception &#123; output.send(MessageBuilder.withPayload(\"Hello rocketMQ\").build());//发一条消息 &#125;&#125; 注解解析： @EnableBinding：表明是发送信息还是订阅信息 Source.class：发送消息（提供者） Sink.class：订阅消息 启动该服务之后，去网页刷新 ： 宿主机ip:8180 网页，去到主题页面： 发现多一个test-topic的主题 去到消息页面，选择test-topic，就会看到我们刚才发的消息。 RocketMQ 消费者 创建一个名为spring-cloud-alibaba-rocketmq-consumer的module，pom文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-rocketmq-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-rocketmq-consumer&lt;/name&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.rocketmq.consumer.RocketMQConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建启动类 1234567891011121314151617181920package org.lee.spring.cloud.alibaba.rocketmq.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;@SpringBootApplication@EnableBinding(&#123;Sink.class&#125;)public class RocketMQConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RocketMQConsumerApplication.class,args); &#125; @StreamListener(\"input\")//监听名为 input的消息 public void receiveInput1(String receiveMsg) &#123; System.out.println(\"input receive: \" + receiveMsg); &#125;&#125; 配置文件： 12345678910111213spring: cloud: stream: bindings: input: &#123;destination: test-topic, content-type: application/json, group: test-group&#125; rocketmq: binder: namesrv-addr: 宿主机ip:9876 application: name: rockermq-consumerserver: port: 9094 启动该程序，看控制台打印：","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Alibaba 链路追踪","slug":"Spring-Cloud-Alibaba3","date":"2020-03-14T01:46:06.000Z","updated":"2020-03-15T01:49:16.108Z","comments":true,"path":"2020/03/14/Spring-Cloud-Alibaba3/","link":"","permalink":"http://ctrl98.github.io/2020/03/14/Spring-Cloud-Alibaba3/","excerpt":"","text":"链路追踪 什么是链路追踪 微服务架构是通过业务来划分服务的，使用 REST 调用。对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂。 随着服务的越来越多，对调用链的分析会越来越复杂。它们之间的调用关系也许如下： 面对以上情况，我们就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题，这就是所谓的 APM（应用性能管理）。 什么是 SkyWalking 目前主要的一些 APM 工具有: Cat、Zipkin、Pinpoint、SkyWalking；Apache SkyWalking 是观察性分析平台和应用性能管理系统。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 Skywalking Agent： 使用 JavaAgent 做字节码植入，无侵入式的收集，并通过 HTTP 或者 gRPC 方式发送数据到 SkyWalking Collector。 SkyWalking Collector： 链路数据收集器，对 agent 传过来的数据进行整合分析处理并落入相关的数据存储中。 Storage： SkyWalking 的存储，时间更迭，SW 已经开发迭代到了 6.x 版本，在 6.x 版本中支持以 ElasticSearch(支持 6.x)、Mysql、TiDB、H2、作为存储介质进行数据存储。 UI： Web 可视化平台，用来展示落地的数据。 SkyWalking 功能特性 多种监控手段，语言探针和服务网格(Service Mesh) 多语言自动探针，Java，.NET Core 和 Node.JS 轻量高效，不需要大数据 模块化，UI、存储、集群管理多种机制可选 支持告警 优秀的可视化方案 SkyWalking 服务端配置 基于 Docker 安装 ElasticSearch 上面介绍过 SkyWalking 存储方案有多种，官方推荐的方案是 ElasticSearch ，所以我们需要先安装 ElasticSearch。 在虚拟机centOS上进行安装。 这里使用拉取镜像并创建容器的方式进行安装： 拉取es镜像，默认拉取最新版： 1docker pull elasticsearch:7.6.1 创建并运行容器： 1docker run -di --name&#x3D;es7 -p 9200:9200 -p 9300:9300 -e &quot;discovery.type&#x3D;single-node&quot; elasticsearch:7.6.1 进入容器： 1docker exec -it es7 &#x2F;bin&#x2F;bash 修改配置： 12cd configvi elasticsearch.yml 添加修改内容如下： 12network.host: 127.0.0.1 #推荐本机IPhttp.port: 9200 打开浏览器访问： 1虚拟机ip:9200 下载并启动 SkyWalking 官方已经为我们准备好了编译过的服务端版本，下载地址为 http://skywalking.apache.org/downloads/，这里我们需要下载6.x releases 版本 配置 SkyWalking 下载完成后解压缩，进入 apache-skywalking-apm-incubating/config 目录并修改 application.yml 配置文件： 这里需要做三件事： 注释 H2 存储方案 启用 ElasticSearch 存储方案 修改 ElasticSearch 服务器地址 启动 SkyWalking 修改完配置后，进入 apache-skywalking-apm-incubating\\bin 目录，运行 startup.bat 启动服务端 通过浏览器访问 http://localhost:8080 出现如下界面即表示启动成功： SkyWalking 客户端配置 Java Agent 服务器探针 参考官网给出的帮助 Setup java agent，我们需要使用官方提供的探针为我们达到监控的目的，按照实际情况我们需要实现三种部署方式 IDEA 部署探针 Java 启动方式部署探针（我们是 Spring Boot 应用程序，需要使用 java -jar 的方式启动应用） Docker 启动方式部署探针（需要做到一次构建到处运行的持续集成效果，本章节暂不提供解决方案，到后面的实战环节再实现） 探针文件在 apache-skywalking-apm-incubating/agent 目录下： IDEA 部署探针 继续之前的案例项目Spring Cloud Alibaba 微服务框架入门，创建一个名为 hello-spring-cloud-external-skywalking 的目录，并将 agent 整个目录拷贝进来： 修改项目的 VM 运行参数，点击菜单栏中的 Run -&gt; EditConfigurations...，此处我们以 nacos-provider 项目为例，修改参数如下： 123-javaagent:D:\\Workspace\\Others\\hello-spring-cloud-alibaba\\hello-spring-cloud-external-skywalking\\agent\\skywalking-agent.jar-Dskywalking.agent.service_name&#x3D;nacos-provider-Dskywalking.collector.backend_service&#x3D;localhost:11800 -javaagent：用于指定探针路径 -Dskywalking.agent.service_name：用于重写 agent/config/agent.config 配置文件中的服务名 -Dskywalking.collector.backend_service：用于重写 agent/config/agent.config 配置文件中的服务地址 有多少个服务需要跟踪，就配置多少个 Java 启动方式 1java -javaagent:&#x2F;path&#x2F;to&#x2F;skywalking-agent&#x2F;skywalking-agent.jar -Dskywalking.agent.service_name&#x3D;nacos-provider -Dskywalking.collector.backend_service&#x3D;localhost:11800 -jar yourApp.jar 测试监控 启动 nacos-provider 、nacos-consumer-feign、gateway 项目，通过观察日志可以发现，已经成功加载探针。访问之前写好的接口： http://localhost:9000/nacos-consumer-feign/echo/hi?token=123 ，然后回来刷新 SkyWalking Web UI ，你会发现启动的三个服务已经配检测到，至此，表示 SkyWalking 链路追踪配置成功。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Alibaba 服务配置","slug":"Spring-Cloud-Alibaba2","date":"2020-03-13T11:49:38.000Z","updated":"2020-03-13T13:08:28.742Z","comments":true,"path":"2020/03/13/Spring-Cloud-Alibaba2/","link":"","permalink":"http://ctrl98.github.io/2020/03/13/Spring-Cloud-Alibaba2/","excerpt":"","text":"Nacos Config 服务端初始化 分布式配置中心 在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。之前我们写配置文件，改完就要重启服务，要是有100个服务呢？ Nacos Config Nacos 提供用于存储配置和其他元数据的 key/value 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。使用 Spring Cloud Alibaba Nacos Config，您可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置。 Spring Cloud Alibaba Nacos Config 是 Spring Cloud Config Server 和 Client 的替代方案，客户端和服务器上的概念与 Spring Environment 和 PropertySource 有着一致的抽象，在特殊的 bootstrap 阶段，配置被加载到 Spring 环境中。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容。 配置文件优先级： bootstrap.properties—&gt;bootstrap.yml—&gt;application.properties—&gt;application.yml 创建配置文件 需要在 Nacos Server 中创建配置文件，我们依然采用 YAML 的方式部署配置文件，操作流程如下： 浏览器打开 http://localhost:8848/nacos ，访问 Nacos Server 新建配置文件，此处我们以之前创建的 服务提供者Spring Cloud Alibaba 微服务框架入门 项目为例： 注意：Data ID 的默认扩展名为 .properties ，希望使用 YAML 配置，此处必须指明是 .yaml 发布成功后在 “配置列表” 一栏即可看到刚才创建的配置项 Nacos Config 客户端的使用 POM 此处我们以之前创建的服务提供者Spring Cloud Alibaba 微服务框架入门项目为例： 在 pom.xml 中增加 org.springframework.cloud:spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 完整的文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-nacos-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-nacos-provider&lt;/name&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; bootstrap.properties 创建名为 bootstrap.properties 的配置文件并删除之前创建的 application.yml 配置文件，由于已经在服务端配置，此处不再赘述： 123456# 这里的应用名对应 Nacos Config 中的 Data ID，实际应用名称以配置中心的配置为准spring.application.name=nacos-provider-config# 指定查找名为 nacos-provider-config.yaml 的配置文件spring.cloud.nacos.config.file-extension=yaml# Nacos Server 的地址spring.cloud.nacos.config.server-addr=127.0.0.1:8848 注意：在之前的 Spring Cloud Netflix 课程中有提到过 Spring Boot 配置文件的加载顺序，依次为 bootstrap.properties -&gt; bootstrap.yml -&gt; application.properties -&gt; application.yml ，其中 bootstrap.properties 配置为最高优先级 启动应用程序 启动应用后我们可以通过日志看到，已经成功加载到了配置文件： 配置的动态更新 Nacos Config 也支持配置的动态更新，操作流程如下： 修改服务端配置，增加一个 user.name 的属性 修改 Controller ，增加一个请求方法，测试配置更新效果 123456789101112131415161718192021222324252627282930package org.lee.spring.cloud.alibaba.nacos.provider.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosProviderController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(value = \"/echo/&#123;message&#125;\") public String echo(@PathVariable String message) &#123; return \"Hello Nacos Discovery \" + message + \" i am from port \" + port; &#125; // 注入配置文件上下文 @Autowired private ConfigurableApplicationContext applicationContext; // 从上下文中读取配置 @GetMapping(value = \"/hi\") public String sayHi() &#123; return \"Hello \" + applicationContext.getEnvironment().getProperty(\"user.name\"); &#125;&#125; 通过浏览器访问该接口:localhost:8081/hi，浏览器显示： 1Hello kobe 修改服务端配置： 刷新浏览器，浏览器显示 1Hello kobeAndGiGi 注意：你可以使用 spring.cloud.nacos.config.refresh.enabled=false 来关闭动态刷新 Nacos Config 多环境的配置 Spring Boot Profile 我们在做项目开发的时候，生产环境和测试环境的一些配置可能会不一样，有时候一些功能也可能会不一样，所以我们可能会在上线的时候手工修改这些配置信息。但是 Spring 中为我们提供了 Profile 这个功能。我们只需要在启动的时候添加一个虚拟机参数，激活自己环境所要用的 Profile 就可以了。 操作起来很简单，只需要为不同的环境编写专门的配置文件，如：application-dev.yml、application-prod.yml， 启动项目时只需要增加一个命令参数 --spring.profiles.active=环境配置 即可，启动命令如下： 1java -jar spring-cloud-alibaba-nacos-provider-1.0-SNAPSHOT.jar --spring.profiles.active&#x3D;prod Nacos Config Profile spring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataid 为 ${spring.application.name}.${file-extension:properties} 为前缀的基础配置，还加载了 dataid 为 ${spring.application.name}-${profile}.${file-extension:properties} 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过 Spring 提供的 ${spring.profiles.active} 这个配置项来配置。 此处我们以之前创建的服务提供者项目为例： 在 Nacos Server 中增加配置 增加一个名为 nacos-provider-config-prod.yaml 的配置： 注意：此时，我将配置文件中的端口由 8081 -&gt; 8082 在项目中增加配置 增加一个名为 bootstrap-prod.properties 的配置文件，内容如下： 1234spring.profiles.active=prodspring.application.name=nacos-provider-configspring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848 主要增加了 spring.profiles.active=prod 配置，用于指定访问 Nacos Server 中的 nacos-provider-config-prod.yaml 配置 启动应用程序 此时我们有两个配置文件，分别为 bootstrap.properties 和 bootstrap-prod.properties ，我们需要指定启动时加载哪一个配置文件，操作流程如下： 设置需要激活的配置 观察日志，判断是否成功加载配置","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Alibaba 微服务框架入门","slug":"Spring-Cloud-Alibaba1","date":"2020-03-11T07:49:49.000Z","updated":"2020-03-13T11:50:59.041Z","comments":true,"path":"2020/03/11/Spring-Cloud-Alibaba1/","link":"","permalink":"http://ctrl98.github.io/2020/03/11/Spring-Cloud-Alibaba1/","excerpt":"","text":"简介 2018 年 10 月 31 日 ，Spring Cloud Alibaba 正式入驻了 Spring Cloud 官方孵化器，并在 Maven 中央库发布了第一个版本。 Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。 主要功能 服务限流降级：默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 组件 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 服务注册与发现 概述 在 Spring Cloud Netflix 阶段我们采用 Eureka 做作为我们的服务注册与发现服务器，现利用 Spring Cloud Alibaba 提供的 Nacos 组件替代该方案。 什么是 Nacos Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 Nacos基本架构图 下载安装 准备环境 Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行 Nacos，还需要为此配置 Maven 环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+ Maven 3.2.x+ 下载 到Nacos的github项目地址： https://github.com/alibaba/nacos 找到快速开始： 点击 latest stable release 调转到压缩包下载。 选择最新的版本，以linux为内核的系统下载以 tar.gz结尾的，windows就下载 zip 的。 这里以 windows 为例，下载后解压，然后进入 /bin 目录双击 startup.cmd。 看到这个标志说明启动成功！紧接着访问： http://localhost:8848/nacos 创建服务提供者 首先创建Spring Boot父工程 在本地磁盘任意地方创建一个名为 spring_cloud_alibaba 文件夹用来存放项目 用idea软件打开该文件夹，右击项目文件夹，new一个module子项目，名为 spring-cloud-alibaba-dependencies pom.xml文件添加相关依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189&lt;groupId&gt;org.example&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;11&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; parent：继承了 Spring Boot 的 Parent，表示我们是一个 Spring Boot 工程 package：pom，表示该项目仅当做依赖项目，没有具体的实现代码 spring-cloud-alibaba-dependencies：在 properties 配置中预定义了版本号为 0.2.1.RELEASE ，表示我们的 Spring Cloud Alibaba 对应的是 Spring Cloud Finchley 版本 build：配置了项目所需的各种插件 repositories：配置项目下载依赖时的第三方库 这里需要注意的是 Spring Boot和Spring Cloud Alibaba的版本要对应 Spring Boot Spring Cloud Spring Cloud Alibaba 2.1.x Greenwich 0.9.x 2.0.x Finchley 0.2.x 1.5.x Edgware 0.1.x 1.5.x Dalston 0.1.x 接下来创建服务提供者 通过一个简单的示例来感受一下如何将服务注册到 Nacos，其实和 Eureka 没有太大差别。 右击项目，new一个名为 spring-cloud-alibaba-nacos-provider module项目，pom.xml文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-alibaba-nacos-provider&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-alibaba-nacos-provider&lt;/name&gt;&lt;inceptionYear&gt;2018-Now&lt;/inceptionYear&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在该子项目的resourses目录下创建配置文件application.yml： 12345678910111213141516spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 8081management: endpoints: web: exposure: include: \"*\" 在src目录的java下，创建 org.lee.spring.cloud.alibaba.nacos.provider包，再创建启动类： 12345678910111213package org.lee.spring.cloud.alibaba.nacos.provider;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClient//服务注册注解public class NacosProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProviderApplication.class,args); &#125;&#125; 创建controller包，添加controller方法： 1234567891011121314package org.lee.spring.cloud.alibaba.nacos.provider.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosProviderController &#123; @GetMapping(value = \"/echo/&#123;message&#125;\") public String echo(@PathVariable String message) &#123; return \"Hello Nacos Discovery \" + message; &#125;&#125; 启动该子工程，通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现一个服务已经注册在服务中了，服务名为 nacos-provider 这时打开 http://localhost:8081/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery hi 服务的端点检查 spring-cloud-starter-alibaba-nacos-discovery 在实现的时候提供了一个 EndPoint, EndPoint 的访问地址为 http://ip:port/actuator/nacos-discovery。 EndPoint 的信息主要提供了两类: 121、subscribe: 显示了当前有哪些服务订阅者2、NacosDiscoveryProperties: 显示了当前服务实例关于 Nacos 的基础配置 通过浏览器访问 http://localhost:8081/actuator/nacos-discovery 你会在浏览器上看到： 创建服务消费者 服务消费者的创建与服务提供者大同小异，这里采用最原始的一种方式，即显示的使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问。 创建一个工程名为 spring-cloud-alibaba-nacos-consumer 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-alibaba-nacos-provider&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-alibaba-nacos-provider&lt;/name&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 创建配置文件application.yml 12345678910111213141516spring: application: name: nacos-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9091management: endpoints: web: exposure: include: \"*\" 创建启动类 12345678910111213package org.lee.spring.cloud.alibaba.nacos.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class NacosConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerApplication.class,args); &#125;&#125; 创建一个名为 NacosConsumerConfiguration 的 Java 配置类，主要作用是为了注入 RestTemplate 12345678910111213package org.lee.spring.cloud.alibaba.nacos.consumer.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class NacosConsumerConfiguration &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 创建一个名为 NacosConsumerController 测试用的 Controller 123456789101112131415161718192021222324252627282930package org.lee.spring.cloud.alibaba.nacos.consumer.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class NacosConsumerController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private RestTemplate restTemplate; @Value(\"$&#123;spring.application.name&#125;\") private String appName; @GetMapping(value = \"/echo/app/name\") public String echo() &#123; //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 ServiceInstance serviceInstance = loadBalancerClient.choose(\"nacos-provider\"); String url = String.format(\"http://%s:%s/echo/%s\", serviceInstance.getHost(), serviceInstance.getPort(), appName); return restTemplate.getForObject(url, String.class); &#125;&#125; 启动工程 通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer 的服务 这时打开 http://localhost:9091/echo/app/name ，你会在浏览器上看到： 1Hello Nacos Discovery nacos-consumer 服务的端点检查 通过浏览器访问 http://localhost:9091/actuator/nacos-discovery 你会在浏览器上看到同样的json 创建服务消费者（Feign） 概述 Feign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，Nacos 也很好的兼容了 Feign，默认实现了负载均衡的效果 Feign 采用的是基于接口的注解 Feign 整合了 ribbon 创建一个工程名为 spring-cloud-alibaba-nacos-consumer-feign 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-alibaba-nacos-consumer-feign&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-alibaba-nacos-consumer-feign&lt;/name&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.hello.spring.cloud.alibaba.nacos.consumer.feign.NacosConsumerFeignApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-openfeign 依赖 创建项目配置文件application.yml 12345678910111213141516spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9092management: endpoints: web: exposure: include: \"*\" 创建启动类 123456789101112131415package org.lee.spring.cloud.alibaba.nacos.consumer.feign;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class NacosConsumerFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerFeignApplication.class,args); &#125;&#125; 通过 @EnableFeignClients 注解开启 Feign 功能 创建 Feign 接口 1234567891011package org.lee.spring.cloud.alibaba.nacos.consumer.feign.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"nacos-provider\")public interface EchoService &#123; @GetMapping(value = \"/echo/&#123;message&#125;\") String echo(@PathVariable(\"message\") String message);&#125; 通过 @FeignClient(&quot;服务名&quot;) 注解来指定调用哪个服务。 创建controller 123456789101112131415161718package org.lee.spring.cloud.alibaba.nacos.consumer.feign.controller;import org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosConsumerFeignController &#123; @Autowired private EchoService echoService; @GetMapping(value = \"/echo/hi\") public String echo() &#123; return echoService.echo(\"Hi Feign\"); &#125;&#125; 启动工程 通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer-feign 的服务； 这时打开 http://localhost:9092/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery Hi Feign 测试负载均衡 启动多个 consumer-provider 实例，修改provider子项目的配置文件的端口为8082； 找到idea编辑器顶部菜单，找到run-----&gt;Edit Configurations…-----&gt;选择provider启动了，勾选右边的Allow parallel run 再次运行NacosProviderApplication启动类，就会创建一个新的实例。 效果图： 修改 consumer-provider 项目中的 Controller 代码，用于确定负载均衡生效 123456789101112131415161718package org.lee.spring.cloud.alibaba.nacos.provider.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosProviderController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(value = \"/echo/&#123;message&#125;\") public String echo(@PathVariable String message) &#123; return \"Hello Nacos Discovery \" + message + \"i am from port \" + port; &#125;&#125; 重启8081和8082两个端口的实例 在浏览器上多次访问 http://localhost:9092/echo/hi ，浏览器交替显示端口变化。 使用熔断器防止服务雪崩 概述 在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 相互调用，在 Spring Cloud 中可以用 RestTemplate + LoadBalanceClient 和 Feign 来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证 100% 可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet 容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的 “雪崩” 效应。 为了解决这个问题，业界提出了熔断器模型。 阿里巴巴开源了 Sentinel 组件，实现了熔断器模式，Spring Cloud 对这一组件进行了整合。在微服务架构中，一个请求需要调用多个服务是非常常见的，如下图： 较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值熔断器将会被打开。 熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值。 什么是 Sentinel 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 的特征 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的 双十一大促流量 的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等。 Feign 中使用 Sentinel 如果要在您的项目中引入 Sentinel，使用 group ID 为 org.springframework.cloud 和 artifact ID 为 spring-cloud-starter-alibaba-sentinel 的 starter。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; Sentinel 适配了 Feign 组件。但默认是关闭的。需要在配置文件中配置打开它，在配置文件增加以下代码： 123feign: sentinel: enabled: true 在 Service 中增加 fallback 指定类 123456789101112package org.lee.spring.cloud.alibaba.nacos.consumer.feign.service;import org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.fallback.EchoServiceFallback;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"nacos-provider\", fallback = EchoServiceFallback.class)public interface EchoService &#123; @GetMapping(value = \"/echo/&#123;message&#125;\") String echo(@PathVariable(\"message\") String message);&#125; 创建熔断器类并实现对应的 Feign 接口 123456789101112package org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.fallback;import org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.stereotype.Component;@Componentpublic class EchoServiceFallback implements EchoService &#123; @Override public String echo(String message) &#123; return \"echo fallback\"; &#125;&#125; 测试熔断器 此时我们关闭服务提供者，再次请求 http://localhost:9092/echo/hi 浏览器会显示： 1echo fallback 使用熔断器仪表盘监控 Sentinel 控制台 Sentinel 控制台提供一个轻量级的控制台，它提供机器发现、单机资源实时监控、集群资源汇总，以及规则管理的功能。您只需要对应用进行简单的配置，就可以使用这些功能。 注意: 集群资源汇总仅支持 500 台以下的应用集群，有大概 1 - 2 秒的延时。 详细内容请到Sentinel的项目仓库查看文档： https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D 下载并打包 12345# 下载源码git clone https://github.com/alibaba/Sentinel.git# 编译打包mvn clean package 注：下载依赖时间较长，请耐心等待… 或者直接下载jar包 https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0 访问以上链接，或者直接去下载jar包： https://github.com/alibaba/Sentinel/releases 下载完成后运行： 1java -Dserver.port&#x3D;8080 -Dcsp.sentinel.dashboard.server&#x3D;localhost:8080 -Dproject.name&#x3D;sentinel-dashboard -jar sentinel-dashboard-1.7.1.jar 这里注意jar包的名称，我下载的是1.7.1版本。 启动控制台 跑起来后访问：localhost:8080，用户名密码默认：sentinel 如若 8080 端口冲突，可使用 -Dserver.port=新端口 进行设置。 配置feign消费者控制台信息 application.yml 配置文件中spring.cloud下增加如下配置： 1234sentinel: transport: port: 8719 dashboard: localhost:8080 这里的 spring.cloud.sentinel.transport.port 端口配置会在应用对应的机器上启动一个 Http Server，该 Server 会与 Sentinel 控制台做交互。比如 Sentinel 控制台添加了 1 个限流规则，会把规则数据 push 给这个 Http Server 接收，Http Server 再将规则注册到 Sentinel 中。 8719说白了就像是服务注册在nacos中一样，给应用一个端口注册到sentinel中让它监控该应用。 测试 Sentinel 使用之前的 Feign 客户端，application.yml 完整配置如下： 12345678910111213141516171819202122232425spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848 sentinel: transport: port: 8719 dashboard: localhost:8080server: port: 9092management: endpoints: web: exposure: include: \"*\"feign: sentinel: enabled: true 重启feign服务，访问sentinel控制台，发现还是原来的数据。 这里我们再次模拟熔断，访问： http://localhost:9092/echo/hi ，触发熔断。 然后再回到sentinel控制台刷新，就有监控到的数据了： 使用路由网关统一访问接口 什么是 Spring Cloud Gateway Spring Cloud Gateway 是 Spring 官方基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，Spring Cloud Gateway 旨在为微服务架构提供一种简单而有效的统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系中的网关，目标是替代 Netflix ZUUL，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 Spring Cloud Gateway 功能特征 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 Spring Cloud Gateway 工程流程 客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（pre）或之后（post）执行业务逻辑。 其实就相当于spring MVC的servletDispachter的工作流程 使用 创建新module，名为spring-cloud-gateway，pom.xml文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-gateway&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-gateway&lt;/name&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.hello.spring.cloud.gateway.GatewayApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-gateway 依赖 特别注意 Spring Cloud Gateway 不使用 Web 作为服务器，而是 使用 WebFlux 作为服务器，Gateway 项目已经依赖了 starter-webflux，所以这里 千万不要依赖 starter-web 由于过滤器等功能依然需要 Servlet 支持，故这里还需要依赖 javax.servlet:javax.servlet-api 创建配置文件application.yml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spring: application: # 应用名称 name: spring-gateway cloud: # 使用 Naoos 作为服务注册发现 nacos: discovery: server-addr: 127.0.0.1:8848 # 使用 Sentinel 作为熔断器 sentinel: transport: port: 8721 dashboard: localhost:8080 # 路由网关配置 gateway: # 设置与服务注册发现组件结合，这样可以采用服务名的路由策略 discovery: locator: enabled: true # 配置路由规则 routes: # 采用自定义路由 ID（有固定用法，不同的 id 有不同的功能，详见：https://cloud.spring.io/spring-cloud-gateway/2.0.x/single/spring-cloud-gateway.html#gateway-route-filters） - id: NACOS-CONSUMER # 采用 LoadBalanceClient 方式请求，以 lb:// 开头，后面的是注册在 Nacos 上的服务名 uri: lb://nacos-consumer # Predicate 翻译过来是“谓词”的意思，必须，主要作用是匹配用户的请求，有很多种用法 predicates: # Method 方法谓词，这里是匹配 GET 和 POST 请求 - Method=GET,POST - id: NACOS-CONSUMER-FEIGN uri: lb://nacos-consumer-feign predicates: - Method=GET,POSTserver: port: 9000# 目前无效feign: sentinel: enabled: true# 目前无效management: endpoints: web: exposure: include: \"*\"# 配置日志级别，方别调试logging: level: org.springframework.cloud.gateway: debug 创建启动类： 123456789101112131415package org.lee.spring.cloud.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class,args); &#125;&#125; 测试访问 依次运行 Nacos 服务、NacosProviderApplication、NacosConsumerApplication、NacosConsumerFeignApplication、GatewayApplication 打开浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 浏览器显示 1Hello Nacos Discovery nacos-consumer i am from port 8082 打开浏览器访问：http://localhost:9000/nacos-consumer-feign/echo/hi 浏览器显示 1Hello Nacos Discovery Hi Feign i am from port 8082 注意：请求方式是 http://路由网关IP:路由网关Port/服务名/\\** 至此说明 Spring Cloud Gateway 的路由功能配置成功","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Security OAuth2.0 认证授权","slug":"Spring-Security-Oauth2","date":"2020-03-10T08:09:22.000Z","updated":"2020-03-10T09:00:06.959Z","comments":true,"path":"2020/03/10/Spring-Security-Oauth2/","link":"","permalink":"http://ctrl98.github.io/2020/03/10/Spring-Security-Oauth2/","excerpt":"","text":"基本概念 什么是认证？ 互联网时代，手机微信、支付宝等软件，使用前都需要进行登录，输入用户名密码进行登录某个软件得过程就叫认证。 为什么要认证？ 认证是为了保护系统得隐私数据与资源，用户身份合法才可以访问系统资源。 认证：用户认证就是判断一个用户得身份是否合法的过程，合法才能继续访问，常见的用户身份认证方式有用户名密码登录、二维码登录、手机短信验证和指纹等。 什么是会话？ 比如微信用户认证后、打开一个网页，不可能每打开一次就要用户重新登录一次，会话就是避免用户每次操作都进行认证，将用户的信息保存在会话中，会话就是系统为了保持当前用户的登录状态提供的机制，常见的有基于Session、基于Token方式等。 什么是授权？ 授权就是通过认证的用户是否有权限去使用该系统的某个功能，比如刚注册的微信用户，由于一开始没有绑定银行卡，所以是没办法使用发红包收红包的功能。 RBAC 业界通常基于RBAC实现授权 基于角色的访问控制 ​ RBAC基于角色的访问控制（Role-Based Access Control）是按角色进行授权，比如主体的角色为总经理，可以查询系统的报表、工资信息等。 代码逻辑可简单表示为： 123if (主体.hasRole(\"总经理角色id\"))&#123; 查询工资();&#125; 基于资源的访问控制 ​ RBAC基于资源的访问控制（Resourse-Based Access Control）是按资源进行授权，比如必须具有查询工资权限才能使用该功能。 代码逻辑可简单表示为： 123if (主体.hasPermission(&quot;查询工资权限标识&quot;))&#123; 查询工资();&#125;","categories":[{"name":"权限框架","slug":"权限框架","permalink":"http://ctrl98.github.io/categories/%E6%9D%83%E9%99%90%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"http://ctrl98.github.io/tags/OAuth2-0/"}]},{"title":"浅谈Spring的IOC/AOP","slug":"Spring1","date":"2020-03-09T02:14:25.000Z","updated":"2020-03-09T05:59:14.872Z","comments":true,"path":"2020/03/09/Spring1/","link":"","permalink":"http://ctrl98.github.io/2020/03/09/Spring1/","excerpt":"","text":"什么是耦合（高/低？） 耦合，就是模块间关联的程度，每个模块之间的联系越多，也就是其耦合性越强，那么独立性也就越差了，所以我们在软件设计中，应该尽量做到低耦合，高内聚。 生活中的例子： 家里有一条串灯，上面有很多灯泡，如果灯坏了，你需要将整个灯带都换掉，这就是高耦合的表现，因为灯和灯带之间是紧密相连，不可分割的，但是如果灯泡可以随意拆卸，并不影响整个灯带，那么这就叫做低耦合。 代码例子： 12Father f &#x3D; new Son();f.method(); Son类继承自Father类，通过 new来创建依赖的对象调用方法 此时如果你想把Son换成Girl类，那么所有 new Son()的地方都要修改，这只是简单的举例，在实际开发中有上百个类，你不可能这样去操作。 这时候我们把对象的创建交给Spring，那么效率就大大地提升了。 12Father f &#x3D; BeanFactory().getBean(B名称);f.method(); 只需要修改getBean里的参数即可。 Spring 框架好在哪里？ 降低耦合度：Spring神奇的 IoC 容器，可以控制对象间的依赖关系，解决了硬编码问题 AOP 编程支持：Spring 提供了面向切面编程 方便集成各种优秀框架：Spring 不排斥各种优秀的开源框架 方便程序测试：Spring 支持 junit4 声明式事务的支持：Spring 帮助我们从普通的事物管理代码中解放出来，通过配置就可以完成对事务的管理 降低 JavaEE API 的使用难度：Spring 将 JavaEE 中一些比较难用的 API (JDBC、JavaMail、远程调用等) 进行了封装，使得它们的使用难度大大降低 Spring 框架的结构 Spring框架是一个分层的架构，根据不同的功能，分成了多个模块，而这些模块都是可以单独或者组合使用。 CoreContainer是Spring框架的最核心部分，其他模块都是基于该模块建立的。 核心容器 CoreContainer 提供 Spring框架的基本功能，分为图中四个模块，核心容器中重要的组件就是 BeanFactory ，本质就是实现了工厂模式，且它使用了 IoC（控制反转）模式，将程序的配置以及依赖性规范与实际程序的代码分开。 Beans：提供了 BeanFactory，Spring中将管理对象称作 Bean Core：提供 Spring 框架的基本组成部分，包括我们首先要学习的 IoC 和 DI Context：访问定义和配置任何对象的媒介，以前两者为基础，ApplicationContext 接口是这部分的重点 spEL (Spring Expression Language)：一个比较强大的运行时查询和操作数据的表达式语言 数据访问/集成（Data Access/Integration） JDBC：提供了一个JDBC抽象层，减少了一些重复无聊的JDBC代码，提升了开发效率 ORM：提供了对流行对象关系映射API的集成层 （JPA、JDO、Hibernate、 mybatis ） OXM：提供了一个支持对象/XML映射实现的抽象层（ JAXB、Castor、XMLBeans、JiBX 、XStrea ） JMS：Java消息服务， 包含用于生产和消费消息的功能 Transactions：事务模块，用于支持实现特殊接口和所有的POJO的类的编程和声明式事物管理 Web 模块 Web：提供了基本的 Web 的集成功能，例如多部分文件上传功能，以及初始化了一个使用了Servlet监听器和面向Web应用程序上下文的 IoC 容器，它还包含一个HTTP客户端和Spring远程支持的相关部分 Servelt：包含 Spring 模型—视图—控制器 (MVC) ，用来实现Web应用 WebSocket：Spring4.0以后新增的模块，它提供了WebSocket和SocketJS的实现 Portlet：就好像是Servlet一般，它提供了Portlet环境下的MVC实现 其余模块 AOP：提供了面向切面编程的能力，允许定义方法拦截器和切入点，按功能分离代码，降低耦合性，可以实现一些面向对象编程中不太好实现的功能 Aspects：提供与 AspectJ 的继承，是一个功能强大且成熟的面向切面编程的框架 Instrumentation：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用 Messaging： 它提供了对消息传递体系结构和协议的支持 Test：其支持使用 JUnit 或者 TestNG，可以实现单元测试，集合测试等测试流程 Spring IOC原理 Inversion of Control，控制反转。是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。 通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。 IoC 内部核心原理就是反射技术，涉及到 Bean 对象的初始化构建等步骤。 Java 反射 Java反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 在日常的第三方应用开发过程中，经常会遇到某个类的某个成员变量、方法或是属性是私有的或是只对系统应用开放，这时候就可以利用Java的反射机制通过反射来获取所需的私有成员或是方法。 反射机制相关类： 类名 用途 Class类 代表类的实体，在运行的Java应用程序中表示类和接口 Field类 代表类的成员变量（成员变量也称为类的属性） Method类 代表类的方法 Constructor类 代表类的构造方法 对于每个类都有自己得子方法，这里不作过多解释，推荐一篇反射文章—详细请看 Java高级特性——反射 Spring 入门程序 使用Eclipse创建一个名为Demo的项目，添加Spring相关的依赖包，commons-logging-1.2.jar、spring-beans-4.3.6.RELEASE.jar、spring-context-4.3.6.RELEASE.jar、spring-core-4.3.6.RELEASE.jar、spring-expression-4.3.6.RELEASE.jar。 在项目的src目录下，创建一个org.ioc包，并在包下创建接口UserDao，然后接口中定义一个say()方法： 123public interface UserDao()&#123; public void say();&#125; 接着在ioc报下创建该接口的实现类UserDaoImpl，实现接口中的方法，并输出一条语句： 12345public class UserDaoImpl implements UserDao&#123; public void say()&#123; System.out.println(\"userDao say Hello World\"); &#125;&#125; 在src下创建spring的配置文件applicationContext.xml，并配置一个id为userDao的Bean： 1&lt;bean id=\"userDao\" class=\"org.ioc.UserDaoImpl\"/&gt; 该段代码表示在spring容器中创建一个id为userDao的bean实例，其中class属性用于指定需要实例化的Bean类。 在ioc包下，创建测试类TestIoc，编写main方法，在mian方法里面初始化spring容器，加载配置文件，获取userDao对象实例，最后调用say()方法输出： 12345678public class TestIoc &#123; public static void main(String[] args)&#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); UserDao userDao = (UserDao)applicationContext.getBean(\"userDao\"); userDao.say(); &#125;&#125; 最后控制台输出： 1userDao say Hello World 从测试方法可以看出，并没有通过new关键字来创建UserDao接口的实现类对象，而是通过Spring容器来获取实现类对象，这就是Spring IOC 容器的工作机制。 依赖注入DI 控制反转（IoC）是一种思想，而依赖注入（Dependency Injection）则是实现这种思想的方法。 其实泛概念上两者是接近的，可以简单的理解为一个概念的不同角度描述。 DI的作用是在使用Spring框架创建对象时，动态地将其所依赖的对象注入Bean组件中。 上面写程序的时候，通过控制反转，使得 Spring 可以创建对象，这样减低了耦合性，但是每个类或模块之间的依赖是不可能完全消失的，而这种依赖关系，我们可以完全交给 spring 来维护。 DI实现方式 构造方法注入：基于构造方法的依赖注入通过调用带参数的构造方法来实现，每个参数代表一个依赖。 这一种的前提就是：类中必须提供一个和参数列表相对应的构造函数 12345678910111213141516171819public class DemoServiceImpl implements DemoService &#123; private String username; private Integer age; private Date birthday; //构造方法 public DemoServiceImpl(String username, Integer phone, Date birthday) &#123; this.username = username; this.age = phone; this.birthday = birthday; &#125; public void addDemo() &#123; System.out.println(\"username: \" + username + \", phone: \" + age + \", birthday: \" + birthday); &#125;&#125; 在ApplicationContext.xml文件中添加如下： 123456&lt;bean id=\"demoService\" class=\"org.service.impl.DemoServiceImpl\"&gt; &lt;constructor-arg name=\"username\" value=\"詹姆斯\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"phone\" value=\"35\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"birthday\" ref=\"bir\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id=\"bir\" class=\"java.util.Date\"&gt;&lt;/bean&gt; 属性解析： constructor-arg 给谁赋值： index：指定参数在构造函数参数列表的索引位置 type：指定参数在构造函数中的数据类型 name：指定参数在构造函数中的名称（更常用） 赋什么值： value：这里可以写基本数据类型和 String ref：这里可以引入另一个bean，帮助我们给其他类型赋值（例如文中 birthday ） 测试后发现可以打印出我们在配置文件配置的value值。 上面就是使用类的构造函数给成员变量进行赋值，但特别的是，这里是通过配置，使用 Spring 框架进行注入。 setter方法注入：通过调用无参构造器或无参静态工厂方法实例化bean后调用该bean的setter。 修改以上配置文件 123456&lt;bean id=\"demoService\"class=\"cn.service.impl.DemoServiceImpl\"&gt; &lt;property name=\"username\" value=\"詹姆斯\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"35\"&gt;&lt;/property&gt; &lt;property name=\"birthday\" ref=\"bir\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"bir\" class=\"java.util.Date\"&gt;&lt;/bean&gt; property name：与成员变量名无关，与set方法后的名称有关，例如 setUsername() 获取到的就是username，并且已经小写了开头 value：这里可以写基本数据类型和 String ref：这里可以引入另一个bean，帮助我们给其他类型赋值（例如文中 birthday ） 实现的效果和上面的一样 Spring AOP原理 Aspect Oriented Programming，面向切面编程。通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP 是 OOP 的延续，是软件开发中的一个热点，也是 Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。其中，最常用的使用场景一般有日志模块、权限模块、事物模块。 AOP 的内部原理其实就是动态代理和反射了。主要涉及到的反射类： 类 说明 InvocationHandler 通过这个接口定义横切的逻辑，然后通过反射机制调用目标类的方法，这样就能动态地把非业务逻辑和业务逻辑动态得拼接在一起 proxy 提供创建动态代理类得静态方法，通常利用INvocationHandler创建代理实例，来间接得调用代理的方法 Spring 中实现动态代理有两种方式可选。 JDK 动态代理 必须实现 InvocationHandler 接口，然后通过 Proxy.newProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h) 获得动态代理对象。 CGLIB 动态代理 使用 CGLIB 动态代理，被代理类**不需要强制实现接口。**CGLIB 不能对声明为 final的方法进行代理，因为 CGLIB 原理是动态生成被代理类的子类。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://ctrl98.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://ctrl98.github.io/tags/Spring/"}]},{"title":"Spring Cloud Netflix核心组件介绍及搭建","slug":"SpringBoot-Netflix1","date":"2020-03-08T08:08:24.000Z","updated":"2020-03-11T08:05:01.983Z","comments":true,"path":"2020/03/08/SpringBoot-Netflix1/","link":"","permalink":"http://ctrl98.github.io/2020/03/08/SpringBoot-Netflix1/","excerpt":"","text":"单体应用存在的问题(耦合度过高) 随着业务的发展，开发变得越来越复杂。 修改，新增某个功能，需要对整个系统进行测试，重新部署。 一个模块出现了问题，很可能导致整个系统崩溃。 多个开发团队同时对数据进行管理，容易发生安全漏洞。 各个模块使用同一种技术开发，各个模块很难根据实际情况选择更合适的技术架构，局限性大。 模块内容过于复杂，如果员工离职，可能需要很长时间才能完成工作交接。 分布式、集群 集群：一台服务器无法负荷高并发的数据访问，那么就设置多几台服务器一起分担压力。(物理、运维层面) 分布式：将一个复杂的问题拆分成若干个小问题，将一个大型的项目架构拆分成若干个微服务来协同完成。(软件设计、开发层面)，分别有不同的人来完成每一个微服务，最终将所有服务进行整合。 Spring Cloud Netflix核心组件 服务治理 Eureka 负载均衡 Ribbon 负载均衡 Feign 服务网关 Zuul 服务跟踪 Zipkin 服务监控 Actuator 服务配置 Config 服务熔断 Hystrix Spring Cloud Eureka 简介： Eureka是 Netflix 开源的基于REST的服务治理解决方案，Spring Cloud 集成了Eureka，提供了服务注册和 服务发现的功能，可以和基于Spring Boot 搭建的微服务应用轻松整合，开箱即用，二次封装形成Spring Cloud Eureka Eureka server：注册中心 Eureka Client：服务提供者、服务消费者，所有要进⾏注册的微服务通过 Eureka Client 连接到 Eureka Server，完成注册。 如何去理解这三者之间的关系：比如说一个外卖订餐平台，商家需要在这个平台注册了才能提供服务，客户需要注册账号才能在商家提供的外卖服务进行下单销费。 分布式系统架构中，每个微服务在启动时，将自己的信息存储在注册中心，叫做服务注册。 服务消费者从注册中心获取服务提供者的网络信息，通过该信息调用服务，叫做服务发现。 Eureka Server代码实现 第一步创建一个maven父工程 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 解决 JDK 9 以上没有 JAXB API 的问题 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt; &lt;version&gt;2.3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步在父工程下创建maven子工程—eureka server pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第三步在module—eureka server创建配置文件 application.yml ，添加eureka server相关配置。 12345678server: port: 8071eureka: client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://localhost:8071/eureka/ 属性说明： server.port：当前eureka的服务端口 eureka.client.register-with-eureka：是否将当前的eureka server服务作为客户端进行注册 eureka.client.fetch-registry：是否获取其他eureka server服务的数据 eureka.client.service-url.defaultZone：注册中心访问地址 第四步在eureka server模块创建启动类 12345678910111213package eureka.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class,args); &#125;&#125; ​ 注解说明 @SpringBootApplication：声明Spring Boot入口程序 @EnableEurekaServer：声明该类是一个Eureka Server 微服务，提供服务注册和服务发现功能，即注册中心 到这里可以访问：http://localhost:8071/eureka 来查看注册中心的微服务信息 Eureka Client 代码实现 在父工程的基础上创建Module—eureka client 在pom.xml文件添加： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Module—eureka client创建配置⽂件 application.yml，添加 Eureka Client 相关配置 1234567891011server: port: 8010spring: application: name: serverProvidereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性说明： spring.application.name：当前服务注册在 Eureka Server 上的名称 eureka.instance.prefer-ip-address：是否将当前服务的 IP 注册到 Eureka Server 创建启动类---------ServerProviderApplication.java 123456@SpringBootApplicationpublic class ServerProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServerProviderApplication.class,args); &#125;&#125; 下面在Module—eureka client模块下实现简单业务测试 在Module—eureka client模块下创建实体类 12345678910111213141516package eurekaclient.lee.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private Integer id; private String name; private Integer age;&#125; 创建业务接口类 1234567891011package eurekaclient.lee.repository;import eurekaclient.lee.entity.Student;import java.util.Collection;public interface StudentRepository &#123; public Collection&lt;Student&gt; findAll(); public Student findById(Integer id); public void saveOrUpdate(Student student); public void deleteById(Integer id);&#125; 创建业务接口实现类 123456789101112131415161718192021222324252627282930313233343536373839404142package eurekaclient.lee.repository.Impl;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.stereotype.Repository;import java.util.Collection;import java.util.HashMap;import java.util.Map;@Repositorypublic class StudentRepositoryImpl implements StudentRepository &#123; private static Map&lt;Integer,Student&gt; studentMap; static &#123; studentMap = new HashMap&lt;&gt;(); studentMap.put(1,new Student(1,\"张三\",22)); studentMap.put(2,new Student(2,\"李四\",23)); studentMap.put(3,new Student(3,\"王五\",34)); &#125; @Override public Collection&lt;Student&gt; findAll() &#123; return studentMap.values(); &#125; @Override public Student findById(Integer id) &#123; return studentMap.get(id); &#125; @Override public void saveOrUpdate(Student student) &#123; studentMap.put(student.getId(),student); &#125; @Override public void deleteById(Integer id) &#123; studentMap.remove(id); &#125;&#125; 创建控制类 123456789101112131415161718192021222324252627282930313233343536373839404142package eurekaclient.lee.controller;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentController &#123; @Autowired private StudentRepository repository; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return repository.findAll(); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return repository.findById(id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @PutMapping(\"/update\") public void update(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; repository.deleteById(id); &#125;&#125; 到这里可以访问： http://localhost:8010/student/findAll 等接口访问数据进行测试，此时该服务已经注册在服务注册中心 RestTemplate的使用 什么是RestTemplate RestTemplate 是 Spring 框架提供的基于 REST 的服务组件，底层是对 HTTP 请求及响应进⾏了封装，提供了很多访问 RETS 服务的⽅法，可以简化代码开发。 如何使⽤ RestTemplate？ 在父工程创建maven工程(new Module)—resttemplate，在其pom.xml中不需要添加额外依赖，因为父工程中已有springboot的依赖，所以其子工程(Module)自然也是一个springboot工程。 创建实体类 12345678910111213141516package resttemplate.lee.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private Integer id; private String name; private Integer age;&#125; 创建controller 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package resttemplate.lee.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import resttemplate.lee.entity.Student;import java.util.Collection;@org.springframework.web.bind.annotation.RestController@RequestMapping(\"/rest\")public class RestController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); &#125; @GetMapping(\"/findAllSec\") public Collection&lt;Student&gt; findAllSec()&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id).getBody(); &#125; @GetMapping(\"/findByIdSec/&#123;id&#125;\") public Student findByIdSec(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); &#125; @PutMapping(\"update\") public void update(@RequestBody Student student)&#123; restTemplate.put(\"http://localhost:8010/student/update\",student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; restTemplate.delete(\"http://localhost:8010/student/deleteById/&#123;id&#125;\",id); &#125;&#125; 创建启动类---------RestTemplateApplication.java 123456789101112131415161718package resttemplate.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RestTemplateApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RestTemplateApplication.class,args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 这个只是简单测试RestTemplate的用法，并不涉及到微服务，为下面实现服务消费者Consumer预热，启动RestTemplateApplication的时候端口默认为8080，所以可以通过访问：http://localhost:8080/rest/findAll 等接口访问数据，此时的数据访问调用的是Eureka Client中的数据。 服务消费者Consumer 在父工程中创建module—consumer 在pom.xml添加 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在module中创建配置文件 application.yml 1234567891011server: port: 8020spring: application: name: consumereureka: client: service-url: defaultZone: http://loaclhost:8071/eureka/ instance: prefer-ip-address: true 创建启动类---------ConsumerApplication.java 123456789101112131415161718package consumer.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class,args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 创建实体类（同上） 创建controller 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package consumer.lee.controller;import consumer.lee.entity.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import java.util.Collection;@RestController@RequestMapping(\"/consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); &#125; @GetMapping(\"/findAllSec\") public Collection&lt;Student&gt; findAllSec()&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id).getBody(); &#125; @GetMapping(\"/findByIdSec/&#123;id&#125;\") public Student findByIdSec(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); &#125; @PutMapping(\"update\") public void update(@RequestBody Student student)&#123; restTemplate.put(\"http://localhost:8010/student/update\",student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; restTemplate.delete(\"http://localhost:8010/student/deleteById/&#123;id&#125;\",id); &#125;&#125; 到此服务消费者创建完成，其实和上面的resttemplate差不多，此模块是在注册中心注册过的，在这里你可以访问http://localhost:8020/consumer/findAll 等接口访问Eureka Client中的数据。 服务网关Zuul Spring Cloud 集成了 Zuul 组件，实现服务⽹关。 什么是Zuul? Zuul 是 Netflix 提供的⼀个开源的 API ⽹关服务器，是客户端和⽹站后端所有请求的中间层，对外开放⼀个 API，将所有请求导⼊统⼀的⼊⼝，屏蔽了服务端的具体实现逻辑，Zuul 可以实现反向代理的功能，在⽹关内部实现动态路由、身份认证、IP 过滤、数据监控等。 在父工程基础上再创建module pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8030spring: application: name: gatewayeureka: client: service-url: dedaultZone: http://localhost:8071/eureka/zuul: routes: serverProvider: /p/** 属性说明 zuul.routes.serverProvider：给服务提供者 provider 设置映射，这里的 serverProvider是Eureka Client在注册中心注册的服务名称，即访问其服务提供者模块，只需在结构访问地址加上/p/即可 创建启动类 12345678910111213package zuul.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@EnableZuulProxy@EnableAutoConfigurationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125; 注解解释 @EnableZuulProxy：包含了 @EnableZuulServer，设置该类是⽹关的启动类。 @EnableAutoConfiguration：可以帮助 Spring Boot 应⽤将所有符合条件的 @Configuration 配 置加载到当前 Spring Boot 创建并使⽤的 IoC 容器中。 Zuul ⾃带了负载均衡功能，provider 创建多个实例(即多个启动类，修改配置文件的端口)，每个实例提供不同的请求，修改 provider（即eureka client中的） 的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package eurekaclient.lee.controller;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentController &#123; @Autowired private StudentRepository repository; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return repository.findAll(); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return repository.findById(id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @PutMapping(\"/update\") public void update(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; repository.deleteById(id); &#125; @GetMapping(\"/index\") public String index()&#123; return \"当前端口：\" + this.port; &#125;&#125; 到这里网关服务基本实现，你只需要访问：http://localhost:8030/p/student/findAll 等接口也是可以访问到服务提供者中的数据。 Ribbon 负载均衡 什么是 Ribbon？ Spring Cloud Ribbon 是⼀个负载均衡解决⽅案，Ribbon 是 Netflix 发布的负载均衡器，Spring Cloud Ribbon 是基于 Netflix Ribbon 实现的，是⼀个⽤于对 HTTP 请求进⾏控制的负载均衡客户端。 在注册中⼼对 Ribbon 进⾏注册之后，Ribbon 就可以基于某种负载均衡算法，如轮询、随机、加权轮询、加权随机等⾃动帮助服务消费者调⽤接⼝，开发者也可以根据具体需求⾃定义 Ribbon 负载均衡算法。实际开发中，Spring Cloud Ribbon 需要结合 Spring Cloud Eureka 来使⽤，Eureka Server 提供所有可以调⽤的服务提供者列表，Ribbon 基于特定的负载均衡算法从这些服务提供者中选择要调⽤的。 具体实例。 在父工程上创建Module 在pom.xml文件中添加 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Module中创建配置文件 application.yml 1234567891011server: port: 8040spring: application: name: ribboneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 创建启动类------RibbonApplication.Java 1234567891011121314151617181920package ribbon.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonApplication.class,args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 注解说明 @LoadBalanced：声明⼀个基于 Ribbon 的负载均衡。 创建实体类(同上) 创建controller 12345678910111213141516171819202122232425262728package ribbon.lee.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import ribbon.lee.entity.Student;import java.util.Collection;@RestController@RequestMapping(\"/ribbon\")public class RibbonController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForObject(\"http://serverProvider/student/findAll\",Collection.class); &#125; @GetMapping(\"/index\") public String index()&#123; return restTemplate.getForObject(\"http://serverProvider/student/index\",String.class); &#125;&#125; 到此ribbon负载均衡基本实现，你可以访问：http://localhost:8040/ribbon/findAll 来访问服务提供者的数据。 Feign 负载均衡 什么是 Feign？ 与 Ribbon ⼀样，Feign 也是由 Netflix 提供的，Feign 是⼀个声明式、模版化的 Web Service 客户端， 它简化了开发者编写 Web 服务客户端的操作，开发者可以通过简单的接⼝和注解来调⽤ HTTP API， Spring Cloud Feign，它整合了 Ribbon 和 Hystrix，具有可插拔、基于注解、负载均衡、服务熔断等⼀ 系列便捷功能。 相⽐较于 Ribbon + RestTemplate 的⽅式，Feign ⼤⼤简化了代码的开发，Feign ⽀持多种注解，包括Feign 注解、JAX-RS 注解、Spring MVC 注解等，Spring Cloud 对 Feing 进⾏了优化，整合了 Ribbon和 Eureka，从⽽让 Feign 的使⽤更加⽅便。 Ribbon 和 Feign 的区别 Ribbon 是⼀个通⽤的 HTTP 客户端⼯具，Feign 是基于 Ribbon 实现的。 Feign 的特点 Feign 是⼀个声明式的 Web Service 客户端。 ⽀持 Feign 注解、Spring MVC 注解、JAX-RS 注解。 Feign 基于 Ribbon 实现，使⽤起来更加简单。 Feign 集成了 Hystrix，具备服务熔断的功能。 在父工程的基础上创建module—feign，在pom.xml中添加 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建该模板的配置文件：application.yml 1234567891011server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 实体类也要复制过来 创建启动类---------FeignApplication.java 12345678910111213package feign.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClientspublic class FeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignApplication.class,args); &#125;&#125; 创建声明式接口---------FeignProviderClient 1234567891011121314151617package feign.lee.feign;import feign.lee.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\")public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 创建控制器 12345678910111213141516171819202122232425262728package feign.lee.controller;import feign.lee.entity.Student;import feign.lee.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/feign\")public class FeignController &#123; @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return feignProviderClient.findAll(); &#125; @GetMapping(\"/index\") public String index()&#123; return feignProviderClient.index(); &#125;&#125; 到这里可以通过：http://localhost:8050/feign/findAll 来访问eureka client中的数据。和上面的Ribbon实现的功能是一样的，但是过程是不一样的。 Feign 中的熔断机制（因为Feign 集成了 Hystrix） 比如说一个功能需要多个微服务共同完成，但是其中一个微服务崩了，导致无法完成任务，如果没有熔断机制，前端就会显示报错，用户友好度不够好，用户也看不懂。 比如说把上面开启好的两个服务提供者eureka client关了，只留下eureka注册中心和feign，然后再次访问http://localhost:8050/feign/findAll或者是http://localhost:8050/feign/index 就会报500的错误。 服务熔断，application.yml 添加熔断机制。 1234567891011121314server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: true feign.hystrix.enabled：是否开启熔断器。 创建 FeignProviderClient 接⼝的实现类 FeignError，定义容错处理逻辑，通过 @Component 注 解将 FeignError 实例注⼊ IoC 容器中。 1234567891011121314151617181920package feign.lee.feign.impl;import feign.lee.entity.Student;import feign.lee.feign.FeignProviderClient;import org.springframework.stereotype.Component;import java.util.Collection;@Componentpublic class FeignError implements FeignProviderClient &#123; @Override public Collection&lt;Student&gt; findAll() &#123; return null; &#125; @Override public String index() &#123; return \"当前服务器正在维护中。。。。。。\"; &#125;&#125; 在 FeignProviderClient 定义处通过 @FeignClient 的 fallback 属性设置映射。 123456789101112131415161718package feign.lee.feign;import feign.lee.entity.Student;import feign.lee.feign.impl.FeignError;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\",fallback = FeignError.class)public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 到这里，当你再次访问http://localhost:8050/feign/index 的时候就提示 “当前服务器正在维护中。。。。。。”。 Hystrix 容错机制 什么是Hystrix容错机制 在不改变各个微服务调⽤关系的前提下，针对错误情况进⾏预先处理。(类似于电路的保险丝) 设计原则 服务隔离机制 服务降级机制 熔断机制 提供实时的监控和报警功能 提供实时的配置修改功能 Hystrix 数据监控需要结合 Spring Boot Actuator 来使⽤，Actuator 提供了对服务的健康健康、数据统计，可以通过 hystrix.stream 节点获取监控的请求数据，提供了可视化的监控界⾯。 在父工程的基础上再创建module—hystrix，pom.xml添加依赖 12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8060spring: application: name: hystrixeureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: truemanagement: endpoints: web: exposure: include: 'hystrix.stream' 创建启动类---------HystrixApplication.java 1234567891011121314151617package hystrix.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClients@EnableCircuitBreaker@EnableHystrixDashboardpublic class HystrixApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HystrixApplication.class,args); &#125;&#125; 注解解释 @EnableCircuitBreaker：声明启⽤数据监控 @EnableHystrixDashboard：声明启⽤可视化数据监控 添加Student实体类 添加feign模块中的FeignProviderClient接口类 1234567891011121314151617package hystrix.lee.feign;import hystrix.lee.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\")public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 添加控制类 12345678910111213141516171819202122232425262728package hystrix.lee.controller;import hystrix.lee.entity.Student;import hystrix.lee.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/hystrix\")public class HystrixController &#123; @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return feignProviderClient.findAll(); &#125; @GetMapping(\"/index\") public String index()&#123; return feignProviderClient.index(); &#125;&#125; 到这里只是演示了hystrix对数据请求进行监控的功能，hystrix的熔断机制在Feign中已经演示过。然后启动注册中心，启动一个服务提供者eureka client，最后再启动hystrix，先访问 http://localhost:8060/actuator/hystrix.stream 查看hystrix对求情的监控，这个时候因为没有发生对提供者的请求，所以没有监控到数据，一直在ping: 然后再访问： http://localhost:8060/hystrix/index ，你会发现ping: 出现了数据。 当然这个网页看着监控的数据显示不是和友好，所以我们这里使用的是 hystrix-dashboard仪表盘来查看，访问： http://localhost:8060/hystrix ，然后把 http://localhost:8060/actuator/hystrix.stream地址复制过来，自己起一个监控的名字，点击Monitor Stream,就有一个可视化仪表盘了。 Spring Cloud 配置中⼼ Spring Cloud Config，通过服务端可以为多个客户端提供配置服务。Spring Cloud Config 可以将配置⽂件存储在本地，也可以将配置⽂件存储在远程 Git 仓库，创建 Config Server，通过它管理所有微服务的配置⽂件。 本地文件系统 在父工程的基础上创建module—nativeconfigserver，pom.xml添加以下 123456789&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8072spring: application: name: nativeconfigserver profiles: active: native cloud: config: server: native: search-locations: classpath:/shared 属性说明 profiles.active：配置⽂件的获取⽅式，这里的native指本地获取 cloud.config.server.native.search-locations：本地配置⽂件存放的路径 在resources 路径下创建 shared ⽂件夹，并在此路径下创建 configclient-dev.yml。 123server: port: 8070foo: foo version 1 创建启动类---------NativeConfigServerApplication.java 12345678910111213package config.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class NativeConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NativeConfigServerApplication.class,args); &#125;&#125; 注解说明 @EnableConfigServer：声明该module为配置中⼼。 以上配置文件的服务已经创建完成，下面开始创建一个congifclient来读取上面我们创建的configserver中的configclient-dev文件的内容。 创建客户端读取本地配置中⼼的配置⽂件 在父工程的基础上创建module—nativeconfigclient，pom.xml文件添加依赖： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 bookstrap.yml ，注意这里的文件名，不再是application。 123456789spring: application: name: configclient profiles: active: dev cloud: config: uri: http://localhost:8072 fail-fast: true 属性说明 cloud.config.uri：本地 Config Server 的访问路径 cloud.config.fail-fase：设置客户端优先判断 Config Server 获取是否正常 通过 spring.application.name 结合 spring.profiles.active 拼接⽬标配置⽂件名(如上拼接的结果：configclient-dev)，configclient-dev.yml，去 Config Server 中查找该⽂件。 创建启动类---------NativeConfigClientApplication.java 1234567891011package configclient.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class NativeConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NativeConfigClientApplication.class,args); &#125;&#125; 创建controller 12345678910111213141516171819202122package configclient.lee.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/native\")public class ConfigClientCtroller &#123; @Value(\"$&#123;server.port&#125;\") private String port; @Value(\"$&#123;foo&#125;\") private String foo; @GetMapping(\"/index\") public String index()&#123; return this.port+ \" - \"+this.foo; &#125;&#125; 到此获取配置文件中心的客户端已创建完成，访问的端口号为要获取的配置文件中的端口号，即：8070，所以该客户端的访问地址为： http://localhost:8070/native/index ，之后网页显示配置中心shared下的文件的内容。 Spring Cloud Config 远程配置 在工程中创建配置⽂件，上传⾄ GitHub（创建config文件夹，然后在里面创建configclient.yml文件） 123456789server: port: 8070spring: application: name: configclienteureka: client: service-url: defaultZone: http://localhost:8071/eureka/ 创建一个githubconfigserver子工程，其pom.xml添加： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011121314151617181920server: port: 8888spring: application: name: configserver cloud: config: server: git: uri: https://github.com/Ctrl08/SpringCloud_Learn.git search-paths: config username: 123456 password: 123456 label: mastereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ # instance:# prefer-ip-address: true 创建启动类---------GithubConfigServerApplication.java 12345678910111213package githubconfig.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class GithubConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GithubConfigServerApplication.class,args); &#125;&#125; 到这里配置中心服务端已创建完成 创建客户端读取远程配置中⼼的配置⽂件 在父工程中创建maven工程，githubconfigclient，pom.xml文件添加依赖 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建bootstrap.yml配置文件 1234567891011121314spring: cloud: config: name: configclient label: master discovery: enabled: true service-id: configservereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性解释 spring.cloud.config.name：当前服务注册在 Eureka Server 上的名称，与远程仓库的配置⽂件名 对应 spring.cloud.config.label：Git Repository 的分⽀ spring.cloud.config.discovery.enabled：是否开启 Config 服务发现⽀持 spring.cloud.config.discovery.service-id：配置中⼼在 Eureka Server 上注册的名称 创建启动类---------GithubConfigClientApplication.java 1234567891011package configclient.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GithubConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GithubConfigClientApplication.class,args); &#125;&#125; 创建控制器 12345678910111213141516171819package configclient.lee.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/hello\")public class HelloController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/index\") public String index()&#123; return this.port; &#125;&#125; 到此远程配置中心基本创建完成，可以通过访问：http://localhost:8070/hello/index 查看client通过远程获取配置中心所设置的端口号。 服务跟踪 Zipkin Spring Cloud Zipkin 对请求进行跟踪 Zipkin 是⼀个可以采集并且跟踪分布式系统中请求数据的组件，让开发者可以更加直观的监控到请求在各个微服务所耗费的时间等，Zipkin：Zipkin Server(请求数据跟踪)、Zipkin Client(数据的展示)。 创建服务跟踪 Zipkin Server 在父工程创建maven子工程，pom.xml文件添加依赖： 1234567891011121314151617181920&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12server: port: 9090 创建服务端启动类---------ZipkinServerApplication.java 12345678910111213package zipkin.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import zipkin.server.internal.EnableZipkinServer;@SpringBootApplication@EnableZipkinServerpublic class ZipkinServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinServerApplication.class,args); &#125;&#125; 注解说明 @EnableZipkinServer：声明启动 Zipkin Server 到这里Zipkin Server创建完成。 创建服务跟踪 Zipkin Client 在父工程创建maven子工程，pom.xml添加依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8090spring: application: name: zipkinclient sleuth: web: client: enabled: true sampler: probability: 1.0 zipkin: base-url: http://localhost:9090/eureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性说明 spring.sleuth.web.client.enabled：设置开启请求跟踪 spring.sleuth.sampler.probability：设置采样⽐例，默认是 1.0 srping.zipkin.base-url：Zipkin Server 地址 创建启动类---------ZipkinClientApplication.java 1234567891011package zipkinclient;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ZipkinClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinClientApplication.class,args); &#125;&#125; 创建控制器controller 12345678910111213141516171819package zipkinclient.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/zipkin\")public class ZipkinController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/index\") public String index()&#123; return this.port; &#125;&#125; 到这里基本完成Zipkin的创建。 启动注册中心、zipkin server和zipkin client，访问：http://localhost:9090/zipkin即可进入数据请求监控的ui界面，点击 Find Traces 按钮即可开启跟踪请求，另开一个浏览页，访问：http://localhost:8090/zipkin/index，再回头看看刚才的页面，刷新页面就可以看到有请求发生并且追踪到了。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Redis实现一个简单的分布锁","slug":"Redis3","date":"2020-03-08T01:41:07.000Z","updated":"2020-03-08T04:06:13.246Z","comments":true,"path":"2020/03/08/Redis3/","link":"","permalink":"http://ctrl98.github.io/2020/03/08/Redis3/","excerpt":"","text":"什么是分布式锁 分布式锁在分布式系统中非常常见，比如对公共资源进行操作。 如卖车票，同一时刻只能有一个节点将某个特定座位的票卖出去；如避免缓存失效带来的大量请求访问数据库的问题 分布式锁需要解决的问题 互斥性：任意时刻只能有一个客户端获取锁 安全性：锁只能被持有该锁的客户端删除 死锁：某个客户端获取到锁，因某些原因宕机，使得其他客户端再也获取不了 容错：某个redis节点宕机，客户端仍然可以获取锁 实现 SETNX key value：如果key不存在，则创建并赋值 时间复杂度：o(1) 返回值：成功返回1，失败返回0 该操作是原子性的 123456789127.0.0.1:6379&gt; get locknx(nil)127.0.0.1:6379&gt; setnx locknx test(integer) 1127.0.0.1:6379&gt; setnx locknx task(integer) 0127.0.0.1:6379&gt; get locknx&quot;test&quot;127.0.0.1:6379&gt; 开始设置成功，说明目前该线程没有被占用，可以执行目前的代码块，如果设置失败，说明该线程目前被其他程序占用该资源，等待设置成功后再释放。。。 发现再后续再赋值locknx的时候失败了，说明此时该值是长期有效的。 如何解决setnx长期有效的问题 EXPIRE key seconds 设置key的生存时间，当key过期时，会被删除 1234567127.0.0.1:6379&gt; expire locknx 2(integer) 1127.0.0.1:6379&gt; setnx locknx task(integer) 1127.0.0.1:6379&gt; get locknx&quot;task&quot;127.0.0.1:6379&gt; 发现再设置的时候已经成功了 在实际代码中可以进行对返回值的判断： 12345678RedisService redisService = SpringUtils.getBean(RedisService.Class);long status = redisService.setnx(key,\"1\");if (status == 1)&#123; redisService.expire(key,expire) //执行独占资源逻辑 doOcuppieWork();&#125; 当有客户端请求该资源时发现status的值为0，说明有程序在占用该资源，后面的就不能执行了，线程进入阻塞，直到status的返回值为1为止。 然后这段程序会有风险，如果程序在执行完setnx后直接挂掉了，并没有进入到expire设置时间，这样key就永远不会过期，一直被占用着，导致其他程序再也获取不了该线程。 解决 将setnx和expire柔和在一起 SET key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置键的过期时间为second秒 PX milliseconds：设置键的过期时间为second毫秒 NX：只有键不存在时，才对键进行设置操作 XX：只有键已经存在时，才对键进行设置操作 SET操作返回值，成功ok，失败返回nil 1234567127.0.0.1:6379&gt; set locktarget 12345 ex 10 nxOK127.0.0.1:6379&gt; set locktarget 1234 ex 10 nx(nil)127.0.0.1:6379&gt; set locktarget 54321 ex 10 nxOK127.0.0.1:6379&gt; 过了10秒之后发现设置成功，符合redis的原子性操作。 因此伪代码也可以设置成： 123456RedisService redisService = SpringUtils.getBean(RedisService.Class);String result = redisService.set(lockkey,requestId,SET_NOT_EXIST,SET_WITH_EXPIRE_TIME,expiretime);if (\"ok\".equals(result))&#123; //执行独占资源逻辑 doOcuppieWork();&#125; 这样就能保证分布式锁操作的原子性了。 大量的key同时过期的注意事项 集中过期，由于清除大量过期的key很耗时，会出现卡顿现象 解决：在设置key的过期时间的时候，给每个key加上随机值","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Redis主从、哨兵及集群模式的配置","slug":"Redis2","date":"2020-03-07T13:02:19.000Z","updated":"2020-03-08T01:44:30.300Z","comments":true,"path":"2020/03/07/Redis2/","link":"","permalink":"http://ctrl98.github.io/2020/03/07/Redis2/","excerpt":"","text":"redis主从模式的配置 redis单例提供了一种数据缓存方式和丰富的数据操作api ，但是把数据完全存储再单个redis中会有两个问题：数据备份和数据量大造成性能低下。主从模式出现就是为了解决单例所带来的问题。 主从模式指： 使用一个redis实例作为主机，其余的实例作为备份机。主机和从机的数据完全一致。主机支持数据的写入和读取等各项操作，而从机则只支持与主机数据的同步和读取，也就是说，客户端可以将数据写入到主机，由主机自动将数据的写入操作同步到从机。 主从模式很好的解决了数据备份问题，并且由于主从服务数据几乎是一致的，因而可以将写入数据的命令发送给主机执行，而读取数据的命令发送给不同的从机执行，从而达到读写分离的目的。如下图的主机和三个从机。 至此redis主从模式的配置可以理解为多个不同的redis实例通过一定的配置告知其相互之间的主从关系。 主从模式的配置主要的配置点有两个： 当前实例端口号和当前实例是主机还是从机，是从机的话其主机的ip和端口是什么？ 一般的redis目录下的redis.conf保存的是默认配置，尽量不要对其进行修改. 这里我们复制三份redis.conf文件，分别命名为6379.conf，6380.conf和6381.conf 6379.conf的配置： 12bind 127.0.0.1port 6379 6380.conf和6381.conf的配置： 123bind 127.0.0.1port 6380slaveof 127.0.0.1 6379 123bind 127.0.0.1port 6381slaveof 127.0.0.1 6379 可以看到，端口为6380和6381的实例被配置为端口为6379的实例的从机。 配置完成后使用redis-server分别执行如下命令启动三个实例： 123.\\redis-server 6379.conf.\\redis-server 6380.conf.\\redis-server 6381.conf 启动之后分别开启三个命令行工具(即redis客户端)分别执行以下命令连接redis实例： 123.\\redis-cli -p 6379.\\redis-cli -p 6380.\\redis-cli -p 6381 分别在三个命令行工具中执行一个get命令，获取键名为msg的数据，如下所示： 12127.0.0.1:6379&gt; get msg(nil) 12127.0.0.1:6380&gt; get msg(nil) 12127.0.0.1:6381&gt; get msg(nil) 可以看到，在三个redis实例中都不存在键为msg的数据，现在我们在主机6379上设置一个键为msg的数据，如下所示： 12127.0.0.1:6379&gt; set msg &quot;hello&quot;OK 可以看到设置成功了，此时我们在6380和6381的实例上执行get msg的命令，如下所示： 12127.0.0.1:6380&gt; get msg&quot;hello&quot; 12127.0.0.1:6381&gt; get msg&quot;hello&quot; 可以看到，虽然我们只是在6379的实例上设置了msg这条数据，但是在6380和6381的实例上也存有了相应的数据，说明我们成功配置了redis的主从模式。另外，如果不在配置文件中指定主从节点的关系，也可以在启动相关redis实例之后使用slaveof命令来指定当前节点称为某个节点的从节点，如： 1127.0.0.1:6380&gt; slaveof 127.0.0.1 6379 redis中sentinel(哨兵)配置 redis主从模式解决了数据备份和单例可能存在的性能问题，但是其也引入了新的问题。 主从模式配置的几个实例，每个实例都会有不同的IP(如果在不同机器上)和端口号，从上面可知，主从模式将读写分配给不同的实例进行从而提高吞吐量，但是也会有另外一个问题，因为每个客户端连接redis都指定了IP和端口号，如果所连接的redis因故障下线，就只能手动去更改客户端配置重新连接，另外如果是主节点故障，那么那些从节点的同步会中断，也需要人工去转移工作。 为了解决以上问题，redis在2.8版本正式推出sentinel(哨兵)架构。 每个sentinel节点其实就是一个redis实例。与主从节点不同的是sentinel节点作用是用于监控redis数据节点的，而sentinel节点集合则表示监控一组主从redis实例多个sentinel监控节点的集合。 比如有主节点master和从节点slave-1、slave-2，为了监控这三个主从节点，这里配置N个sentinel节点sentinel-1，sentinel-2，...，sentinel-N。 对于一组主从节点，sentinel只是在其外部额外添加的一组用于监控作用的redis实例。在主从节点和sentinel节点集合配置好之后，sentinel节点之间会相互发送消息，以检测其余sentinel节点是否正常工作，并且sentinel节点也会向主从节点发送消息，以检测监控的主从节点是否正常工作。 前面讲到，sentinel架构的主要作用是解决主从模式下主节点的故障转移工作的。这里如果主节点因为故障下线，那么某个sentinel节点发送检测消息给主节点时，如果在指定时间内收不到回复，那么该sentinel就会主观的判断该主节点已经下线，那么其会发送消息给其余的sentinel节点，询问其是否“认为”该主节点已下线，其余的sentinel收到消息后也会发送检测消息给主节点。 如果其认为该主节点已经下线，那么其会回复向其询问的sentinel节点，告知其也认为主节点已经下线，当该sentinel节点最先收到超过指定数目（配置文件中配置的数目和当前sentinel节点集合数的一半，这里两个数目的较大值）的sentinel节点回复说当前主节点已下线，那么其就会对主节点进行故障转移工作，故障转移的基本思路是在从节点中选取某个从节点向其发送slaveof no one（假设选取的从节点为127.0.0.1:6380），使其称为独立的节点（也就是新的主节点），然后sentinel向其余的从节点发送slaveof 127.0.0.1 6380命令使它们重新成为新的主节点的从节点。 重新分配之后sentinel节点集合还会继续监控已经下线的主节点（假设为127.0.0.1:6379），如果其重新上线，那么sentinel会向其发送slaveof命令，使其成为新的主机点的从节点，如此故障转移工作完成。 简单来说就是：当redis服务为主从的时候如果主节点挂掉，则会选取一个从节点为master，当以前的master重启之后不再是master而为slave。 创建并修改sentinel.conf 复制三个配置文件：sentinel-26379.conf，sentinel-26380.conf和sentinel-26381.conf。分别按照如下示例编辑这三个配置文件 123456789101112131415port 26379 daemonize yes logfile &quot;26379.log&quot; dir &#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000sentinel myid mm55d2d712b1f3f312b637f9b546f00cdcedc787#port 26379#sentinel monitor mymaster 127.0.0.1 6379 2#sentinel down-after-milliseconds mymaster 5000#sentinel failover-timeout mymaster 15000#sentinel myid 88a3f92f656984fd84c183b6b183d5d264ddc485 属性说明 port：当前Sentinel服务运行的端口 sentinel monitor mymaster 127.0.0.1 6379 2：Sentinel去监视一个名为mymaster的主redis实例，这个主实例的IP地址为本机地址127.0.0.1，端口号为6379，而将这个主实例判断为失效至少需要2个 Sentinel进程的同意，只要同意Sentinel的数量不达标，自动failover就不会执行 sentinel down-after-milliseconds mymaster 5000：指定了Sentinel认为Redis实例已经失效所需的毫秒数。当 实例超过该时间没有返回PING，或者直接返回错误，那么Sentinel将这个实例标记为主观下线。只有一个 Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移：只有在足够数量的Sentinel都将一个实例标记为主观下线之后，实例才会被标记为客观下线，这时自动故障迁移才会执行 sentinel failover-timeout mymaster 15000：如果在该时间（ms）内未能完成failover操作，则认为该failover失败 myid：区分每个监控的哨兵的身份 分别使用三个配置文件使用如下命令启用sentinel 123.&#x2F;src&#x2F;redis-sentinel sentinel-26379.conf.&#x2F;src&#x2F;redis-sentinel sentinel-26380.conf.&#x2F;src&#x2F;redis-sentinel sentinel-26381.conf 由于sentinel节点也是一个redis实例，因而我们可以通过如下命令使用redis-cli连接sentinel节点： 1.&#x2F;src&#x2F;redis-cli -p 26379 连上sentinel节点之后我们可以通过如下命令查看sentinel状态： 1127.0.0.1:26379&gt; info sentinel 结果如下： 1234567# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;127.0.0.1:6379,slaves&#x3D;2,sentinels&#x3D;3 可以看到，sentinel检测到主从节点总共有三个，其中一个主节点，两个从节点，并且sentinel节点总共也有三个。启动完成之后，我们可以通过主动下线主节点来模拟sentinel的故障转移过程。首先我们连接上端口为6379的主节点，使用如下命令查看主从节点状态： 1127.0.0.1:6379&gt; info replication 结果如下： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;45616,lag&#x3D;1slave1:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;45616,lag&#x3D;1master_repl_offset:45616repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:45615 可以看到，当前主节点有两个从节点，端口分别为6380和6381。然后我们对主节点执行如下命令： 1127.0.0.1:6379&gt; shutdown save 然后我们连接上端口号为6380的从节点，并执行如下命令： 1127.0.0.1:6380&gt; info replication 结果如下： 123456789# Replicationrole:masterconnected_slaves:1slave0:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;12344,lag&#x3D;0master_repl_offset:12477repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:12476 可以看到，当端口为6379的实例下线之后，端口为6380的实例被重新竞选为新的主节点，并且端口为6381的实例被设置为6380的实例的从节点。如果我们此时重新启用端口为6379的节点，然后再查看主从状态，结果如下： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;59918,lag&#x3D;0slave1:ip&#x3D;127.0.0.1,port&#x3D;6379,state&#x3D;online,offset&#x3D;59918,lag&#x3D;1master_repl_offset:60051repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:60050 可以看到，端口为6379的redis实例重新连接后，sentinel节点检测到其重新连接，那么对其发送命令，使其成为新的主节点的从节点。 redis集群的配置 redis集群是在redis 3.0版本推出的一个功能，其有效的解决了redis在分布式方面的需求。当遇到单机内存，并发和流量瓶颈等问题时，可采用Cluster方案达到负载均衡的目的。并且从另一方面讲，redis中sentinel有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。 对于redis集群的配置，首先将redis安装目录下的redis.conf文件复制六份，分别取名为：cluster-6379.conf、cluster-6380.conf、cluster-6381.conf、cluster-6382.conf、cluster-6383.conf、cluster-6384.conf。对于一个高可用的集群方案，集群每个节点都将为其分配一个从节点，以防止数据节点因为故障下线，这里使用六份配置文件定义六个redis实例，其中三个作为主节点，剩余三个分别作为其从节点。对于这六份配置文件，以其中一份为例，以下是其需要修改的参数： 12345678port 6379cluster-enabled yescluster-node-timeout 15000cluster-config-file &quot;nodes-6379.conf&quot;pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pidlogfile &quot;cluster-6379.log&quot;dbfilename dump-cluster-6379.rdbappendfilename &quot;appendonly-cluster-6379.aof&quot; 对于其余的配置文件，只需要将其中对应项的端口号和带有端口号的文件名修改为当前要指定的端口号和端口号的文件名即可。配置文件配置好之后使用如下命令启动集群中的每个实例： 123456.&#x2F;src&#x2F;redis-server cluster-6379.conf.&#x2F;src&#x2F;redis-server cluster-6380.conf.&#x2F;src&#x2F;redis-server cluster-6381.conf.&#x2F;src&#x2F;redis-server cluster-6382.conf.&#x2F;src&#x2F;redis-server cluster-6383.conf.&#x2F;src&#x2F;redis-server cluster-6384.conf 仔细阅读上述配置文件可发现，当前配置和启动过程中并没有指定这六个实例的主从关系，也没有对16384个槽位进行分配。因而我们还需要进行进一步的配置，槽位的分配和主从关系的设定有两种方式进行，一种是使用redis-cli连接到集群节点上后使用cluster meet命令连接其他的节点，如我们首先执行如下命令连接到6379端口的节点： 1.&#x2F;src&#x2F;redis-cli -p 6379 连接上后使用cluster meet命令分别连接其余节点： 12345127.0.0.1:6379&gt;cluster meet 127.0.0.1 6380127.0.0.1:6379&gt;cluster meet 127.0.0.1 6381127.0.0.1:6379&gt;cluster meet 127.0.0.1 6382127.0.0.1:6379&gt;cluster meet 127.0.0.1 6383127.0.0.1:6379&gt;cluster meet 127.0.0.1 6384 连接好后可以使用cluster nodes命令查看当前集群状态： 1234567127.0.0.1:6379&gt; cluster nodes4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1:6384 master - 0 1468073975551 5 connectedcfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1:6379 myself,master - 0 0 0 connectedbe9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1:6383 master - 0 1468073978579 4 connected40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1:6382 master - 0 1468073980598 3 connected8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1:6380 master - 0 1468073974541 1 connected40b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1:6381 master - 0 1468073979589 2 connected 可以看到配置的六个节点都已经加入到了集群中，但是其现在还不能使用，因为还没有将16384个槽分配到集群节点中。虚拟槽的分配可以使用redis-cli分别连接到6379，6380和6381端口的节点中，然后分别执行如下命令： 123127.0.0.1:6379&gt;cluster addslots &#123;0...5461&#125;127.0.0.1:6380&gt;cluster addslots &#123;5462...10922&#125;127.0.0.1:6381&gt;cluster addslots &#123;10923...16383&#125; 添加完槽位后可使用cluster info命令查看当前集群状态： 123456789101112127.0.0.1:6379&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:5cluster_my_epoch:0cluster_stats_messages_sent:4874cluster_stats_messages_received:4726 这里我们将16384个虚拟槽位分配给了三个节点，而剩余的三个节点我们通过如下命令将其配置为这三个节点的从节点，从而达到高可用的目的： 123456127.0.0.1:6382&gt;cluster replicate cfb28ef1deee4e0fa78da86abe5d24566744411eOK127.0.0.1:6383&gt;cluster replicate 8e41673d59c9568aa9d29fb174ce733345b3e8f1OK127.0.0.1:6384&gt;cluster replicate 40b8d09d44294d2e23c7c768efc8fcd153446746OK 如此，所有的集群节点都配置完毕，并且处于可用状态。这里可以使用cluster nodes命令查看当前节点的状态： 1234567127.0.0.1:6379&gt; cluster nodes4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1:6384 slave 40b8d09d44294d2e23c7c768efc8fcd153446746 0 1468076865939 5 connectedcfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1:6379 myself,master - 0 0 0 connected 0-5461be9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1:6383 slave 8e41673d59c9568aa9d29fb174ce733345b3e8f1 0 1468076868966 4 connected40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1:6382 slave cfb28ef1deee4e0fa78da86abe5d24566744411e 0 1468076869976 3 connected8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1:6380 master - 0 1468076870987 1 connected 5462-1092240b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1:6381 master - 0 1468076867957 2 connected 10923-16383 我们使用redis-cli使用如下命令连接集群： 1.&#x2F;src&#x2F;redis-cli -c -p 6380 注意连接集群模式的redis实例时需要加上参数-c，表示连接的是集群模式的实例。连接上后执行get命令： 123127.0.0.1:6380&gt; get hello-&gt; Redirected to slot [866] located at 127.0.0.1:6379(nil) 可以看到，在6380端口的实例上执行get命令时，其首先会为当前的键通过一致哈希算法计算其所在的槽位，并且判断该槽位不在当前redis实例中，因而重定向到目标实例上执行该命令，最后发现没有该键对应的值，因而返回了一个（nil）。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Redis数据缓存 基础知识","slug":"Redis1","date":"2020-03-06T01:12:22.000Z","updated":"2020-03-08T07:47:46.848Z","comments":true,"path":"2020/03/06/Redis1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Redis1/","excerpt":"","text":"主流应用架构 穿透查询：请求数据的时候先到缓存层查询数据，当缓存层没有数据，在穿透到存储层查询 回种：穿透查询完成后再缓存到缓存区 熔断：当存储层挂了之后，会自动从缓存层获取并返回数据，无论有没有获取到数据都返回 缓存中间件——Memcache和Redis的区别 Memcache：代码层次类似Hash 优缺点： 支持简单数据类型 不支持数据持久化存储 不支持主从 不支持分片(把数据库打碎的过程，将大数据分布到各个物理节点上) Redis 优缺点： 数据类型丰富 支持数据持久化存储 支持主从 支持分片(3.0版本后) 为什么Redis能这么快？ 100000+QPS（QPS即query per second，每秒内查询次数） 完全基于内存，绝大部分请求时纯粹的内存操作，执行效率高 数据结构简单，对数据操作也简单 采用单线程，单线程也能处理高并发请求，想多核也可以启动多实例 使用多路复用I/O复用模型，非阻塞IO redis单例的安装及配置使用 win10本地安装redis服务 进入根目录，配置redis.windows.conf： 添加配置需要密码验证 requirepass 123456 修改 appendonly 为yes 开启aof日志防止数据丢失 根目录处以管理员身份打开cmd 输入启动命令启动服务端： 12.\\redis-server.exe redis.windows.conf###注意如果提示错误，把前面的.\\请去掉再回车试试 如果需要按照指定的配置文件来启动，可在redis-server.exe后接上配置文件名 : 1.\\redis-server.exe redis1.conf 再打开一个cmd窗口启动客户端： 1.\\redis-cli.exe 然后输入认证密码命令连接服务： 1auth 123456 显示ok即连接成功，输入ping测试看是否返回pong。 如果需要连接指定ip和端口的客户端，可以使用如下方式 : 1.\\redis-cli.exe -h 127.0.0.1 -p 6379 Redis数据类型 String类型 redis最基本的数据类型，k-v存储，最大能存储512M，二进制安全(即可以包含任何数据，如jpg图片、序列化对象…) 简单操作 1234567891011121314151617127.0.0.1:6379&gt; set name &quot;redis&quot;OK127.0.0.1:6379&gt; get name&quot;redis&quot;127.0.0.1:6379&gt; set name &quot;memocache&quot;OK127.0.0.1:6379&gt; get name&quot;memocache&quot;127.0.0.1:6379&gt; set count 1OK127.0.0.1:6379&gt; get count&quot;1&quot;127.0.0.1:6379&gt; incr count(integer) 2127.0.0.1:6379&gt; get count&quot;2&quot;127.0.0.1:6379&gt; Hash类型 string元素组成的字典，适合用于存储对象 简单操作 1234567891011127.0.0.1:6379&gt; hmset lilei name &quot;lilei&quot; age 18 title &quot;senior&quot;OK127.0.0.1:6379&gt; hget lilei age&quot;18&quot;127.0.0.1:6379&gt; hget lilei title&quot;senior&quot;127.0.0.1:6379&gt; hset lilei title &quot;collge&quot;(integer) 0127.0.0.1:6379&gt; hget lilei title&quot;collge&quot;127.0.0.1:6379&gt; List类型 列表，按照String元素插入顺序排序，可以添加元素到列表的头部或尾部，元素先进后出，(最新排行榜) 简单操作 1234567891011127.0.0.1:6379&gt; lpush mylist aaa(integer) 1127.0.0.1:6379&gt; lpush mylist bbb(integer) 2127.0.0.1:6379&gt; lpush mylist ccc(integer) 3127.0.0.1:6379&gt; lrange mylist 0 101) &quot;ccc&quot;2) &quot;bbb&quot;3) &quot;aaa&quot;127.0.0.1:6379&gt; Set类型 String元素组成的无须集合，通过哈希表表现，不允许重复，(微博的互相关注) 简单操作 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; sadd myset 111(integer) 1127.0.0.1:6379&gt; sadd myset 222(integer) 1127.0.0.1:6379&gt; sadd myset 333(integer) 1127.0.0.1:6379&gt; sadd myset 333(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;111&quot;2) &quot;222&quot;3) &quot;333&quot;127.0.0.1:6379&gt; sadd myset abc(integer) 1127.0.0.1:6379&gt; sadd myset abd(integer) 1127.0.0.1:6379&gt; sadd myset abb(integer) 1127.0.0.1:6379&gt; sadd myset abd(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;abc&quot;2) &quot;222&quot;3) &quot;abd&quot;4) &quot;abb&quot;5) &quot;333&quot;6) &quot;111&quot;127.0.0.1:6379&gt; Sorted Set类型 通过分数score来为集合中的成员进行从小到大排序，去重 简单操作 12345678910111213141516127.0.0.1:6379&gt; zadd myzset 3 abc(integer) 1127.0.0.1:6379&gt; zadd myzset 1 abd(integer) 1127.0.0.1:6379&gt; zadd myzset 2 abb(integer) 1127.0.0.1:6379&gt; zadd myzset 2 abb(integer) 0127.0.0.1:6379&gt; zadd myzset 1 bgg(integer) 1127.0.0.1:6379&gt; zrangebyscore myzset 0 101) &quot;abd&quot;2) &quot;bgg&quot;3) &quot;abb&quot;4) &quot;abc&quot;127.0.0.1:6379&gt; 缓存雪崩 什么是缓存雪崩？ 如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩 由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。 有什么解决方案来防止缓存雪崩？ 加锁排队 mutex互斥锁解决，Redis的SETNX去set一个mutex key，当操作返回成功时，再进行加载数据库的操作并回设缓存，否则，就重试整个get缓存的方法 数据预热 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据。可以通过缓存reload机制，预先去更新缓存，在即将发生大并发访问前手动触发加载缓存不同的key。 双层缓存策略 C1为原始缓存，C2为拷贝缓存，C1失效时，可以访问C2，C1缓存失效时间设置为短期，C2设置为长期 定时更新缓存策略 实效性要求不高的缓存，容器启动初始化加载，采用定时任务更新或移除缓存 设置不同的过期时间，让缓存失效的时间点尽量均匀 缓存击穿 什么是缓存击穿？ 在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 会带来什么问题 会造成某一时刻数据库请求量过大，压力剧增。 如何解决 上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它，其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。 缓存穿透 什么是缓存穿透？ 缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到对应key的value，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库。 有什么解决方案来防止缓存穿透？ 缓存空值 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障）我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过5分钟。通过这个设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库。 采用布隆过滤器BloomFilter 优势：占用内存空间很小，位存储；性能特别高，使用key的hash判断key存不存在 将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力 在缓存之前在加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查询缓存，缓存中没有再去查询数据库","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Mysql 基础知识（一）","slug":"Mysql1","date":"2020-03-06T01:05:41.000Z","updated":"2020-03-24T12:10:02.092Z","comments":true,"path":"2020/03/06/Mysql1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Mysql1/","excerpt":"","text":"where子句 **where：**数据库中常用的是where关键字，用于在初始表中筛选查询。它是一个约束声明，用于约束数据，在返回结果集之前起作用。 **group by:**对select查询出来的结果集按照某个字段或者表达式进行分组，获得一组组的集合，然后从每组中取出一个指定字段或者表达式的值。 **having：**用于对where和group by查询出来的分组经行过滤，查出满足条件的分组结果。它是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作。 执行顺序 select –&gt;where –&gt; group by–&gt; having–&gt;order by update 当我们需要将字段中的特定字符串批量修改为其他字符串时，可已使用以下操作： 12UPDATE runoob_tbl SET runoob_title &#x3D; REPLACE(runoob_title, &#39;C++&#39;, &#39;Python&#39;) where runoob_id &#x3D; 3; delete delete，drop，truncate 都有删除表的作用，区别在于： 1、delete 和 truncate 仅仅删除表数据，drop 连表数据和表结构一起删除，打个比方，delete 是单杀，truncate 是团灭，drop 是把电脑摔了。 2、delete 是 DML 语句，操作完以后如果没有不想提交事务还可以回滚，truncate 和 drop 是 DDL 语句，操作完马上生效，不能回滚，打个比方，delete 是发微信说分手，后悔还可以撤回，truncate 和 drop 是直接扇耳光说滚，不能反悔。 3、执行的速度上，drop&gt;truncate&gt;delete，打个比方，drop 是神舟火箭，truncate 是和谐号动车，delete 是自行车。 like子句 LIKE 子句中使用百分号 **%**字符来表示任意字符，类似于UNIX或正则表达式中的星号 ***** 如果没有使用百分号 %, LIKE 子句与等号 = 的效果是一样的 like 匹配/模糊匹配，会与 % 和 _ 结合使用： 123456&#39;%a&#39; &#x2F;&#x2F;以a结尾的数据&#39;a%&#39; &#x2F;&#x2F;以a开头的数据&#39;%a%&#39; &#x2F;&#x2F;含有a的数据&#39;_a_&#39; &#x2F;&#x2F;三位且中间字母是a的&#39;_a&#39; &#x2F;&#x2F;两位且结尾字母是a的&#39;a_&#39; &#x2F;&#x2F;两位且开头字母是a的 union 操作符 UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。 union 实例： 1SELECT country FROM Websites UNION SELECT country FROM apps ORDER BY country 查两张表中的同一个字段的不同值都查询出来（去重） union all 实例： 1SELECT country FROM Websites UNION ALL SELECT country FROM apps ORDER BY country 查两张表中的同一个字段的相同的值都查出来（不去重） order by 子句排序 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列 。 1SELECT * from runoob_tbl ORDER BY submission_date ASC; 拼音排序 字符集采用的是 gbk(汉字编码字符集) ，直接 order by就行 字符集采用的是 utf8(万国码) ， 先对字段进行转码然后排序 ORDER BY CONVERT(runoob_title using gbk); group up 子句 例如： 将数据表按名字进行分组，并统计每个人有多少条记录 1SELECT name, COUNT(*) FROM employee_tbl GROUP BY name; with rollup 可以实现在分组统计数据基础上再进行相同的统计（SUM,AVG,COUNT…） 1SELECT name, SUM(singin) as singin_count FROM employee_tbl GROUP BY name WITH ROLLUP; join 连接 需要从多个数据表中读取数据，JOIN 在两个或多个表中查询数据 INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录 比如：读取runoob_tbl表中所有runoob_author字段在tcount_tbl表对应的runoob_count字段值 语法举例：Select A.Name from A INNER JOIN B ON A.id =B.id 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a INNER JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; 等价于： 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a, tcount_tbl b WHERE a.runoob_author &#x3D; b.runoob_author; **LEFT JOIN（左连接）：**获取左表所有记录，即使右表没有对应匹配的记录 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a LEFT JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a RIGHT JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; alter 删除表字段 1ALTER TABLE testalter_tbl DROP i; 添加表字段 1ALTER TABLE testalter_tbl ADD i INT; 修改表字段类型及名称： MODIFY 或 CHANGE 子句 ​ 把字段 c 的类型从 CHAR(1) 改为 CHAR(10) 1ALTER TABLE testalter_tbl MODIFY c CHAR(10); ​ 使用 CHANGE 子句, 语法有很大的不同。 在 CHANGE 关键字之后，紧跟着的是你要修改的字段名，然后指定新字段名及类型 1ALTER TABLE testalter_tbl CHANGE i j BIGINT; 修改表名 1ALTER TABLE testalter_tbl RENAME TO alter_tbl; 删除重复数据 如果你想删除数据表中的重复数据，你可以使用以下的SQL语句： 123mysql&gt; CREATE TABLE tmp SELECT last_name, first_name, sex FROM person_tbl GROUP BY (last_name, first_name, sex);mysql&gt; DROP TABLE person_tbl;mysql&gt; ALTER TABLE tmp RENAME TO person_tbl; 也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。方法如下： 12mysql&gt; ALTER IGNORE TABLE person_tbl -&gt; ADD PRIMARY KEY (last_name, first_name);","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://ctrl98.github.io/tags/MySQL/"}]},{"title":"Git Bash基础操作","slug":"Git1","date":"2020-03-06T00:48:45.000Z","updated":"2020-03-25T06:57:58.675Z","comments":true,"path":"2020/03/06/Git1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Git1/","excerpt":"","text":"Git基本操作 安装： 根据系统自己选择下载傻瓜式安装 配置： 用户名： 1$ git config --global user.name &quot;你的账号&quot; 邮箱： 1$ git config --global user.email &quot;你的邮箱账号&quot; 查看全局配置命令： 1$ cat ~&#x2F;.gitconfig 初始化： 新建一个文件夹，再当前目录下打开git bash 执行命令： 1$ git init 查看状态： 在当前目录新建一个README.md文档； 查看当前git仓库状态： 1$ git status 提交新建文档到缓存区命令： 1$ git add README.md 再次查看当前git仓库状态： 截图中也提示，如果想取消本次提交，可执行： 1$ git rm --cached README.md 提交新文件到暂存区： 提交命令： 1$ git add README.md 当前目录下全部文件都提交： 1$ git add -A 提交新内容到git本地仓库： 提交命令： 1$ git commit -m &quot;add README.md&quot; m：message，输入你本次提交的内容或日志 设置要提交到的远程仓库： 先到自己的github创建新的空白远程仓库； 命令： 1$ git remote add origin https:&#x2F;&#x2F;github.com&#x2F;ctrl98&#x2F;git-test.git 查看当前远程仓库的信息： 1$ git remote -v 提交新内容到远程仓库命令： 1$ git push -u origin master 参数说明： -u：第一次提交的时候加上这个属性，以后提交只需要输入：git push即可 -origin：远端链接的名字，创建远程仓库时默认 -master：仓库主干分支 克隆远程仓库项目到本地： 命令： 1$ git clone https:&#x2F;&#x2F;github.com&#x2F;ctrl98&#x2F;git-test.git 更新远程仓库代码到本地： 远程仓库做了修改，本地仓库还是旧的，可执行拉取命令： 1$ git pull Git分支 分支互相独立，互不影响 创建新的分支： 1$ git branch feature1 查看当前分支列表： 1$ git branch 切换分支： 1$ git checkout feature1 查看当前分析目录信息，可发现有master主干上的文件： 在feature1分支下创建a.txt文件，并编辑文件内容：this is a.txt，保存并退出。 commit feature1的文件到本地仓库中。 再创建一个新的分支并切换到该分支： 1$ git checkout -d feature2 查看一下该分支的目录文件信息，发现有master的README.md文档和feature1的a.txt文档，也就是说是基于feature1的，新分支的内容是基于上个分支的内容。 查看文件内容命令： 1$ cat a.txt 分支简单合并 合并命令： 1$ git merge 分支名称 创建并切换到分支feature3: 1$ git checkout -b feature3 新建b.txt文件，并编写内容：hello world： 12touch b.txt;vi b.txt 提交该文件到本地仓库中： 12git add b.txtgit commit -m &quot;add b.txt&quot; 切换回master主分支中： 1$ git checkout master 删除feature3分支： 1$ git branch -d feature3 发现无法删除，因为feature3中本地仓库中有提交，提示你要么合并该分支到master，要么就强制删除分支 合并feature3到master主分支，Head指针执行master： 1$ git merge feature3 提示合并成功 远程仓库创建分支显示 切换到需要再远程仓库中显示的分支： 1$ git checkout feature1 输入设置命令： 1$ git push origin feature1 这个时候远程仓库就会有一个feature1分支显示 也可以起别名： 1$ git push origin feature1:f1 删除远程仓库分支 本地git命令行切换到要删除远程的分支 输入删除命令： 1git push origin :feature1 查看Git日志 命令： 1git log 更简洁地查看： 1git log --oneline 如果提交次数多的话，还可以指定查看最新的提交范围： 1git log --oneline -5 想要查看某一次提交了什么新的内容，可以先复制日志对应的ID，然后执行： 1git show +id 合并操作 清空上面创建的分支，只留下master –ff 方式 创建并切换至f1分支 创建fa.txt文件并提交到本地仓库 查看日志： 1git log --oneline 发现指针HEAD指向了f1 切换回master分支进行合并 (默认使用 --ff 模式) ： 12git checkout mastergit merge f1 此时使用的是 fast-forward 方式合并策略，也就是默认的 --ff 模式，可以通过 git merge --help查看相关模式， 这种方式不会创建一个新的commit，只会显示f1分支提交的message。 –no-ff 方式 保证了原有开发的提交量的完整性 切换回f1分支 创建fb.txt文件并提交到本地仓库： 123touch fb.txtgit add fb.txtgit commit -m &quot;add fb.txt&quot; 切换回master分支进行合并： 12git checkout mastergit merge f1 --no-ff 这个时候会进入一个界面，产生了一条message，叫 Merge branch ‘f1’，我们可以修改这个message，默认不修改，保存退出，这个时候发行合并的策略变为：Merge made by the ‘recursive’ strategy，此时查看log日志会出现拐弯现象，把f1的commit和合并时的message两个commit都显示出来了。 提交到远程仓库，并创建远程仓库分支f1： 12git pushgit push origin f1:f1 打开github的远程仓库，添加master下的a.txt文件内容： 1update 这个时候远程仓库是最新的版本，本地是较旧的版本 回到本地仓库，同步远程master分支的内容到本地： 1git pull 切换到f1分支，f1分支想要拿到master的最新版本，需要merger一下master，才能和master保持同步： 1git merge master 再查看一下日志，发现日志对于本次同步只显示了一条 update a.txt 的信息，并没有出现拐弯 这个时候master有人作了修改，且回到master分支： 12345git checkout mastertouch m1.txtgit add m1.txtgit commit -m &quot;add m1.txt&quot;git log --oneline rebase命令 再回到f1分支，如果我们使用git rebase命令来合并，将f1这个分支移动到master分支的最后一次提交，会把master所有提交并入过来： 12git rebase masterll 再次查看log日志，会发现在f1中会产生一条新的提交，叫&quot;add m1.txt&quot;，重写了项目的提交历史，并且不会带来一条 merge 的commit. rebase最大的好处： 就是使得提交的历史不会出现分叉，项目提交历史看着非常整齐，他不会像 git merge 那样引入一条分叉 rebase的缺点：安全性和可跟踪性，不要在master上使用rebase命令，rebase命令他不是合并操作，而是复制操作，而merge命令是把两个分支的内容合并到一起。 简单处理合并冲突 在f1分支基础上再创建一个f2分支，并随便修改一下a.txt的内容，保存退出提交到本地仓库： 12git checkout -b f2vi a.txt 回到f1分支，同样修改a.txt文件内容并提交到本地仓库： 12git chrckout f1vi a.txt 再次回到f2分支，这个时候想拉取一下f1同学写的代码： 12git checkout f2git merge f1 这个时候会出现文件冲突，需要解决冲突，查看一下a.txt文件： 1cat a.txt 发现文件内容很乱，显示两个分支上对这个文件的不同修改的内容，要么使用f1的要么使用f2的，然后修改a.txt，就会看到刚才查看到的内容： 1vi a.txt 这样修改很麻烦，实际开发中会用工具下来修改 使用mergetool命令来检测冲突并解决冲突： 1git mergetool 再次回车使用vimdiff来解决冲突，把不需要保留的内容删除，然后保存退出，再看一下a.txt文件： 1cat a.txt 发现内容已经修改为刚才保留下来的内容，然后再commit一下： 1git commit -m &quot;update a.txt&quot; Git的回滚撤销 git reset 分支名^ 回到上一次提交的版本，他只是把HEAD指针移动了，并没有删除东西，默认是–mixed模式（本次提交的东西从暂存区撤销，但仍留在工作区中），在master分支下： 123touch hello.javagit add hello.javagit commit -m &quot;add hello.java&quot; 此时查看log，会发现已经有本条提交记录，这个时候想回退上个版本： 1git reset master^ # ^符号代表上一次的意思 查看状态： 1git status 发现hello.java文件处于未提交状态 同样也可以直接： 1git reset 版本码(查看每条日志前的唯一标识) hard模式简单粗暴，直接还原上个版本的东西，暂存区、工作目录都清空本次更新的内容： 1git reset --hard 版本号 git revert 此次操作之前和之后的commit和history都会保留，并且把这次撤销作为一次最新的提交，用新的commit来回滚上一个版本； 1git revert 版本号 执行后会产生一次commit，填写提交的message，直接保存退出，他就把删除了revert那个版本的东西，比如那次提交是新建了一个文件，执行revert后，那个文件就不存在，但是那次提交commit的message就更新为 revert … 所以，在公共分支上使用 git revert，会把提交的信息记录保存下来，可以回溯，在其他分支，可以直接 git reset回退 Git 工作基本流程 最后附上Git命令大全","categories":[{"name":"Git","slug":"Git","permalink":"http://ctrl98.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://ctrl98.github.io/tags/Git/"},{"name":"版本控制工具","slug":"版本控制工具","permalink":"http://ctrl98.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"使用Dockerfile创建镜像","slug":"Docker6","date":"2020-02-27T05:43:51.000Z","updated":"2020-02-27T06:38:09.608Z","comments":true,"path":"2020/02/27/Docker6/","link":"","permalink":"http://ctrl98.github.io/2020/02/27/Docker6/","excerpt":"","text":"什么是Dockerfile文件 Dockerfile文件其实就是一个文本文件，由一系列命令和参数构成，Docker可以读取Dockerfile文件并根据Dockerfile文件的描述构建镜像。 Dockerfile文件内容一般为4个部分 基础镜像信息 维护者信息 镜像操作命令 容器启动时执行的命令 Dockerfile常用命令 命令 作用 FROM image_name:tag 定义了使用哪个基础镜像启动构建流程 MAINTAINER user_name 声明镜像的创建者 EVN key value 声明环境变量(可以多条) RUN command 是Dockerfile核心部分(可以写多条) ADD source_dir/file dest_dir/file 将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压 COPY source_dir/file dest_dir/file 和上一条一样，不同的是不自动解压 WORKDIR path_dir 设置工作目录 目标 使用Dockerfile构建一个包含jdk11环境的centos7镜像。 分析： ​ 假设以centos7作为基础镜像，添加jdk11并构建一个包含jdk1.8的centos7新镜像，使用Dockerfile可以实现。 步骤： 拉取centos7镜像 上传jdk11压缩包 编写Dockerfile文件 构建镜像 测试（基于新镜像创建并启动容器，测试jdk版本） 拉取centos7镜像 这个不作过多解释，直接使用 docker pull centos:7命令拉取。 上传jdk文件到宿主机 创建目录： 1mkdir &#x2F;usr&#x2F;local&#x2F;dockerjdk11 使用 WinSCP 软件来上传本地电脑文件到虚拟机centos系统dockerjdk11目录下，也不作过多解释，下载软件后直接输入虚拟机的IP地址，用户名和密码即可登录，端口默认是 22； 编写Dockerfile文件 在/usr/local/dockerjdk11目录下使用vi命令进行编写： 1vi Dockerfile 内容为： 123456789FROM centos:7MAINTAINER 23h59m59sWORKDIR &#x2F;usrRUN mkdir &#x2F;usr&#x2F;local&#x2F;javaADD jdk-11.0.5_linux-x64_bin.tar.gz &#x2F;usr&#x2F;local&#x2F;java&#x2F;ENV JAVA_HOME &#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk-11.0.5ENV JRE_HOME $JAVA_HOME&#x2F;jreENV CLASSPATH $JAVA_HOME&#x2F;lib&#x2F;dt.jar:JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;lib:$CLASSPATHENV PATH $JAVA_HOME&#x2F;bin:$PATH 按Esc键，然后英文状态下输入 : 键，然后紧接着输入 wq 保存并退出。 构建镜像 输入构建镜像命令： 1docker build -t&#x3D;&#39;jdk11&#39; . -t：要构建的镜像的名称 .：这个点不能省略，表示当前目录下 等到successfully 查看当前镜像列表是否构建成功： 1docker images 测试（基于新镜像创建并启动容器，测试jdk版本） 基于构建的新镜像jdk11创建并启动容器： 1docker run -it --name&#x3D;newtestjdk11 jdk11 &#x2F;bin&#x2F;bash 创建成功后自动进入该容器，测试jdk版本： 1java -version 发现显示jdk的版本为11.0.5","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker容器的备份、迁移与恢复","slug":"Docker5","date":"2020-02-27T04:13:17.000Z","updated":"2020-02-27T05:08:04.763Z","comments":true,"path":"2020/02/27/Docker5/","link":"","permalink":"http://ctrl98.github.io/2020/02/27/Docker5/","excerpt":"","text":"容器的备份、迁移与恢复 其中涉及到的命令： docker commit：将容器保存为镜像 docker save：将镜像备份为tar文件 docker load：根据tar文件恢复为镜像 容器备份 目标：能够将服务器A的某个容器保存为镜像，备份成tar文件，迁移到服务器B恢复镜像再启动以恢复的镜像作为基础的容器来运行。 需求：在当前的容器中安装了各种组件，期望在其他服务器上也能快速拥有该容器的一切环境。 可以将当前的容器制作为一个镜像，再将该镜像复制到其他服务器，其他服务器再基于镜像运行容器。 镜像制作 将容器保存为一个镜像，通过 commit命令： 1docker commit myredis myredis 第一个mytomcat：容器名称 第二个mytomcat：创建的镜像名称 查看镜像列表是否制作成功： 1docker images 成功制作 备份镜像 通过save命令，在当前目录下保存tar文件： 1docker save -o myredis.tar(生成的文件名) myredis(要备份的镜像名) 通过ll命令查看当前路径下的文件，发现已有myredis.tar文件： 迁移镜像 由于环境限制，只能通过 docker rm命令 把本机的myredis容器删除，从而 使用 docker rmi命令 把上面制作的myredis镜像删除，模拟另一台服务器，实际环境可以把tar文件复制到另一台服务器。 恢复镜像 在当前目录下拿到了tar文件 通过 docker load命令恢复镜像： 1docker load -i myredis.tar(镜像备份的名称) 恢复之后可以查看一下镜像列表： 基于镜像运行容器 创建基于刚才恢复的myredis镜像的容器： 1docker run -di --name&#x3D;myredis -p 6379:6379 myredis 执行之后查看容器列表： 迁移成功。","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker部署Tomcat容器","slug":"Docker4","date":"2020-02-26T11:58:21.000Z","updated":"2020-02-26T12:23:52.774Z","comments":true,"path":"2020/02/26/Docker4/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker4/","excerpt":"","text":"分析 创建容器的时候对容器中的webapps目录（存放web项目的目录）进行目录挂载，发布web项目只需要把项目上传到宿主机的挂载目录即可，tomcat会自动解压包。 拉取Tomcat镜像 拉取镜像的时候不指定版本号，默认下载tomcat最新版的，这里默认就行。 拉取Tomcat镜像： 1docker pull tomcat 等待Pull complete： 查看镜像列表： 1docker images 拉取成功 创建并启动Tomcat容器 执行一下命令进行创建： 1docker run -di --name&#x3D;mytomcat -p 9000:8080 -v &#x2F;usr&#x2F;local&#x2F;mytomcat&#x2F;webapps:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps tomcat 属性解释： -di：创建守护式容器 –name：容器名字 -p：端口映射 -v：目录挂载（映射） 注意 创建容器的时候如出现ipv4的警告信息： 修改配置文件： 1vi &#x2F;etc&#x2F;sysctl.conf 在这文件上添加： 1net.ipv4.ip_forward&#x3D;1 重启网络： 1systemctl restart network 查看一下容器列表： 1docker ps 创建成功","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"},{"name":"Tomcat","slug":"容器引擎/Tomcat","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/Tomcat/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker部署mysql Navicat远程连接","slug":"Docker3","date":"2020-02-26T10:53:17.000Z","updated":"2020-02-26T12:01:13.768Z","comments":true,"path":"2020/02/26/Docker3/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker3/","excerpt":"","text":"拉取Mysql5.7镜像 这里拉取的Mysql版本是5.7版本 这里不再作搜索，直接拉取： 1docker pull centos&#x2F;mysql-57-centos7 查看镜像列表： 1docker images -----------------------------------------拉取成功------------------------------------------- 创建并启动Mysql守护式容器 1docker run -di --name&#x3D;mysql5.7 -p 4100:3306 -e MYSQL_ROOT_PASSWORD&#x3D;root centos&#x2F;mysql-57-centos7 -di：守护式容器 –name：容器名称 -p：端口映射，前面的是宿主机，后面是容器的端口 -e：设置密码 centos/mysql-57-centos7：基于哪个镜像创建 镜像创建成功，进入该容器，输入用户名，密码不用输直接回车（我也不是很清楚为什么）： 1docker exec -it mysql5.7 &#x2F;bin&#x2F;bash 想要让外部工具连接Mysql容器，需要给用户权限： 1grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; ; 等待Query OK后，再刷新权限： 1flush privileges; 使用Navicat12工具测试连接 打开软件，点击左上角的连接，选择Mysql -连接名：随意 -主机：宿主机的IP地址 -密码：你创建容器时设置的密码 输入之后点击测试连接： 提示连接成功","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"},{"name":"MySQL","slug":"容器引擎/MySQL","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/MySQL/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker基础知识之镜像与容器","slug":"Docker2","date":"2020-02-26T02:26:40.000Z","updated":"2020-02-27T04:10:33.214Z","comments":true,"path":"2020/02/26/Docker2/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker2/","excerpt":"","text":"废话不多说，前提条件是你的电脑已安装Docker和完成了基本的配置，还没有的话开车送你去Docker基础知识 Docker镜像 容器的运行是建立在镜像基础之上，当然前提是docker服务已启动。 先用 查看镜像 的命令查看一下本机有什么镜像，不出意外应该啥也没有： 1docker images 镜像没有没关系，从共有仓库 拉取镜像 下来就行了，先来搜索你需要拉取的镜像，比如我们想搜索一个centos7的镜像： 1docker search +你要搜索的镜像名称(如：centos7) 搜索出来的结果： 搜索到之后就拉取我们需要的镜像，比如我们拉取一个centos7镜像： 1docker pull centos:7(镜像的名字:版本号)&#x2F;(若不指定版本号，默认拉取最新版本) 过了一小会之后就会提示 Pull complete，说明拉取成功。 这时候我们再回头使用查看镜像的命令就会看到centos7的镜像了： 镜像可以拉取当然也可以删除： 1docker rmi centos(要删除的镜像名或者镜像id) 或者哪天不开心想把全部镜像删了： 1docker rmi &#96;docker images -q&#96; Docker容器 首先我们要知道docker容器分为两种，一种是 交互式容器，一种是 守护式容器，实际开发中一般采用守护式容器。 两者本质区别 交互式容器随容器的创建、启动而启动，随容器的退出而关闭。 守护式容器随容器的创建、启动而启动，但退出容器后，容器依然在后台运行。 上面我们已经拉取了centos7镜像，下面我们先了解一下创建容器的相关命令属性： 属性 说明 -i 表示运行 -t 表示容器启动后会进入其命令行，加入这两个参数后，容器创建就能登录进去，即分配一个伪终端 –name 为创建容器的名字 -v 表示目录挂载、映射关系 -d 在run后面加上-d参数，则会创建一个守护式容器在后台运行 -p 表示端口映射 -e 表示添加环境变量 查看容器命令（只能查出正在运行的容器）： 1docker ps 查看全部容器命令： 1docker ps -a 查看容器的IP地址： 1docker inspect 容器名字或id 创建一个交互式容器： 1docker run -it --name&#x3D;mycentos7 centos:7 &#x2F;bin&#x2F;bash 执行后会自动进入我们所创建好的容器—mycentos7，使用 ll 命令，然后退出就会回到本机： 创建一个守护式容器： 1docker run -di --name&#x3D;mycentos2 centos:7 创建成功后查看一下容器列表，发现已经在后台运行了： 下面进入该容器看看（exec表示进入的意思）： 1docker exec -it mycentos2 &#x2F;bin&#x2F;bash 可以看出来和交互式容器没什么区别，当我们执行 exit 命令退出该容器后，再查看一下容器列表，发现该容器依旧在后台运行，刚才创建的交互式容器可以通过 docker ps -a命令查看。 停止守护式容器运行： 1docker stop 容器名称或者id 启动容器： 1docker start 容器名称或者id 目录挂载 将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器 创建映射目录 1mkdir &#x2F;usr&#x2F;local&#x2F;test 创建并启动一个守护式容器并挂载test目录： 1docker run -di -v &#x2F;usr&#x2F;local&#x2F;test:&#x2F;usr&#x2F;local&#x2F;test --name&#x3D;mycentos3 centos:7 查看容器列表： 我们在宿主机的test目录下新建一个文件： 1touch test.txt 然后进入 mycentos3容器： 1docker exec -it mycentos3 &#x2F;bin&#x2F;bash 进入test目录下查看文件信息： 1cd &#x2F;usr&#x2F;local&#x2F;test 发现在宿主机创建的test.txt文件也同样被创建在容器中挂载的目录下。 删除容器 1docker rm 容器名称 (注意，正在运行中的容器是无法删除的)","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker基础知识","slug":"Docker1","date":"2020-02-25T07:46:30.000Z","updated":"2020-02-26T09:33:27.998Z","comments":true,"path":"2020/02/25/Docker1/","link":"","permalink":"http://ctrl98.github.io/2020/02/25/Docker1/","excerpt":"","text":"Docker 什么是Docker 百度百科：Docker容器是一个应用容器引擎， 让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 linux 或 Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 说白了就是把应用（项目）部署到Docker容器中运行，就好像放在真实的物理机上运行一样，不用担心开发环境和生产环境的不一致。 为什么要使用Docker Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多 。 性能很高 ， 系统的开销尽量小 。 环境一致，让开发人员专注于开发。 应用迁移更便捷。 应用更好维护。 应用场景 web应用的自动打包和发布 自动化测试 可持续集成 安装各种组件 Docker的组成部分 Docker客户端：个人电脑安装的docker软件、用来连接操作docker。 Docker守护进程：例如有容器A、镜像1 （容器时基于镜像来运行的,镜像相当于类，容器则是类的实例）。 Docker镜像：从docker仓库中拉去过来，而docker仓库又分共有(docker hub)和私有仓库。 以下以 centOS7 系统为基础环境讲述 卸载旧的版本 如果你的系统中已经有旧版本，那么就卸载他吧， 较旧的 Docker 版本称为 docker 或 docker-engine，卸载后记得要删除相关依赖项。 更新 yum 源： 1sudo yum update 查看已安装软件是否有Docker： 1yum list installed 或者直接查看有没有安装Docker： 1yum list installed | grep docker 如果有的话卸载及相关依赖： 1yum -y remove docker.x86_64#软件名看你自己的 安装Docker社区版(个人和中小型企业基本够用) 安装先安装需要的软件包： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源： 1sudo yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo 如果返回结果如下图表明设置成功： 安装docker： 1sudo yum install -y docker-ce 如果返回结果如下图表明安装成功： 查看docker安装版本： 1docker -v 配置Docker镜像源 创建文件夹： 1mkdir &#x2F;etc&#x2F;docker 使用一下命令编辑内容并创建文件—daemon.json 1cd &#x2F;etc&#x2F;docker 1vi daemon.json 文件内容为： 1&#123;&quot;registry-mirrors&quot;:[&quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;]&#125; 镜像也可以用自己的阿里云镜像加速(建议) 编辑完后，按 Esc键，然后按 :，输入 wq，保存文件并退出。 在/etc/docker目录下使用 ll命令查看文件是否创建成功？ Docker基础命令 下面我们来了解一下docker的基础命令 首先是启动docker服务： 1systemctl start docker 停止docker服务： 1systemctl stop docker 查看docker当前状态： 1systemctl status docker 重启docker服务： 1systemctl restart docker 把docker服务设置成开机自动启动： 1systemctl enable docker 到这里说明你已经距离入门还有一大段距离~~~干巴爹斯！！！！","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]}]}