{"meta":{"title":"Lee's Notes","subtitle":"","description":"","author":"unknown","url":"http://ctrl98.github.io","root":"/"},"pages":[{"title":"About","date":"2020-03-09T06:03:39.247Z","updated":"2020-03-09T06:03:39.247Z","comments":true,"path":"about/index.html","permalink":"http://ctrl98.github.io/about/index.html","excerpt":"","text":""},{"title":"All categories","date":"2020-02-25T04:47:45.380Z","updated":"2020-02-25T04:47:45.380Z","comments":true,"path":"categories/index.html","permalink":"http://ctrl98.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-25T04:55:08.804Z","updated":"2020-02-25T04:55:08.804Z","comments":true,"path":"tags/index.html","permalink":"http://ctrl98.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Mysql面试题","slug":"Mysql面试题","date":"2020-05-15T00:31:54.000Z","updated":"2020-05-15T00:32:56.637Z","comments":true,"path":"2020/05/15/Mysql面试题/","link":"","permalink":"http://ctrl98.github.io/2020/05/15/Mysql%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"什么是MySQL? MySQL 是一种关系型数据库，在Java企业级开发中非常常用，因为 MySQL 是开源免费的，并且方便扩展。阿里巴巴数据库系统也大量用到了 MySQL，因此它的稳定性是有保障的。MySQL是开放源代码的，因此任何人都可以在 GPL(General Public License) 的许可下下载并根据个性化的需要对其进行修改。MySQL的默认端口号是3306。 什么是数据库连接池？ 从上一个sql生命周期题目，可以看到其中的连接在里面发挥着重大作用，但频繁的创建和销毁，非常浪费系统资源。由于数据库更适合长连接，也就有个连接池，能对连接复用，维护连接对象、分配、管理、释放，也可以避免创建大量的连接对DB引发的各种问题；另外通过请求排队，也缓解对DB的冲击。 存储引擎 存储引擎负责对表中的数据进行读取和写入，常用的存储引擎有InnoDB、MyISAM、Menory等。 InnoDB和MyISAM的区别 InnoDB MyISAM 事务 支持 不支持 锁 支持MVCC行锁、表锁 表锁 外键 支持 不支持 存储空间 由于需要高速缓存，较大 可压缩 适用场景 有一定量的update和Insert 大量的查询 事务相关 什么是事务? 事务是逻辑上的一组操作，要么都执行，要么都不执行。 事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。 事物的四大特性(ACID) 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 并发事务带来哪些问题? 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对统一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复度和幻读区别： 不可重复读的重点是修改，幻读的重点在于新增或者删除。 例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导致A再读自己的工资时工资变为 2000；这就是不可重复读。 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。 事务隔离级别有哪些? SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻影读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看 123456mysql&gt; SELECT @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+ 这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 **REPEATABLE-READ（可重读）事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 *REPEATABLE-READ（可重读）* 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的SERIALIZABLE(可串行化)**隔离级别。 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。 索引相关 常见的索引种类有：主键索引(primary)、唯一索引(unique)、普通索引(indx)、联合索引。 主键索引又称聚簇索引，其余的都成为非聚簇索引，或者也称为非主键索引，或者二级索引。 聚簇索引和非聚簇索引 聚集索引采用的数据结构是B+树。 聚集索引的叶子节点存储的是整行数据，非聚集索引的叶子节点存储的是索引列和主键。 如果要是通过非聚集索引获取整行数据的某个字段值，那么流程应该是这样的： 首先通过查询条件找到对应的主键id 从id主键的B+树上找到对应id的数据。 从整行数据中获取对应的字段值。 这个流程的过程叫做回表。 回表查询 回表是对Innodb存储引擎而言的，在InnoDB存储引擎中，主键索引的叶子节点存储的记录的数据，而普通索引的叶子节点存储的主键索引的地点。 当我们通过主键查询时，只需要搜索主键索引的搜索树，直接可以得到记录的数据。 当我们通过普通索引进行查询时，通过搜索普通索引的搜索树得到主键的地址之后，还要再使用该主键对主键搜索树进行搜索，这个过程称为回表。 覆盖索引 覆盖索引，即从非聚簇索引中就能查到记录，不需要再次从主键索引中获取记录。 优点：避免回表的产生，减少I/O，提高性能。 可以通过explain命令，查看Extra中是否有Using index。 建立索引的原则 符合最左前缀原则，联合索引要把查询频率最高的列放在最左边。 查询频率比较高的列。 索引列不能参与计算，最好使用简单的数字类型。 主键自增 尽量使用覆盖索引进行查询，避免回表带来的性能损耗。 最左前缀 顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。 还有一个就是生效原则 比如 12345678index(a,b,c)where a&#x3D;3 只使用了awhere a&#x3D;3 and b&#x3D;5 使用了a,bwhere a&#x3D;3 and b&#x3D;5 and c&#x3D;4 使用了a,b,cwhere b&#x3D;3 or where c&#x3D;4 没有使用索引where a&#x3D;3 and c&#x3D;4 仅使用了awhere a&#x3D;3 and b&gt;10 and c&#x3D;7 使用了a,bwhere a&#x3D;3 and b like &#39;xx%&#39; and c&#x3D;7 使用了a,b 做过哪些MySQL索引相关优化 尽量使用主键查询: 聚簇索引上存储了全部数据, 相比普通索引查询, 减少了回表的消耗. MySQL5.6之后引入了索引下推优化, 通过适当的使用联合索引, 减少回表判断的消耗. 若频繁查询某一列数据, 可以考虑利用覆盖索引避免回表. 联合索引将高频字段放在最左边. 简要说一下数据库范式 第一范式: 每个字段都不可再分. 第二范式: 在一范式的基础上, 要求数据库表中的每个实例或行必须可以被惟一地区分. 通常需要为表加上一个列, 以存储各个实例的惟一标识. 这个惟一属性列被称为主关键字或主键. 第三范式: 在二范式的基础上, 要求一个数据库表中不包含已在其它表中已包含的非主关键字信息. 所以第三范式具有如下特征：1). 每一列只有一个值. 2). 每一行都能区分. 3). 每一个表都不包含其他表已经包含的非主关键字信息. Mysql如何为表字段添加索引？ 1.添加PRIMARY KEY（主键索引） 1ALTER TABLE &#96;table_name&#96; ADD PRIMARY KEY ( &#96;column&#96; ) 2.添加UNIQUE(唯一索引) 1ALTER TABLE &#96;table_name&#96; ADD UNIQUE ( &#96;column&#96; ) 3.添加INDEX(普通索引) 1ALTER TABLE &#96;table_name&#96; ADD INDEX index_name ( &#96;column&#96; ) 4.添加FULLTEXT(全文索引) 1ALTER TABLE &#96;table_name&#96; ADD FULLTEXT ( &#96;column&#96;) 5.添加多列索引 1ALTER TABLE &#96;table_name&#96; ADD INDEX index_name ( &#96;column1&#96;, &#96;column2&#96;, &#96;column3&#96; ) 大表优化 当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下： 1. 限定数据的范围 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内； 2. 读/写分离 经典的数据库拆分方案，主库负责写，从库负责读； 3. 垂直分区 根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂； 4. 水平分区 保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 锁 概念 MySQL中的锁，对于MySQL来说，锁是一个很重要的特性，数据库的锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性，这样才能保证在高并发的情况下，访问数据库的时候，数据不会出现问题。 InnoDB存储引擎中的锁 表锁 表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。 当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并大度大打折扣。 使用表级锁定的主要是MyISAM，MEMORY，CSV等一些非事务性存储引擎。 特点： 开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 页锁 页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。在数据库实现资源锁定的过程中，随着锁定资源颗粒度的减小，锁定相同数据量的数据所需要消耗的内存数量是越来越多的，实现算法也会越来越复杂。不过，随着锁定资源 颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。使用页级锁定的主要是BerkeleyDB存储引擎。 特点： 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 行锁 行级锁定最大的特点就是锁定对象的粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。 虽然能够在并发处理能力上面有较大的优势，但是行级锁定也因此带来了不少弊端。由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。 特点： 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 比较表锁我们可以发现，这两种锁的特点基本都是相反的，而从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。 锁的类型 InnoDB存储引擎中存在着不同类型的锁，下面一一介绍一下。 S or X (共享锁、排他锁) 数据的操作其实只有两种，也就是读和写，而数据库在实现锁时，也会对这两种操作使用不同的锁；InnoDB 实现了标准的行级锁，也就是共享锁（Shared Lock）和互斥锁（Exclusive Lock）。 共享锁（读锁）（S Lock），允许事务读一行数据。 排他锁（写锁）（X Lock），允许事务删除或更新一行数据。 IS or IX (共享、排他)意向锁 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB存储引擎支持一种额外的锁方式，就称为意向锁，意向锁在 InnoDB 中是表级锁，意向锁分为： 意向共享锁：表达一个事务想要获取一张表中某几行的共享锁。 意向排他锁：表达一个事务想要获取一张表中某几行的排他锁。 另外，这些锁之间的并不是一定可以共存的，有些锁之间是不兼容的，所谓兼容性就是指事务 A 获得一个某行某种锁之后，事务 B 同样的在这个行上尝试获取某种锁，如果能立即获取，则称锁兼容，反之叫冲突。 乐观锁与悲观锁的区别 悲观锁 总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁 总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 两种锁的使用场景 从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。 乐观锁常见的两种实现方式 乐观锁一般会使用版本号机制或CAS算法实现。 1. 版本号机制 一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1；而当前帐户余额字段（ balance ）为 $100 ； 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。 这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。 2. CAS算法 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 乐观锁的缺点 ABA 问题是乐观锁一个常见的问题 1 ABA 问题 如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 &quot;ABA&quot;问题。 JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 2 循环时间长开销大 自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3 只能保证一个共享变量的原子操作 CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://ctrl98.github.io/tags/MySQL/"},{"name":"面试","slug":"面试","permalink":"http://ctrl98.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"SSM面试题","slug":"SSM面试题","date":"2020-05-15T00:29:04.000Z","updated":"2020-05-15T00:30:27.476Z","comments":true,"path":"2020/05/15/SSM面试题/","link":"","permalink":"http://ctrl98.github.io/2020/05/15/SSM%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"Spring 1、Spring是什么? Spring是一个轻量级的IoC和AOP容器框架，是为Java应用程序提供基础性服务的一套框架，目的是用于简化企业应用程序的开发，它使得开发者只需要关心业务需求。常见的配置方式有三种：基于XML的配置、基于注解的配置、基于Java的配置。 主要由以下几个模块组成： Spring Core：核心类库，提供IOC服务； Spring Context：提供框架式的Bean访问方式，以及企业级功能（JNDI、定时任务等）； Spring AOP：AOP服务； Spring DAO：对JDBC的抽象，简化了数据访问异常的处理； Spring ORM：对现有的ORM框架的支持； Spring Web：提供了基本的面向Web的综合特性，例如多方文件上传； Spring MVC：提供面向Web应用的Model-View-Controller实现； 2、Spring 的优点？ ① 降低耦合度：Spring神奇的 IoC 容器，可以控制对象间的依赖关系，解决了硬编码问题，让你的程序变得 “动态且高效” ② AOP 编程支持：Spring 提供了面向切面编程，可以非常方便的实现一些权限拦截或运行监控等的功能 ③ 方便集成各种优秀框架：Spring 不排斥各种优秀的开源框架，其内部提供了很多优秀框架（Struts、Hibernate、MyBatis、Hessian、Quartz）的直接支持 ④ 方便程序测试：Spring 支持 junit4 ，可以通过注解方便的测试程序 ⑤ 声明式事务的支持：Spring 帮助我们从普通的事物管理代码中解放出来，通过配置就可以完成对事物的管理 ⑥ 降低 JavaEE API 的使用难度：Spring 将 JavaEE 中一些比较难用的 API (JDBC、JavaMail、远程调用等) 进行了封装，使得它们的使用难度大大降低 3、核心组成 BeanDefinition 是Spring内部的一个接口,定义了对Bean的基本规范(beanClassName、scope、lazyInit等),对象在容器中的抽象; BeanDefinition这个东西怎么玩呢,通过getBeanFactory().registerBeanDefinition()方式进行注册(就是put) BeanFactory 位于类结构树的顶端,它最主要的方法就是getBean(String beanName),该方法从容器中返回特定名称的Bean,BeanFactory的功能通过其他的接口得到不断扩展 ApplicationContext ApplicationContext由BeanFactory派生而来,提供了更多面向实际应用的功能.ApplicationContext 继承了HierarchicalBeanFactory和ListableBeanFactory接口,在此基础上,还通过多个其他的接口扩展了BeanFactory的功能 ApplicationContext 与 BeanFactory 的区别 BeanFactory 才是 Spring 管理 Bean 的顶级接口，它提供了实例化对象和取出对象的功能，但是由于BeanFactory的简单与一些局限性，有时候并不是很适合于大型企业级的开发，因此，Spring提供了一个新的内容也就是 ApplicationContext：它是一个更加高级的容器，并且功能更加分丰富 在使用时最明显的一个区别就是：两者创建对象的时间点不一样 ApplicationContext：单例对象适用采用此接口 构建核心容器时，创建对象时采用立即加载的方式。即：只要一读取完配置文件马上就创建配置文件中配置的对象 BeanFactory：适合多例对象 构建核心容器时，创建对象时采用延迟加载的方式。即：什么时候根据id获取对象，什么时候才真正的创建对象 4、Spring IOC 定义 Inversion of Control，控制反转。是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（DependencyInjection，简称 DI），这也是 Spring 的实现方式。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。 原理 IoC 内部核心原理就是反射技术，当然这里面还涉及到 Bean 对象的初始化构建等步骤，这个在后面的生命周期中讲，这里我们需要了解 Java 中反射是如何做的就好。 依赖注入DI (1) 构造函数注入 这一种的前提就是：类中必须提供一个和参数列表相对应的构造函数 看个例子就清楚了 我们就在 service 中创建几个成员，然后给出其对应的带参构造，以及添加一个方法 123456789101112131415161718192021&#x2F;** * 账户业务层实现类 *&#x2F;public class AccountServiceImpl implements AccountService &#123; private String username; private Integer age; private Date birthday; public AccountServiceImpl(String username, Integer phone, Date birthday) &#123; this.username &#x3D; username; this.age &#x3D; phone; this.birthday &#x3D; birthday; &#125; public void addAccount() &#123; System.out.println(&quot;username: &quot; + username + &quot;, phone: &quot; + age + &quot;, birthday: &quot; + birthday); &#125;&#125; 添加配置，这里先运行，再解释 1234567&lt;bean id&#x3D;&quot;accountService&quot; class&#x3D;&quot;cn.ideal.service.impl.AccountServiceImpl&quot;&gt; &lt;constructor-arg name&#x3D;&quot;username&quot; value&#x3D;&quot;汤姆&quot;&gt;&lt;&#x2F;constructor-arg&gt; &lt;constructor-arg name&#x3D;&quot;phone&quot; value&#x3D;&quot;21&quot;&gt;&lt;&#x2F;constructor-arg&gt; &lt;constructor-arg name&#x3D;&quot;birthday&quot; ref&#x3D;&quot;nowdt&quot;&gt;&lt;&#x2F;constructor-arg&gt;&lt;&#x2F;bean&gt;&lt;bean id&#x3D;&quot;nowdt&quot; class&#x3D;&quot;java.util.Date&quot;&gt;&lt;&#x2F;bean&gt; 测试后，成功的获取到了这些值，并且根据方法内的格式，打印到了屏幕上 1username: 汤姆, phone: 21, birthday: Sat Feb 15 16:09:00 CST 2020 看完这个例子，好像有点明白了，上面所做的不就是，使用类的构造函数给成员变量进行赋值，但特别的是，这里是通过配置，使用 Spring 框架进行注入。 来说一下所涉及到的标签： constructor-arg（放在 bean 标签内） 再说一说其中的属性值 给谁赋值： index：指定参数在构造函数参数列表的索引位置 type：指定参数在构造函数中的数据类型 name：指定参数在构造函数中的名称（更常用） 赋什么值： value：这里可以写基本数据类型和 String ref：这里可以引入另一个bean，帮助我们给其他类型赋值（例如文中 birthday ） (2)set 注入（常用） 顾名思义，我们将前面的构造函数先注释掉，然后补充成员变量的 set 方法 在配置的时候，需要修改 1234567&lt;bean id&#x3D;&quot;accountService&quot;class&#x3D;&quot;cn.ideal.service.impl.AccountServiceImpl&quot;&gt; &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;汤姆&quot;&gt;&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;age&quot; value&#x3D;&quot;21&quot;&gt;&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;birthday&quot; ref&#x3D;&quot;nowdt&quot;&gt;&lt;&#x2F;property&gt;&lt;&#x2F;bean&gt;&lt;bean id&#x3D;&quot;nowdt&quot; class&#x3D;&quot;java.util.Date&quot;&gt;&lt;&#x2F;bean&gt; property name：与成员变量名无关，与set方法后的名称有关，例如 setUsername() 获取到的就是username，并且已经小写了开头 value：这里可以写基本数据类型和 String ref：这里可以引入另一个bean，帮助我们给其他类型赋值（例如文中 birthday ） 在这里，还有一种方式就是使用 p名称空间注入数据 (本质还是set) 头部中需要修改引入这一句 123456789101112xmlns:p&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;p&quot;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:p&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;p&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot; http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd&quot;&gt; &lt;bean id&#x3D;&quot;accountService&quot; class&#x3D;&quot;cn.ideal.service.impl.AccountServiceImpl&quot; p:name&#x3D;&quot;汤姆&quot; p:age&#x3D;&quot;21&quot; p:birthday-ref&#x3D;&quot;nowdt&quot;&#x2F;&gt; &lt;bean id&#x3D;&quot;nowdt&quot; class&#x3D;&quot;java.util.Date&quot;&gt;&lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 5、Spring AOP 定义 Aspect Oriented Programming，面向切面编程。通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP 是 OOP 的延续，是软件开发中的一个热点，也是 Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。其中，最常用的使用场景一般有日志模块、权限模块、事物模块。 原理 AOP 的内部原理其实就是动态代理和反射了。 AOP实现的关键在于 代理模式，AOP代理主要分为静态代理和动态代理。静态代理的代表为AspectJ；动态代理则以Spring AOP为代表。 （1）AspectJ是静态代理的增强，所谓静态代理，就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强，他会在编译阶段将AspectJ(切面)织入到Java字节码中，运行的时候就是增强之后的AOP对象。 （2）Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是每次运行时在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 动态代理相关原理的话，你需要了解什么是代理模式、静态代理的不足、动态代理的实现原理。Spring 中实现动态代理有两种方式可选，这两种动态代理的实现方式的一个对比也是面试中常问的。 JDK 动态代理 JDK动态代理只提供接口的代理，不支持类的代理。 必须实现 InvocationHandler 接口，然后通过 Proxy.newProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h) 获得动态代理对象。 CGLIB 动态代理 如果代理类没有实现 InvocationHandler 接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。 使用 CGLIB 动态代理，被代理类**不需要强制实现接口。**CGLIB 不能对声明为 final的方法进行代理，因为 CGLIB 原理是动态生成被代理类的子类。 5、Spring Bean 生命周期 首先容器启动后，对bean进行初始化 按照bean的定义，注入属性 检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给bean，如BeanNameAware等 以上步骤，bean对象已正确构造，通过实现BeanPostProcessor接口，可以再进行一些自定义方法处理如:postProcessBeforeInitialzation BeanPostProcessor的前置处理完成后，可以实现postConstruct，afterPropertiesSet,init-method等方法， 增加我们自定义的逻辑， 通过实现BeanPostProcessor接口，进行postProcessAfterInitialzation后置处理 接着Bean准备好被使用啦 容器关闭后，如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法 通过给destroy-method指定函数，就可以在bean销毁前执行指定的逻辑 Spring MVC 1、什么是Spring MVC ？ SpringMVC是一个基于Java的实现了MVC设计模式的请求驱动类型的轻量级Web框架，通过把Model，View，Controller分离，将web层进行职责解耦，把复杂的web应用分成逻辑清晰的几部分，简化开发，减少出错，方便组内开发人员之间的配合。 2、Springmvc的优点 （1）可以支持各种视图技术,而不仅仅局限于JSP； （2）与Spring框架集成（如IoC容器、AOP等）； （3）清晰的角色分配：前端控制器(dispatcherServlet) , 请求到处理器映射（handlerMapping), 处理器适配器（HandlerAdapter), 视图解析器（ViewResolver）。 （4）支持各种请求资源的映射策略。 3、SpringMVC的工作流程/原理 4、springMVC和struts2的区别 （1）springmvc的入口是一个servlet即前端控制器（DispatchServlet），而struts2入口是一个filter过虑器（StrutsPrepareAndExecuteFilter）。 （2）springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，可以设计为单例或多例(建议单例)，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。 （3）Struts采用值栈存储请求和响应的数据，通过OGNL存取数据，springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过reques域传输到页面。Jsp视图解析器默认使用jstl。 5、SpringMVC怎么样设定重定向和转发 （1）转发：在返回值前面加&quot;forward:&quot;，譬如&quot;forward:user.do?name=method4&quot; （2）重定向：在返回值前面加&quot;redirect:&quot;，譬如&quot;redirect:www.baidu.com&quot; 6、SpringMvc怎么和AJAX相互调用 通过Jackson框架就可以把Java里面的对象直接转化成Js可以识别的Json对象。具体步骤如下 ： （1）加入Jackson.jar （2）在配置文件中配置json的映射 （3）在接受Ajax方法里面可以直接返回Object,List等,但方法前面要加上@ResponseBody注解。 7、 SpringMVC常用的注解 @RequestMapping：用于处理请求 url 映射的注解，可用于类或方法上。用于类上，则表示类中的所有响应请求的方法都是以该地址作为父路径。 @RequestBody：注解实现接收http请求的json数据，将json转换为java对象。 @ResponseBody：注解实现将conreoller方法返回对象转化为json对象响应给客户。 Mybatis 1、什么是Mybatis? （1）Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，开发时只需要关注SQL语句本身，不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。程序员直接编写原生态sql，可以严格控制sql执行性能，灵活度高。 （2）MyBatis 可以使用XML 或注解来配置和映射原生信息，将POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。 （3）通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。 2、Mybaits的优点 （1）基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态SQL语句，并可重用； （2）与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接； （3）很好的与各种数据库兼容（因为MyBatis使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持）； （4）能够与Spring很好的集成； （5）提供映射标签，支持对象与数据库的ORM字段关系映射；提供对象关系映射标签，支持对象关系组件维护； 3、MyBatis框架适用场合 （1）MyBatis专注于SQL本身，是一个足够灵活的DAO层解决方案。 （2）对性能的要求很高，或者需求变化较多的项目，如互联网项目，MyBatis将是不错的选择。 4、MyBatis与Hibernate的区别 （1）Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句。 （2）Mybatis直接编写原生态sql，可以严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套sql映射文件，工作量大。 （3）Hibernate对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用hibernate开发可以节省很多代码，提高效率。 5、#{}和${}的区别是什么？ #{}：是占位符，预编译处理； ${}：是拼接符，字符串替换，没有预编译处理。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； Mybatis在处理${}时， 原值传入，替换成变量的值。 使用#{}可以有效的防止SQL注入，提高系统安全性。 6、如何处理实体类中的属性名和表中的字段名不一样 第1种： 通过在查询的sql语句中定义字段名的别名，让字段名的别名和实体类的属性名一致。 123&lt;select id=”selectorder” parametertype=”int” resultetype=”me.gacl.domain.order”&gt; select order_id id, order_no orderno ,order_price price form orders where order_id=#&#123;id&#125;;&lt;/select&gt; 第2种： 通过来映射字段名和实体类属性名的一一对应的关系。 1234567891011&lt;select id=\"getOrder\" parameterType=\"int\" resultMap=\"orderresultmap\"&gt; select * from orders where order_id=#&#123;id&#125;&lt;/select&gt;&lt;resultMap type=”me.gacl.domain.order” id=”orderresultmap”&gt; &lt;!–用id属性来映射主键字段–&gt; &lt;id property=”id” column=”order_id”&gt; &lt;!–用result属性来映射非主键字段，property为实体类属性名，column为数据表中的属性–&gt; &lt;result property = “orderno” column =”order_no”/&gt; &lt;result property=”price” column=”order_price” /&gt;&lt;/reslutMap&gt; 7、 模糊查询like语句该怎么写 第1种：在Java代码中添加sql通配符。 123456string wildcardname = “%smi%”;list&lt;name&gt; names = mapper.selectlike(wildcardname);&lt;select id=”selectlike”&gt; select * from foo where bar like #&#123;value&#125;&lt;/select&gt; 第2种：在sql语句中拼接通配符，会引起sql注入 123456string wildcardname = “smi”;list&lt;name&gt; names = mapper.selectlike(wildcardname);&lt;select id=”selectlike”&gt; select * from foo where bar like \"%\"#&#123;value&#125;\"%\"&lt;/select&gt; 第3种：在sql语句中拼接通配符，不会引起sql注入,一般会采用这种 123456string wildcardname &#x3D; “smi”;list&lt;name&gt; names &#x3D; mapper.selectlike(wildcardname);&lt;select id&#x3D;”selectlike”&gt; select * from foo where bar like concat(&#39;%&#39;,#&#123;value&#125;,&#39;%&#39;) &lt;&#x2F;select&gt; 8、通常一个Xml映射文件，都会写一个Dao接口与之对应，Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？ Dao接口即Mapper接口。接口的全限名，就是映射文件中的namespace的值；接口的方法名，就是映射文件中Mapper的Statement的id值；接口方法内的参数，就是传递给sql的参数。 Mapper接口里的方法，是不能重载的，因为是使用 全限名+方法名 的保存和寻找策略。Mapper接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回。 9、Mybatis是如何进行分页的？分页插件的原理是什么？ Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页。可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。 分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。 10、Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？ 第一种是使用resultMap标签，逐一定义数据库列名和对象属性名之间的映射关系。 第二种是使用sql列的别名功能，将列的别名书写为对象属性名。 有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。 11、如何获取自动生成的(主)键值? insert 方法总是返回一个int值 ，这个值代表的是插入的行数。 如果采用自增长策略，自动生成的键值在 insert 方法执行完后可以被设置到传入的参数对象中。 示例： 1234567891011&lt;insert id=”insertname” usegeneratedkeys=”true” keyproperty=”id”&gt; insert into names (name) values (#&#123;name&#125;)&lt;/insert&gt; Name name = new Name(); name.setname(“fred”); int rows = mapper.insertname(name); // 完成后,id已经被设置到对象中 system.out.println(“rows inserted = ” + rows); system.out.println(“generated key value = ” + name.getid()); 14、在mapper中如何传递多个参数? 12345678910111213141516171819202122232425262728293031323334353637383940414243441）第一种：//DAO层的函数Public UserselectUser(String name,String area);//对应的xml,#&#123;0&#125;代表接收的是dao层中的第一个参数，#&#123;1&#125;代表dao层中第二参数，更多参数一致往后加即可。&lt;select id=\"selectUser\"resultMap=\"BaseResultMap\"&gt; select * fromuser_user_t whereuser_name = #&#123;0&#125; anduser_area=#&#123;1&#125; &lt;/select&gt;（2）第二种： 使用 @param 注解:public interface usermapper &#123; user selectuser(@param(“username”) string username,@param(“hashedpassword”) string hashedpassword);&#125;//然后,就可以在xml像下面这样使用(推荐封装为一个map,作为单个参数传递给mapper):&lt;select id=”selectuser” resulttype=”user”&gt; select id, username, hashedpassword from some_table where username = #&#123;username&#125; and hashedpassword = #&#123;hashedpassword&#125;&lt;/select&gt;（3）第三种：多个参数封装成maptry&#123;//映射文件的命名空间.SQL片段的ID，就可以调用对应的映射文件中的SQL//由于我们的参数超过了两个，而方法中只有一个Object参数收集，因此我们使用Map集合来装载我们的参数 Map&lt;String, Object&gt; map = new HashMap(); map.put(\"start\", start); map.put(\"end\", end); return sqlSession.selectList(\"StudentID.pagination\", map);&#125;catch(Exception e)&#123; e.printStackTrace(); sqlSession.rollback(); throw e; &#125;finally&#123; MybatisUtil.closeSqlSession();&#125; 12、Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？ 不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复； 原因就是namespace+id是作为Map&lt;String, MapperStatement&gt;的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。 但是，在以前的Mybatis版本的namespace是可选的，不过新版本的namespace已经是必须的了。 13、为什么说Mybatis是半自动ORM映射工具？它与全自动的区别在哪里？ Hibernate属于全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而Mybatis在查询关联对象或关联集合对象时，需要手动编写sql来完成，所以，称之为半自动ORM映射工具。 14、 一对一、一对多的关联查询 12345678910111213141516171819202122232425262728293031323334353637&lt;mapper namespace=\"com.lcb.mapping.userMapper\"&gt; &lt;!--association 一对一关联查询 --&gt; &lt;select id=\"getClass\" parameterType=\"int\" resultMap=\"ClassesResultMap\"&gt; select * from class c,teacher t where c.teacher_id=t.t_id and c.c_id=#&#123;id&#125; &lt;/select&gt; &lt;resultMap type=\"com.lcb.user.Classes\" id=\"ClassesResultMap\"&gt; &lt;!-- 实体类的字段名和数据表的字段名映射 --&gt; &lt;id property=\"id\" column=\"c_id\"/&gt; &lt;result property=\"name\" column=\"c_name\"/&gt; &lt;association property=\"teacher\" javaType=\"com.lcb.user.Teacher\"&gt; &lt;id property=\"id\" column=\"t_id\"/&gt; &lt;result property=\"name\" column=\"t_name\"/&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;!--collection 一对多关联查询 --&gt; &lt;select id=\"getClass2\" parameterType=\"int\" resultMap=\"ClassesResultMap2\"&gt; select * from class c,teacher t,student s where c.teacher_id=t.t_id and c.c_id=s.class_id and c.c_id=#&#123;id&#125; &lt;/select&gt; &lt;resultMap type=\"com.lcb.user.Classes\" id=\"ClassesResultMap2\"&gt; &lt;id property=\"id\" column=\"c_id\"/&gt; &lt;result property=\"name\" column=\"c_name\"/&gt; &lt;association property=\"teacher\" javaType=\"com.lcb.user.Teacher\"&gt; &lt;id property=\"id\" column=\"t_id\"/&gt; &lt;result property=\"name\" column=\"t_name\"/&gt; &lt;/association&gt; &lt;collection property=\"student\" ofType=\"com.lcb.user.Student\"&gt; &lt;id property=\"id\" column=\"s_id\"/&gt; &lt;result property=\"name\" column=\"s_name\"/&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;/mapper&gt; 15、MyBatis实现一对多有几种方式,怎么操作的 联合查询和嵌套查询。 联合查询是几个表联合查询,只查询一次,通过在resultMap里面的collection节点配置一对多的类就可以完成； 嵌套查询是先查一个表,根据这个表里面的 结果的外键id,去再另外一个表里面查询数据,也是通过配置collection,但另外一个表的查询通过select节点配置。 16、什么是MyBatis的接口绑定？有哪些实现方式？ 接口绑定，就是在MyBatis中任意定义接口,然后把接口里面的方法和SQL语句绑定,我们直接调用接口方法就可以,这样比起原来了SqlSession提供的方法我们可以有更加灵活的选择和设置。 接口绑定有两种实现方式： 一种是通过注解绑定，就是在接口的方法上面加上@Select、@Update等注解，里面包含Sql语句来绑定； 另外一种就是通过xml里面写SQL来绑定,在这种情况下,要指定xml映射文件里面的namespace必须为接口的全路径名。当Sql语句比较简单时候,用注解绑定,当SQL语句比较复杂时候,用xml绑定,一般用xml绑定的比较多。 17、使用MyBatis的mapper接口调用时有哪些要求？ ①Mapper接口方法名和mapper.xml中定义的每个sql的id相同； ②Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同； ③Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同； ④Mapper.xml文件中的namespace即是mapper接口的类路径。 18、Mapper编写有哪几种方式？ 第一种：接口实现类继承SqlSessionDaoSupport：使用此种方法需要编写mapper接口，mapper接口实现类、mapper.xml文件。 （1）在sqlMapConfig.xml中配置mapper.xml的位置 1234&lt;mappers&gt; &lt;mapper resource=\"mapper.xml文件的地址\" /&gt; &lt;mapper resource=\"mapper.xml文件的地址\" /&gt;&lt;/mappers&gt; （2）定义mapper接口 （3）实现类集成SqlSessionDaoSupport，mapper方法中可以this.getSqlSession()进行数据增删改查。 （4）spring 配置 123&lt;bean id=\" \" class=\"mapper接口的实现\"&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"&gt;&lt;/property&gt;&lt;/bean&gt; 第二种：使用org.mybatis.spring.mapper.MapperFactoryBean： （1）在sqlMapConfig.xml中配置mapper.xml的位置，如果mapper.xml和mappre接口的名称相同且在同一个目录，这里可以不用配置 1234&lt;mappers&gt; &lt;mapper resource&#x3D;&quot;mapper.xml文件的地址&quot; &#x2F;&gt; &lt;mapper resource&#x3D;&quot;mapper.xml文件的地址&quot; &#x2F;&gt;&lt;&#x2F;mappers&gt; （2）定义mapper接口： ①mapper.xml中的namespace为mapper接口的地址 ②mapper接口中的方法名和mapper.xml中的定义的statement的id保持一致 ③Spring中定义 1234&lt;bean id&#x3D;&quot;&quot; class&#x3D;&quot;org.mybatis.spring.mapper.MapperFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;mapperInterface&quot; value&#x3D;&quot;mapper接口地址&quot; &#x2F;&gt; &lt;property name&#x3D;&quot;sqlSessionFactory&quot; ref&#x3D;&quot;sqlSessionFactory&quot; &#x2F;&gt;&lt;&#x2F;bean&gt; 第三种：使用mapper扫描器： （1）mapper.xml文件编写： mapper.xml中的namespace为mapper接口的地址； mapper接口中的方法名和mapper.xml中的定义的statement的id保持一致； 如果将mapper.xml和mapper接口的名称保持一致则不用在sqlMapConfig.xml中进行配置。 （2）定义mapper接口：注意mapper.xml的文件名和mapper的接口名称保持一致，且放在同一个目录 （3）配置mapper扫描器： 1234&lt;bean class&#x3D;&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name&#x3D;&quot;basePackage&quot; value&#x3D;&quot;mapper接口包地址&quot;&gt;&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;sqlSessionFactoryBeanName&quot; value&#x3D;&quot;sqlSessionFactory&quot;&#x2F;&gt;&lt;&#x2F;bean&gt; （4）使用扫描器后从spring容器中获取mapper的实现对象。","categories":[{"name":"SSM框架","slug":"SSM框架","permalink":"http://ctrl98.github.io/categories/SSM%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://ctrl98.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"SSM框架","slug":"SSM框架","permalink":"http://ctrl98.github.io/tags/SSM%E6%A1%86%E6%9E%B6/"}]},{"title":"Java基础面试题","slug":"Java基础面试题","date":"2020-05-15T00:25:50.000Z","updated":"2020-05-15T00:28:02.402Z","comments":true,"path":"2020/05/15/Java基础面试题/","link":"","permalink":"http://ctrl98.github.io/2020/05/15/Java%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"Java基础知识 1、 为什么 Java 中只有值传递？ 参数传递给方法（或函数）的一些专业术语 按值调用(call by value)表示方法接收的是调用者提供的值 按引用调用（call by reference)表示方法接收的是调用者提供的变量地址 一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值。 Java 程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。 example 1 123456789101112131415161718public static void main(String[] args) &#123; int num1 &#x3D; 10; int num2 &#x3D; 20; swap(num1, num2); System.out.println(&quot;num1 &#x3D; &quot; + num1); System.out.println(&quot;num2 &#x3D; &quot; + num2);&#125;public static void swap(int a, int b) &#123; int temp &#x3D; a; a &#x3D; b; b &#x3D; temp; System.out.println(&quot;a &#x3D; &quot; + a); System.out.println(&quot;b &#x3D; &quot; + b);&#125; 结果： 1234a &#x3D; 20b &#x3D; 10num1 &#x3D; 10num2 &#x3D; 20 我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看 example2. example 2 1234567891011public static void main(String[] args) &#123; int[] arr &#x3D; &#123; 1, 2, 3, 4, 5 &#125;; System.out.println(arr[0]); change(arr); System.out.println(arr[0]);&#125;public static void change(int[] array) &#123; &#x2F;&#x2F; 将数组的第一个元素变为0 array[0] &#x3D; 0;&#125; 结果： 1210 实现一个改变对象参数状态的方法并不是一件难事。理由很简单，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。 有些程序员（甚至本书的作者）认为 Java 程序设计语言对对象采用的是引用调用，实际上，这种理解是不对的。由于这种误解具有一定的普遍性，所以下面给出一个反例来详细地阐述一下这个问题。 example 3 12345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; &#x2F;&#x2F; TODO Auto-generated method stub Student s1 &#x3D; new Student(&quot;小张&quot;); Student s2 &#x3D; new Student(&quot;小李&quot;); Test.swap(s1, s2); System.out.println(&quot;s1:&quot; + s1.getName()); System.out.println(&quot;s2:&quot; + s2.getName()); &#125; public static void swap(Student x, Student y) &#123; Student temp &#x3D; x; x &#x3D; y; y &#x3D; temp; System.out.println(&quot;x:&quot; + x.getName()); System.out.println(&quot;y:&quot; + y.getName()); &#125;&#125; 结果： 1234x:小李y:小张s1:小张s2:小李 通过上面两张图可以很清晰的看出： 方法并没有改变存储在变量 s1 和 s2 中的对象引用。swap 方法的参数 x 和 y 被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝 2、 ==与 equals(重要) == : 基本数据类型比较的是值，引用数据类型比较的是内存地址 equals() : 情况 1：类没有覆盖 equals()方法。则通过 equals()比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况 2：类覆盖了 equals()方法。一般，我们都覆盖 equals()方法来两个对象的内容相等；若它们的内容相等，则返回 true(即，认为这两个对象相等)。 1234567891011121314151617int i &#x3D; 1;int x &#x3D; 1;String a &#x3D; &quot;123&quot;;String aa &#x3D; &quot;123&quot;;String b &#x3D; a;String c &#x3D; new String(&quot;123&quot;);String d &#x3D; c;System.out.println(a &#x3D;&#x3D; aa); trueSystem.out.println(i &#x3D;&#x3D; x); trueSystem.out.println(a &#x3D;&#x3D; b); trueSystem.out.println(a.equals(b)); trueSystem.out.println(a &#x3D;&#x3D; c); falseSystem.out.println(a.equals(c)); trueSystem.out.println(a &#x3D;&#x3D; d); falseSystem.out.println(a.equals(d)); true 说明： String 中的 equals 方法是被重写过的，因为 object 的 equals 方法是比较的对象的内存地址，而 String 的 equals 方法比较的是对象的值。 当创建 String 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 String 对象。 3、hashCode 与 equals（重要） 3.1、hashCode（）介绍 hashCode() 的作用是获取哈希码，也称为散列码； 它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置； hashCode() 定义在 JDK 的 Object.java 中，这就意味着 Java 中的任何类都包含有 hashCode() 函数； 另外需要注意的是： Object 的 hashcode 方法是本地方法，也就是用 c 语言或 c++ 实现的，该方法通常用来将对象的 内存地址 转换为整数之后返回； 3.2、为什么要有 hashCode 以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的 Java 启蒙书《Head fist java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 3.3、hashCode（）与 equals（）的相关规定 如果两个对象相等，则 hashcode 一定也是相同的 两个对象相等,对两个对象分别调用 equals 方法都返回 true 两个对象有相同的 hashcode 值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 3.4、为什么两个对象有相同的 hashcode 值，它们也不一定是相等的？ 因为 hashCode() 所使用的杂凑算法也许刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode）。 我们刚刚也提到了 HashSet,如果 HashSet 在对比的时候，同样的 hashcode 有多个对象，它会使用 equals() 来判断是否真的相同。也就是说 hashcode 只是用来缩小查找成本。 3.5、有没有可能两个不相等的对象有相同的hashcode 有可能.在产生hash冲突时,两个不相等的对象就会有相同的 hashcode 值.当hash冲突产生时,一般有以下几种方式来处理: （1）拉链法:每个哈希表节点都有一个next指针,多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表进行存储； （2）开放定址法:一旦发生了冲突,就去寻找下一个空的散列地址,只要散列表足够大,空的散列地址总能找到,并将记录存入； （3）再哈希:又叫双哈希法,有多个不同的Hash函数.当发生冲突时,使用第二个,第三个….等哈希函数计算地址,直到无冲突； 4、 String 和 StringBuffer、StringBuilder 的区别是什么？String 为什么是不可变的？ 可变性 String 类中使用 final 关键字修饰字符数组来保存字符串，private final char value[]，所以 String 对象是不可变的。 而 StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。 线程安全性 String 中的对象是不可变的，也就可以理解为常量，线程安全。 StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。 StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 操作少量的数据: 适用 String 单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer String 真的是不可变的吗？ 我觉得如果别人问这个问题的话，回答不可变就可以了。下面只是给大家看两个有代表性的例子： 1) String 不可变但不代表引用不可以变 123String str &#x3D; &quot;Hello&quot;;str &#x3D; str + &quot; World&quot;;System.out.println(&quot;str&#x3D;&quot; + str); 结果： 1str&#x3D;Hello World 解析： 实际上，原来 String 的内容是不变的，只是 str 由原来指向&quot;Hello&quot;的内存地址转为指向&quot;Hello World&quot;的内存地址而已，也就是说多开辟了一块内存区域给&quot;Hello World&quot;字符串。 5、什么是反射机制？反射机制的应用场景有哪些？ 5.1 反射机制介绍 JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。 5.2 静态编译和动态编译 **静态编译：**在编译时确定类型，绑定对象 **动态编译：**运行时确定类型，绑定对象 5.3 获取一个对象对应的反射类，在 Java 中有下列方法可以获取一个对象的反射类 通过 getClass() 方法 通过 Class.forName() 方法 使用 类.class 通过类加载器实现，getClassLoader() Java获取反射的三种方法 1.通过new对象 2.通过路径 3.通过类名 1234567891011121314151617181920212223public class Student &#123; private int id; String name; protected boolean sex; public float score; &#125;复制代码public class Get &#123; //获取反射机制三种方式 public static void main(String[] args) throws ClassNotFoundException &#123; //方式一(通过建立对象) Student stu = new Student(); Class classobj1 = stu.getClass(); System.out.println(classobj1.getName()); //方式二（所在通过路径-相对路径） Class classobj2 = Class.forName(\"fanshe.Student\"); System.out.println(classobj2.getName()); //方式三（通过类名） Class classobj3 = Student.class; System.out.println(classobj3.getName()); &#125; 5.4 反射的应用场景 反射是框架设计的灵魂。 5.5反射中，Class.forName和ClassLoader区别 Class.forName和ClassLoader都可以对类进行加载 ClassLoader：负责加载 Java 类的字节代码到 Java 虚拟机中。 Class.forName：其实是调用了ClassLoader。 所以区别就是在类加载的时候，class.forName有参数控制是否对类进行初始化。 6、 什么是 JDK?什么是 JRE？什么是 JVM？三者之间的联系与区别 6.1 JVM Java 虚拟机（JVM）是运行 Java 字节码的虚拟机。 在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。 6.2 JDK 和 JRE JDK 是 Java Development Kit，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。 JRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。 6.3 总结 Jdk包含Jre包含JVM 7、接口和抽象类的区别是什么? 接口的方法默认是 public，所有方法在接口中不能有实现，抽象类可以有非抽象的方法 接口中的实例变量默认是 final 类型的，而抽象类中则不一定 一个类可以实现多个接口，但最多只能实现一个抽象类 一个类实现接口的话要实现接口的所有方法，而抽象类不一定 接口不能用 new 实例化，但可以声明，但是必须引用一个实现该接口的对象 从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。 注意：Java8 后接口可以有默认实现( default )。 8、重载和重写的区别 重载 发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同。 重写 **重写是子类对父类的允许访问的方法的实现过程进行重新编写,发生在子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。**另外，如果父类方法访问修饰符为 private 则子类就不能重写该方法。也就是说方法提供的行为改变，而方法的外貌并没有改变。 9、 Java 面向对象编程三大特性: 封装 继承 多态 封装 封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。 继承 继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。 关于继承如下 3 点请记住： 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。（以后介绍）。 多态 所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 在 Java 中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 10、Java 支持的数据类型有哪些？ 整数值型：byte(1个字节)，short(2个字节)，int(4个字节)，long(8个字节) 字符型：char(2个字节) 浮点类型：float(4个字节)，double (8个字节) 布尔型：boolean(没有明确说明) 整数默认 int 型，小数默认是 double 型。Float 和 long 类型的必须加后缀。比如 float f = 100f。 首先知道 String 是引用类型不是基本类型，引用类型声明的变量是指该变量在内存中实际存储的是一个引用地址，实体在堆中。引用类型包括类、接口、数组等。String 类还是 final 修饰的。 11、什么是自动拆装箱？ 11.1、 自动装箱和拆箱就是基本类型和引用类型之间的转换，至于为什么要转换，因为基本类型转换为引用类型后，就可以 new 对象，从而调用包装类中封装好的方法进行基本类型之间的转换 11.2、 装箱就是自动将基本数据类型转换为包装器类型（int–&gt;Integer）；调用方法：Integer的valueOf(int) 方法 拆箱就是自动将包装器类型转换为基本数据类型（Integer–&gt;int）。调用方法：Integer的intValue方法 在Java SE5之前，如果要生成一个数值为10的Integer对象，必须这样进行： 1Integer i &#x3D; new Integer(10); 而在从Java SE5开始就提供了自动装箱的特性，如果要生成一个数值为10的Integer对象，只需要这 样就可以了： 1Integer i &#x3D; 10; 12、 &amp; 与 &amp;&amp; 的区别？ 如果 &amp;&amp; 左边的表达式的值是 false，右边的表达式会被直接短路掉，不会进行运算。 13、是否可以在 static 环境中访问非 static 变量？ 不可以、因为非static变量是属于类的、类没有创建出来就不可以访问。 14、final, finally, finalize 的区别 final: 用于声明属性,方法和类, 分别表示属性不可变, 方法不可覆盖, 类不可继承. finally:是异常处理语句结构的一部分，表示总是执行. finalize: 是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等. JVM不保证此方法总被调用. 15、Bio、Nio、Aio区别 BIO 就是传统的 java.io 包，它是基于流模型实现的，交互的方式是同步、阻塞方式，也就是说在读入输入流或者输出流时，在读写动作完成之前，线程会一直阻塞在那里，它们之间的调用时可靠的线性顺序。它的有点就是代码比较简单、直观；缺点就是 IO 的效率和扩展性很低，容易成为应用性能瓶颈。 NIO 是 Java 1.4 引入的 java.nio 包，提供了 Channel、Selector、Buffer 等新的抽象，可以构建多路复用的、同步非阻塞 IO 程序，同时提供了更接近操作系统底层高性能的数据操作方式。 AIO 是 Java 1.7 之后引入的包，是 NIO 的升级版本，提供了异步非堵塞的 IO 操作方式，所以人们叫它 AIO（Asynchronous IO），异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。 16、error和exception的区别，CheckedException，RuntimeException的区别。 Error: 表示编译时或者系统错误，如虚拟机相关的错误，OutOfMemoryError等，error是无法处理的。 Exception: 代码异常，Java程序员关心的基类型通常是Exception。它能被程序本身可以处理，这也是它跟Error的区别。 它可以分为RuntimeException（运行时异常）和CheckedException（可检查的异常）。 常见的RuntimeException异常： 12345- NullPointerException 空指针异常- ArithmeticException 出现异常的运算条件时，抛出此异常- IndexOutOfBoundsException 数组索引越界异常- ClassNotFoundException 找不到类异常- IllegalArgumentException 非法参数异常 常见的 Checked Exception 异常： 12- IOException 操作输入流和输出流时可能出现的异常- ClassCastException 类型转换异常类 17、序列化与反序列化 序列化是指将对象转换为字节序列的过程，而反序列化则是将字节序列转换为对象的过程。 Java对象序列化是将实现了Serializable接口的对象转换成一个字节序列，能够通过网络传输、文件存储等方式传输 ，传输过程中却不必担心数据在不同机器、不同环境下发生改变，也不必关心字节的顺序或其他任何细节，并能够在以后将这个字节序列完全恢复为原来的对象。 18、JDK动态代理与cglib实现的区别 java动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。 cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。 JDK动态代理只能对实现了接口的类生成代理，而不能针对类 cglib是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法。因为是继承，所以该类或方法最好不要声明成final Java多线程 1、Java中实现多线程有几种方法 （1）继承Thread类； （2）实现Runnable接口； （3）实现Callable接口通过FutureTask包装器来创建Thread线程； （4）使用ExecutorService、Callable、Future实现有返回结果的多线程（也就是使用了ExecutorService来管理前面的三种方式）。 2、什么是线程和进程? 2.1 何为进程? 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 2.2 何为线程? 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 2、说说并发与并行的区别? 并发： 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； 并行： 单位时间内，多个任务同时执行。 4、什么是线程死锁?如何避免死锁? 15.1. 认识线程死锁 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 比如线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo &#123; private static Object resource1 = new Object();//资源 1 private static Object resource2 = new Object();//资源 2 public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + \"get resource1\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + \"waiting get resource2\"); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + \"get resource2\"); &#125; &#125; &#125;, \"线程 1\").start(); new Thread(() -&gt; &#123; synchronized (resource2) &#123; System.out.println(Thread.currentThread() + \"get resource2\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + \"waiting get resource1\"); synchronized (resource1) &#123; System.out.println(Thread.currentThread() + \"get resource1\"); &#125; &#125; &#125;, \"线程 2\").start(); &#125;&#125; 1234Thread[线程 1,5,main]get resource1Thread[线程 2,5,main]get resource2Thread[线程 1,5,main]waiting get resource2Thread[线程 2,5,main]waiting get resource1 产生死锁必须具备以下四个条件： 互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 3、notify()和notifyAll()有什么区别？ notify可能会导致死锁，而notifyAll则不会 任何时候只有一个线程可以获得锁，也就是说只有一个线程可以运行synchronized 中的代码使用notifyAll,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。 wait() 应配合while循环使用，不应使用if，务必在wait()调用前后都检查条件，如果不满足，必须调用notify()唤醒另外的线程来处理，自己继续wait()直至条件满足再往下执行。 notify() 是对notifyAll()的一个优化，但它有很精确的应用场景，并且要求正确使用。不然可能导致死锁。正确的场景应该是 WaitSet中等待的是相同的条件，唤醒任一个都能正确处理接下来的事项，如果唤醒的线程无法正确处理，务必确保继续notify()下一个线程，并且自身需要重新回到WaitSet中。 6、说说 sleep() 方法和 wait() 方法区别和共同点? 两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。 两者都可以暂停线程的执行。 Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。 7、为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？ new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。 6、Java线程池的原理？线程池有哪些？线程池工厂有哪些线程池类型，及其线程池参数是什么？ 对于Java线程池，这个流程图比较重要： 9、CAS机制是什么，如何解决ABA问题？ CAS涉及三个操作数 1.需要读写的内存地址V 2.进行比较的预期原值A 3.拟写入的新值B 如果内存位置的值V与预期原A值相匹配，那么处理器会自动将该位置值更新为新值B。 CAS思想：要进行更新时，认为位置V上的值还是跟A值相等，如果是是相等，就认为它没有被别的线程更改过，即可更新为B值。否则，认为它已经被别的线程修改过，不更新为B的值，返回当前位置V最新的值。 10、说几种实现幂等的方式 什么是幂等性？一次和多次请求某一个资源对于资源本身应该具有同样的结果。就是说，其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。 实现幂等一般有以下几种方式： 悲观锁方式（如数据库的悲观锁，select…for update） 乐观锁方式 (如CAS算法) 唯一性约束（如唯一索引） 分布式锁 （redis分布式锁等） Java集合 结构图 1、ArrayList和LinkedList有什么区别。 思路：从它们的底层数据结构、效率、开销进行阐述 ArrayList是数组的数据结构，LinkedList是链表的数据结构。 随机访问的时候，ArrayList的效率比较高，因为LinkedList要移动指针，而ArrayList是基于索引(index)的数据结构，可以直接映射到。 插入、删除数据时，LinkedList的效率比较高，因为ArrayList要移动数据。 LinkedList比ArrayList开销更大，因为LinkedList的节点除了存储数据，还需要存储引用。 2、HashSet、TreeSet HashSet底层是HashMap，排列无序，不可以重复，因为底层的HashMap的键不允许重复； TreeSet底层是TreeMap，排列无序，不可以重复； 3、HashSet 是如何保证不重复的？ 向 HashSet 中 add ()元素时，判断元素是否存在的依据，不仅要比较hash值，同时还要结合 equles 方法比较。HashSet 中的 add ()方法会使用 HashMap 的 add ()方法。 以下是 HashSet 部分源码： 12345678private static final Object PRESENT &#x3D; new Object(); private transient HashMap&lt;E,Object&gt; map; public HashSet()&#123; map &#x3D; new HashMap&lt;&gt;(); &#125;public boolean add(E e)&#123; return map.put(e, PRESENT)&#x3D;&#x3D;null; &#125; HashMap 的 key 是唯一的，由上面的代码可以看出 HashSet 添加进去的值就是作为 HashMap 的key。所以不会重复（ HashMap 比较key是否相等是先比较 hashcode 在比较 equals ）。 4、List集合和Set集合的区别 List , Set 都是继承自 Collection 接口 List 特点：元素有放入顺序，元素可重复 ， Set 特点：元素无放入顺序，元素不可重复，重复元素会覆盖掉，（元素虽然无放入顺序，但是元素在set中的位置是有该元素的 HashCode 决定的，其位置其实是固定的，加入Set 的 Object 必须定义 equals ()方法 ，另外list支持for循环，也就是通过下标来遍历，也可以用迭代器，但是set只能用迭代，因为他无序，无法用下标来取得想要的值。） Set和List对比 ： Set：检索元素效率低下，删除和插入效率高，插入和删除不会引起元素位置改变。 List：和数组类似，List可以动态增长，查找元素效率高，插入删除元素效率低，因为会引起其他元素位置改变。 5、Collection包结构，其与Collections的区别 Collection是集合类的上级接口，子接口有 Set、List、LinkedList、ArrayList、Vector、Stack、Set； Collections是集合类的一个帮助类，它包含有各种有关集合操作的静态多态方法，用于实现对各种集合的搜索、排序、线程安全化等操作。此类不能实例化，就像一个工具类，服务于Java的Collection框架。 6、 HashMap和HashTable的区别 （1）两者父类不同 HashMap是继承自AbstractMap类； Hashtable是继承自Dictionary类； （2）对null的支持不同 HashMap：key 和 value都可以为null，key不可重复，value可重复； HashTable：key和value都不能为null，key不可重复，value可重复； （3）安全性不同 HashMap是线程不安全的，在多线程并发的环境下，可能会产生死锁等问题，因此需要开发人员自己处理多线程的安全问题。 HashTable是线程安全的，它的每个方法上都有synchronized 关键字，因此可直接用于多线程中。虽然HashMap是线程不安全的，但是它的效率远远高于HashTable，这样设计是合理的，因为大部分的使用场景都是单线程。当需要多线程操作的时候可以使用线程安全的ConcurrentHashMap。 ConcurrentHashMap虽然也是线程安全的，但是它的效率比Hashtable要高好多倍。因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。 （5）计算hash值的方法不同 6、HashMap 是线程安全的吗，为什么不是线程安全的? 不是线程安全的； 如果有两个线程A和B，都进行插入数据，刚好这两条不同的数据经过哈希计算后得到的哈希码是一样的，且该位置还没有其他的数据。所以这两个线程都会进入我在上面标记为1的代码中。假设一种情况，线程A通过if判断，该位置没有哈希冲突，进入了if语句，还没有进行数据插入，这时候 CPU 就把资源让给了线程B，线程A停在了if语句里面，线程B判断该位置没有哈希冲突（线程A的数据还没插入），也进入了if语句，线程B执行完后，轮到线程A执 行，现在线程A直接在该位置插入而不用再判断。这时候，你会发现线程A把线程B插入的数据给覆盖了。发生了线程不安全情况。本来在 HashMap 中，发生哈希冲突是可以用链表法或者红黑树来解决的，但是在多线程中，可能就直接给覆盖了。 7、HashMap 的扩容过程 当向容器添加元素的时候，会判断当前容器的元素个数，如果大于等于阈值 — 即当前数组的长度乘以加载因子的值的时候，就要自动扩容啦。 扩容( resize )就是重新计算容量，向 HashMap 对象里不停的添加元素，而 HashMap 对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然 Java 里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 123456HashMap hashMap&#x3D;new HashMap(cap);cap&#x3D;3， hashMap 的容量为4； cap&#x3D;4， hashMap 的容量为4；cap&#x3D;5， hashMap 的容量为8； cap&#x3D;9， hashMap 的容量为16； 如果 cap 是2的n次方，则容量为 cap ，否则为大于 cap 的第一个2的n次方的数。 8、HashMap，HashTable，ConcurrentHashMap的共同点和区别 思路：可以从它们的底层结构、是否允许存储null，是否线性安全等几个维度进行描述，最后可以向面试官描述一下HashMap的死循环问题，以及ConcurrentHashMap为啥放弃分段锁。 HashMap 底层由链表+数组实现； 可以存储null键和null值； 线性不安全； 初始容量为16，扩容每次都是2的n次幂； 加载因子为0.75，当Map中元素总数超过Entry数组的0.75，触发扩容操作； 并发情况下，HashMap进行put操作会引起死循环，导致CPU利用率接近100%； HashTable HashTable的底层也是由链表+数组实现； 无论key还是value都不能为null； 它是线性安全的，使用了synchronized关键字； ConcurrentHashMap ConcurrentHashMap的底层是数组+链表/红黑树 不能存储null键和值 ConcurrentHashMap是线程安全的 ConcurrentHashMap使用 锁分段技术 确保线性安全 JDK8为何又放弃分段锁，是因为多个分段锁浪费内存空间，竞争同一个锁的概率非常小，分段锁反而会造成效率低。 JDK8的实现已经抛弃了Segment分段锁机制，利用 CAS+Synchronized 来保证并发更新的安全。数据结构采用：数组+链表/红黑树 9、HashMap死循环 原因分析： 在内部，HashMap使用一个Entry数组保存key、value数据，当一对key、value被加入时，会通过一个hash算法得到数组的下标index，算法很简单，根据key的hash值，对数组的大小取模 hash &amp; (length-1)，并把结果插入数组该位置，如果该位置上已经有元素了，就说明存在hash冲突，这样会在index位置生成链表。 如果存在hash冲突，最惨的情况，就是所有元素都定位到同一个位置，形成一个长长的链表，这样get一个值时，最坏情况需要遍历所有节点，性能变成了O(n)，所以元素的hash值算法和HashMap的初始化大小很重要。 当插入一个新的节点时，如果不存在相同的key，则会判断当前内部元素是否已经达到阈值（默认是数组大小的0.75），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。 jdk1.8以前： 在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。 曾经有人把这个问题报给了Sun，不过Sun不认为这是一个bug，因为在HashMap本来就不支持多线程使用，要并发就用ConcurrentHashmap。 jdk1.8以后： 底层改成数组+链表/红黑树，插入链表时头插法改成了尾插法 9、说说List,Set,Map三者的区别？ List(对付顺序的好帮手)： List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 Set(注重独一无二的性质): 不允许重复的集合。不会有多个元素引用相同的对象。 Map(用Key来搜索的专家): 使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://ctrl98.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://ctrl98.github.io/tags/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"Redis 持久化方式","slug":"Redis4","date":"2020-03-25T10:36:33.000Z","updated":"2020-03-25T11:20:24.571Z","comments":true,"path":"2020/03/25/Redis4/","link":"","permalink":"http://ctrl98.github.io/2020/03/25/Redis4/","excerpt":"","text":"持久化方式之RDB RDB（快照）持久化：保存某个时间点的全量数据快照 我们以window为例，查看redis的配置文件信息 redis.window.conf 文件。 RDB配置 搜索查找关键词 save 查看相关快照策略： save 上面的 900 表示900秒后，会进行一次快照备份。 如果写入数大于10，就会在300秒进行快照备份，以此类推。 stop-writes-on-bgsave-error 该配置默认是 yes 开启，表示备份出错的时候，主进程就拒绝写入操作，这样做是为了保护数据持久化的一致性 rdbcompression 该配置默认开启，备份的时候将rdb文件压缩后再作保存。 如果禁用RDB配置，只需在图一的 save 后面添加： 1save &quot;&quot; 在与配置文件的目录下，你会发现有一个叫 dump.rdb 的文件，这个就是用来储存数据的，里面都是乱码。 手动触发RDB操作 1、通过 save 命令：阻塞Redis的服务进程，知道RDB文件被创建完毕。 2、通过 BGSAVE 命令：Fork出一个子进程来创建RDB文件，不阻塞服务器进程。 把原来的dump.rdb 的文件删除，连接redis的客户端，执行 save 命令，客户端处于卡顿状态，隔了一会就会返回 ok，再次查看文件列表，会发现多出一个 dump.rdb 的文件 再次把dump.rdb 的文件删除，执行 lastsave ，他会返回一串数字，就是上次执行save命令的时间。执行 bgsave 命令，客户端会立马返回 saving started，并没有卡顿。 自动触发RDB持久化 根据redis.conf配置里的 SAVE m n定时触发（用的是BGSAVE） 主从复制时，主节点自动触发 执行Debug Reload 执行ShutDown且没有开启AOF持久化 持久化方式之AOF AOF（Append-Only-File）持久化：保存写状态 记录下除了查询以外的所有变更数据库状态的指令 以append的形式追加到AOF文件中（增量） 配置 该方式默认是关闭的，找到配置文件的 appendonly 属性，把 no 改成 yes 即生效。 上图中，表示每一秒会把redis的数据内容写入aof文件，改完后重启服务。 RDB和AOF的优缺点 RDB 优点：全量数据快照，文件小，恢复快 缺点：无法保证最近一次快照之后的数据 AOF 优点：可读性高，适合保存增量数据，数据不易丢失 缺点：文件体积大，恢复时间长 RDB-AOF混合持久化方式 redis4.0后退出的方式，并且作为默认的方式，结合了两种方式的优点。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Java 多线程与并发基础原理一","slug":"Java多线程与并发1","date":"2020-03-24T02:33:16.000Z","updated":"2020-03-24T08:08:03.670Z","comments":true,"path":"2020/03/24/Java多线程与并发1/","link":"","permalink":"http://ctrl98.github.io/2020/03/24/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%911/","excerpt":"","text":"进程与线程的区别 注意：Oracle官方公布将支持jdk8版本到2025年、支持jdk11版本到2026年，一般不用jdk9或者10，因为官方对其支持周期时间短。 定义 进程 每个进程对应一个程序，每个进程对应一定的内存地址空间，并且只能使用它自己的内存空间，各个进程间互不干扰，并且保存了每个进程的运行状态，为进程切换提供可能，比如电脑运行多个软件且来换切换应用。 进程让操作系统的并发成为了可能，虽然并发从宏观上看，由多个任务在执行，但是事实上对于单核CPU机器来讲，任意一个时刻，只能有一个任务在占用CPU资源。而让用户看起来像同一时刻并发执行多个任务的原因是单核CPU分配给单一任务的时间片很短，切换的频次高，造成了并发执行的假象。 线程 随着电脑的普及，人们对实时性的要求越来越高，因为一个进程在一定的时间内只做一件事情，如果一个进程有多个子任务，只能逐个地去执行这些子任务，而子任务往往不存在顺序上的依赖，所以是可以并发执行的。所以人们就发明了线程，让每个线程去执行每个子任务，这样一个进程就包括了多个线程，每个线程负责每一个独立的子任务，力求达到实时性的效果。线程让进程的内部并发成为可能。 区别 进程是资源分配的最小单位，线程是CPU调度的最先单位 进程有独立的地址空间，相互不影响，线程没有 线程属于某个进程，共享其资源 Thread的start方法和run方法的区别 在main函数主线程中创建一个Thread对象，并编写run方法： 12345678910111213141516public class ThreadTest&#123; private static void attack()&#123; System.out.println(\"正在运行中----\"); System.out.println(\"current Thread is \" + Thread.currentThread().getName()); &#125; public static void main(String[] args)&#123; Thread t = new Thread()&#123; public void run()&#123; attack(); &#125; &#125;; System.out.println(\"current main Thread is \" + Thread.currentThread().getName()); t.run(); &#125;&#125; 执行后结果可发现： 123current main Thread is main正在运行中----current Thread is main 线程调用run方法，只会在主线程中上执行该方法，并不会创建新的线程。 当线程对象调用start方法时： 12345678910111213141516public class ThreadTest&#123; private static void attack()&#123; System.out.println(\"正在运行中----\"); System.out.println(\"current Thread is \" + Thread.currentThread().getName()); &#125; public static void main(String[] args)&#123; Thread t = new Thread()&#123; public void run()&#123; attack(); &#125; &#125;; System.out.println(\"current main Thread is \" + Thread.currentThread().getName()); t.start(); &#125;&#125; 执行后结果可发现： 123current main Thread is main正在运行中----current Thread is Thread-0 线程调用start方法，会在主线程中创建新的线程去执行Thread的run。 查看start的源码方法，在jdk中发现，是jvm的jvm_startThread方法。 Thread和Runnable是什么关系 实际上，Thread是一个类，而Runnable是一个接口，两个都可以创建新的线程。 我们用Thread来创建一个线程来看看： 12345678910111213141516public class MyThread &#123; public static void main(String[] args) &#123; ThreadA threadA = new ThreadA(); threadA.start(); &#125;&#125;class ThreadA extends Thread &#123; @Override public void run() &#123; System.out.println(\"run is running\"); super.run(); &#125;&#125; ThreadA类继承Thread类，并覆写其run方法，在主线程上开启新的线程。 我们看看Thread类的源码发现： 12publicclass Thread implements Runnable Thread类是通过实现Runnable接口来重写run方法，然后Thread本身就包含很多方法。 我们用Runnable来创建新线程看看： 123456789101112131415161718public class MyRunnable &#123; public static void main(String[] args) &#123; ThreadB threadB = new ThreadB(); Thread thread = new Thread(threadB); thread.start(); &#125;&#125;class ThreadB implements Runnable &#123; @Override public void run() &#123; System.out.println(\"runnable is running\"); &#125;&#125; ThreadB类实现Runnable接口并重写其run方法，然后通过Thread类中的 Thread(Runnable target) 构造方法传入一个Runnable对象来创建线程。 关系：Thread是实现Runnable接口的类，为run方法提供多线程 线程的状态 五个状态 新建（new）：创建后尚未启动的线程 就绪（Runnable）：调用start方法后，等待获取CPU的使用权 运行（Running）：成功获取CPU使用权 阻塞（Blocked）：被人为挂起或耗时处理进入阻塞，当阻塞消除后进入就绪状态 结束（Termeinated）：调用了stop()方法或者run方法执行完毕 sleep和wait的区别 基本差别： sleep是Thread类的方法，wait是Object类中定义的方法 sleep方法可以在任何地方使用 wait方法只能在synchronized方法或synchronized块中使用 wait方法如不传参数，会进入无限期等待状态 最主要的本质区别： Thread.sleep只会让出CPU，不会导致锁行为的改变 Object.wait不仅让出CPU，还会释放已经占有的同步资源锁 下面举一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.thread;public class WaitSleepDemo &#123; public static void main(String[] args) &#123; final Object lock = new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"thread a is waiting to get lock\"); synchronized (lock) &#123; try &#123; System.out.println(\"thread a get lock\"); Thread.sleep(20); System.out.println(\"thread a do wait method\"); lock.wait(1000); System.out.println(\"thread a is done\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); //为了确保两个线程按顺序执行，让主线程休眠10毫秒 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"thread b is waiting to get lock\"); synchronized (lock) &#123; try &#123; System.out.println(\"thread b get lock\"); System.out.println(\"thread b is sleeping 10ms\"); Thread.sleep(10); System.out.println(\"thread b is done\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 打印的结果为： 12345678thread a is waiting to get lockthread a get lockthread b is waiting to get lockthread a do wait methodthread b get lockthread b is sleeping 10msthread b is donethread a is done 说明： 1、当创建并执行线程a时，线程a执行run方法，打印 thread a is waiting to get lock ，获取锁后打印 thread a get lock 2、线程a调用sleep方法让出CPU使用权，此时线程b被创建并且执行，线程b执行run方法打印 thread b is waiting to get lock，由于线程a调用的是sleep方法，没有释放锁，线程b获取不了锁，因此线程b进入阻塞 3、线程a获得CPU使用权，打印 thread a do wait method，调用Object对象的wait方法后，线程a让出CPU使用权并且释放锁 4、此时CPU执行线程b，线程b获取锁后打印 thread b get lock ，接着打印 thread b is sleeping 10ms，进入休眠状态，让出CPU使用权，注意此时也没有释放锁，所以线程a还是处于阻塞状态，线程b再获得使用权，打印 thread b is done ，线程b执行结束后释放锁，紧接着线程a才再次获得锁，打印出 thread a is done。 notify和notifyall的区别 notify是Object类中的定义一个方法，用于唤醒某个处于无限期等待的线程。 修改上面的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.thread;public class WaitSleepDemo &#123; public static void main(String[] args) &#123; final Object lock &#x3D; new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;thread a is waiting to get lock&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;thread a get lock&quot;); Thread.sleep(20); System.out.println(&quot;thread a do wait method&quot;); lock.wait(); System.out.println(&quot;thread a is done&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#x2F;&#x2F;为了确保两个线程按顺序执行，让主线程休眠10毫秒 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;thread b is waiting to get lock&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;thread b get lock&quot;); System.out.println(&quot;thread b is sleeping 10ms&quot;); Thread.sleep(10); System.out.println(&quot;thread b is done&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 主要是把 wait 方法的参数去掉，再次执行，会发现线程b执行完毕后，线程a一直处于无限等待中，需要把它唤醒才能接着执行线程a剩下的代码，在线程b执行结束后调用notify或者是notifyAll方法： 1lock.notify(); 执行后发现程序都执行完毕了，说明唤醒成功。这两个方法有什么不同呢？ 区别 先了解两个概念： 锁池EntryList 等待池WaitSet notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁 notify只会随机选取一个处于等待池的线程进入锁池去竞争获取锁 yield函数 概念 当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意让出CPU使用权的暗示，但是线程调度器可能会忽视这个暗示。 下面举个例子： 12345678910111213141516171819202122232425package org.thread;public class YieldDemo &#123; public static void main(String[] args) &#123; Runnable yieldTask = new Runnable() &#123; @Override public void run() &#123; for (int i = 1; i &lt;= 10; i++) &#123; System.out.println(Thread.currentThread().getName() + i); if (i == 5) &#123; Thread.yield(); &#125; &#125; &#125; &#125;; Thread t1 = new Thread(yieldTask,\"Thread-A \"); Thread t2 = new Thread(yieldTask,\"Thread-B \"); t1.start(); t2.start(); &#125;&#125; 从打印的内容来看，无论哪个线程打印到5的时候，该线程时随机让出CPU的使用权的，并不是每次都会让出。 interrupt函数 如何去中断线程 已经被抛弃的方法： 通过调用stop方法停止线程，不安全且暴力。 通过调用suspend方法停止线程 通过调用resume方法停止线程 目前使用的方法： 调用interrupt()方法，通知线程应该中断。 如果线程处于被阻塞状态，那么该线程将立即退出被阻塞状态，并且抛出一个InterruptedException异常 如果线程处于正常活动状态，那么会将该线程的中断标志设置为true，被设置中断标志的线程将继续正常运行，不受影响。 需要被调用的线程配合中断 在正常运行任务时，经常检查本线程的中断标志，如果时true，则立即自行停止线程。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://ctrl98.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java多线程","slug":"Java多线程","permalink":"http://ctrl98.github.io/tags/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"http://ctrl98.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Spring Cloud Alibaba 异步通信","slug":"Spring-Cloud-Alibaba4","date":"2020-03-15T06:48:20.000Z","updated":"2020-03-16T10:45:33.101Z","comments":true,"path":"2020/03/15/Spring-Cloud-Alibaba4/","link":"","permalink":"http://ctrl98.github.io/2020/03/15/Spring-Cloud-Alibaba4/","excerpt":"","text":"消息队列的流派 什么是 MQ Message Queue（MQ），消息队列中间件。很多人都说：MQ 通过将消息的发送和接收分离来实现应用程序的异步和解偶，这个给人的直觉是——MQ 是异步的，用来解耦的，但是这个只是 MQ 的效果而不是目的。MQ 真正的目的是为了通讯，屏蔽底层复杂的通讯协议，定义了一套应用层的、更加简单的通讯协议。一个分布式系统中两个模块之间通讯要么是 HTTP，要么是自己开发的 TCP，但是这两种协议其实都是原始的协议。HTTP 协议很难实现两端通讯——模块 A 可以调用 B，B 也可以主动调用 A，如果要做到这个两端都要背上 WebServer，而且还不支持长连接（HTTP 2.0 的库根本找不到）。TCP 就更加原始了，粘包、心跳、私有的协议，想一想头皮就发麻。MQ 所要做的就是在这些协议之上构建一个简单的“协议”——生产者/消费者模型。MQ 带给我的“协议”不是具体的通讯协议，而是更高层次通讯模型。它定义了两个对象——发送数据的叫生产者；接收数据的叫消费者， 提供一个 SDK 让我们可以定义自己的生产者和消费者实现消息通讯而无视底层通讯协议。 有 Broker 的 MQ 这个流派通常有一台服务器作为 Broker，所有的消息都通过它中转。生产者把消息发送给它就结束自己的任务了，Broker 则把消息主动推送给消费者（或者消费者主动轮询） 重 Topic kafka、JMS（ActiveMQ）就属于这个流派，生产者会发送 key 和数据到 Broker，由 Broker 比较 key 之后决定给哪个消费者。这种模式是我们最常见的模式，是我们对 MQ 最多的印象。在这种模式下一个 topic 往往是一个比较大的概念，甚至一个系统中就可能只有一个 topic，topic 某种意义上就是 queue，生产者发送 key 相当于说：“hi，把数据放到 key 的队列中” 。 如上图所示，Broker 定义了三个队列，key1，key2，key3，生产者发送数据的时候会发送 key1 和 data，Broker 在推送数据的时候则推送 data（也可能把 key 带上）。 虽然架构一样但是 kafka 的性能要比 jms 的性能不知道高到多少倍，所以基本这种类型的 MQ 只有 kafka 一种备选方案。如果你需要一条暴力的数据流（在乎性能而非灵活性）那么 kafka 是最好的选择。 轻 Topic 这种的代表是 RabbitMQ（或者说是 AMQP）。生产者发送 key 和数据，消费者定义订阅的队列，Broker 收到数据之后会通过一定的逻辑计算出 key 对应的队列，然后把数据交给队列。 这种模式下解耦了 key 和 queue，在这种架构中 queue 是非常轻量级的（在 RabbitMQ 中它的上限取决于你的内存），消费者关心的只是自己的 queue；生产者不必关心数据最终给谁只要指定 key 就行了，中间的那层映射在 AMQP 中叫 exchange（交换机）。 AMQP 中有四种 exchange Direct exchange：key 就等于 queue Fanout exchange：无视 key，给所有的 queue 都来一份 Topic exchange：key 可以用“宽字符”模糊匹配 queue Headers exchange：无视 key，通过查看消息的头部元数据来决定发给那个 queue（AMQP 头部元数据非常丰富而且可以自定义） 这种结构的架构给通讯带来了很大的灵活性，我们能想到的通讯方式都可以用这四种 exchange 表达出来。如果你需要一个企业数据总线（在乎灵活性）那么 RabbitMQ 绝对的值得一用。 无 Broker 的 MQ 无 Broker 的 MQ 的代表是 ZeroMQ。该作者非常睿智，他非常敏锐的意识到——MQ 是更高级的 Socket，它是解决通讯问题的。所以 ZeroMQ 被设计成了一个“库”而不是一个中间件，这种实现也可以达到——没有 Broker 的目的。 节点之间通讯的消息都是发送到彼此的队列中，每个节点都既是生产者又是消费者。ZeroMQ 做的事情就是封装出一套类似于 Socket 的 API 可以完成发送数据，读取数据 ZeroMQ 其实就是一个跨语言的、重量级的 Actor 模型邮箱库。你可以把自己的程序想象成一个 Actor，ZeroMQ 就是提供邮箱功能的库；ZeroMQ 可以实现同一台机器的 RPC 通讯也可以实现不同机器的 TCP、UDP 通讯，如果你需要一个强大的、灵活、野蛮的通讯能力，别犹豫 ZeroMQ。 附：Queue 和 Topic 的区别 Queue： 一个发布者发布消息，下面的接收者按队列顺序接收，比如发布了 10 个消息，两个接收者 A,B 那就是 A,B 总共 会收到 10 条消息，不重复。 Topic： 一个发布者发布消息，有两个接收者 A,B 来订阅，那么发布了 10 条消息，A,B 各收到 10 条消息。 类型 Topic Queue 概要 Publish Subscribe Messaging 发布订阅消息 Point-to-Point 点对点 有无状态 Topic 数据默认不落地，是无状态的。 Queue 数据默认会在 MQ 服务器上以文件形式保存，比如 ActiveMQ 一般保存在 $AMQ_HOME\\data\\kr-store\\data 下面。也可以配置成 DB 存储。 完整性保障 并不保证 Publisher 发布的每条数据，Subscriber 都能接受到。 Queue 保证每条数据都能被 Receiver 接收。 消息是否会丢失 一般来说 Publisher 发布消息到某一个 Topic 时，只有正在监听该 Topic 地址的 Sub 能够接收到消息；如果没有 Sub 在监听，该 Topic 就丢失了。 Sender 发送消息到目标 Queue，Receiver 可以异步接收这个 Queue 上的消息。Queue 上的消息如果暂时没有 Receiver 来取，也不会丢失。 消息发布接收策略 一对多的消息发布接收策略，监听同一个 Topic 地址的多个 Sub 都能收到 Publisher 发送的消息。Sub 接收完通知 MQ 服务器 一对一的消息发布接收策略，一个 Sender 发送的消息，只能有一个 Receiver 接收。Receiver 接收完后，通知 MQ 服务器已接收，MQ 服务器对 Queue 里的消息采取删除或其他操作。 RocketMQ 概述 阿里巴巴写的一个MQ，他的前身是activeMQ，RocketMQ是Apache的一个项目，但是写代码的是阿里巴巴。消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下优势： 削峰填谷： 主要解决瞬时写压力大于应用服务能力导致消息丢失、系统奔溃等问题 系统解耦： 解决不同重要程度、不同能力级别系统之间依赖导致一死全死 提升性能： 当存在一对多调用时，可以发一条消息给消息系统，让消息系统通知相关系统 蓄流压测： 线上有些链路不好压测，可以通过堆积一定量消息再放开来压测 RocketMQ Apache Alibaba RocketMQ 是一个消息中间件。消息中间件中有两个角色：消息生产者和消息消费者。RocketMQ 里同样有这两个概念，消息生产者负责创建消息并发送到 RocketMQ 服务器，RocketMQ 服务器会将消息持久化到磁盘，消息消费者从 RocketMQ 服务器拉取消息并提交给应用消费。 RocketMQ 特点 RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： 支持严格的消息顺序 支持 Topic 与 Queue 两种模式 亿级消息堆积能力 比较友好的分布式特性 同时支持 Push 与 Pull 方式消费消息 历经多次天猫双十一海量消息考验 RocketMQ 优势 目前主流的 MQ 主要是 RocketMQ、kafka、RabbitMQ，其主要优势有： 支持事务型消息（消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 不支持） 支持结合 RocketMQ 的多个系统之间数据最终一致性（多方事务，二方事务是前提） 支持 18 个级别的延迟消息（RabbitMQ 和 Kafka 不支持） 支持指定次数和时间间隔的失败消息重发（Kafka 不支持，RabbitMQ 需要手动确认） 支持 Consumer 端 Tag 过滤，减少不必要的网络传输（RabbitMQ 和 Kafka 不支持） 支持重复消费（RabbitMQ 不支持，Kafka 支持） 消息队列对比参照表 基于 Docker 安装 RocketMQ rocketmq需要三个容器，server、broker和console docker-compose启动 简单粗暴，如果你的虚拟机安装了docker-compose，那就很方便了，直接构建服务和容器。 docker-compose.yaml 使用docker-compose来直接构建三个所需容器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455version: '3.5'services: rmqnamesrv: image: foxiswho/rocketmq:server container_name: rmqnamesrv ports: - 9876:9876 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store networks: rmq: aliases: - rmqnamesrv rmqbroker: image: foxiswho/rocketmq:broker container_name: rmqbroker ports: - 10909:10909 - 10911:10911 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store - ./data/brokerconf/broker.conf:/etc/rocketmq/broker.conf environment: NAMESRV_ADDR: \"rmqnamesrv:9876\" JAVA_OPTS: \" -Duser.home=/opt\" JAVA_OPT_EXT: \"-server -Xms128m -Xmx128m -Xmn128m\" command: mqbroker -c /etc/rocketmq/broker.conf depends_on: - rmqnamesrv networks: rmq: aliases: - rmqbroker rmqconsole: image: styletang/rocketmq-console-ng container_name: rmqconsole ports: - 8080:8080 environment: JAVA_OPTS: \"-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" depends_on: - rmqnamesrv networks: rmq: aliases: - rmqconsolenetworks: rmq: name: rmq driver: bridge broker.conf RocketMQ Broker 需要一个配置文件，按照上面的 Compose 配置，我们需要在 ./data/brokerconf/ 目录下创建一个名为 broker.conf 的配置文件，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# 所属集群名字brokerClusterName&#x3D;DefaultCluster# broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a,# 在 broker-b.properties 使用: broker-bbrokerName&#x3D;broker-a# 0 表示 Master，&gt; 0 表示 SlavebrokerId&#x3D;0# nameServer地址，分号分割# namesrvAddr&#x3D;rocketmq-nameserver1:9876;rocketmq-nameserver2:9876# 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;192.168.0.120:10909&gt; failed# 解决方式1 加上一句 producer.setVipChannelEnabled(false);，解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP# brokerIP1&#x3D;192.168.0.253# 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums&#x3D;4# 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，falseautoCreateTopicEnable&#x3D;true# 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup&#x3D;true# Broker 对外服务的监听端口listenPort&#x3D;10911# 删除文件时间点，默认凌晨4点deleteWhen&#x3D;04# 文件保留时间，默认48小时fileReservedTime&#x3D;120# commitLog 每个文件的大小默认1GmapedFileSizeCommitLog&#x3D;1073741824# ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整mapedFileSizeConsumeQueue&#x3D;300000# destroyMapedFileIntervalForcibly&#x3D;120000# redeleteHangedFileInterval&#x3D;120000# 检测物理文件磁盘空间diskMaxUsedSpaceRatio&#x3D;88# 存储路径# storePathRootDir&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store# commitLog 存储路径# storePathCommitLog&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;commitlog# 消费队列存储# storePathConsumeQueue&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;consumequeue# 消息索引存储路径# storePathIndex&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;index# checkpoint 文件存储路径# storeCheckpoint&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;checkpoint# abort 文件存储路径# abortFile&#x3D;&#x2F;home&#x2F;ztztdata&#x2F;rocketmq-all-4.1.0-incubating&#x2F;store&#x2F;abort# 限制的消息大小maxMessageSize&#x3D;65536# flushCommitLogLeastPages&#x3D;4# flushConsumeQueueLeastPages&#x3D;2# flushCommitLogThoroughInterval&#x3D;10000# flushConsumeQueueThoroughInterval&#x3D;60000# Broker 的角色# - ASYNC_MASTER 异步复制Master# - SYNC_MASTER 同步双写Master# - SLAVEbrokerRole&#x3D;ASYNC_MASTER# 刷盘方式# - ASYNC_FLUSH 异步刷盘# - SYNC_FLUSH 同步刷盘flushDiskType&#x3D;ASYNC_FLUSH# 发消息线程池数量# sendMessageThreadPoolNums&#x3D;128# 拉消息线程池数量# pullMessageThreadPoolNums&#x3D;128 直接访问 http://rmqIP:8080 登入控制台，即可看到控制台界面。 镜像拉取启动 这里因为本虚拟机无法安装 docker-compose，所以采用一个个镜像拉取启动。 使用centos7查找镜像： 1docker search rocketmq 这里选取 foxiswho/rocketmq，查看该镜像的所有版本： 123curl https:&#x2F;&#x2F;registry.hub.docker.com&#x2F;v1&#x2F;repositories&#x2F;foxiswho&#x2F;rocketmq&#x2F;tags\\| tr -d &#39;[\\[\\]&quot; ]&#39; | tr &#39;&#125;&#39; &#39;\\n&#39;\\| awk -F: -v image&#x3D;&#39;foxiswho&#x2F;rocketmq&#39; &#39;&#123;if(NR!&#x3D;NF &amp;&amp; $3 !&#x3D; &quot;&quot;)&#123;printf(&quot;%s:%s\\n&quot;,image,$3)&#125;&#125;&#39; 如想查看其他镜像的所包含的所有版本，把’foxiswho/rocketmq’换成你想查的镜像名称即可。 我们需要该镜像里的 foxiswho/rocketmq:server-4.5.1 和 foxiswho/rocketmq:broker-4.5.1 两版本。 启动Server 这里不用拉取镜像，直接创建server容器： 1docker run -d -p 9876:9876 --name rmqserver foxiswho&#x2F;rocketmq:server-4.5.1 启动Broker 在以下目录创建一个配置文件目录进行文件挂载： 12cd &#x2F;usr&#x2F;localmkdir conf 构建broker容器： 12345docker run -di -p 10911:10911 -p 10909:10909\\ --name rmqbroker --link rmqserver:namesrv\\ -e &quot;NAMESRV_ADDR&#x3D;namesrv:9876&quot; -e &quot;JAVA_OPTS&#x3D;-Duser.home&#x3D;&#x2F;opt&quot;\\ -e &quot;JAVA_OPT_EXT&#x3D;-server -Xms128m -Xmx128m&quot;\\ foxiswho&#x2F;rocketmq:broker-4.5.1 其中 /conf/broker.conf.old为容器中的配置文件目录，把该文件内容换成上面broker.conf的配置文件即可。 构建console控制台界面 1234docker run -di --name rmqconsole -p 8180:8080 --link rmqserver:namesrv\\ -e &quot;JAVA_OPTS&#x3D;-Drocketmq.namesrv.addr&#x3D;namesrv:9876\\ -Dcom.rocketmq.sendMessageWithVIPChannel&#x3D;false&quot;\\ -t styletang&#x2F;rocketmq-console-ng 访问：宿主机ip:8180 即可访问。 RocketMQ 生产者 概述 RocketMQ 是一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 整个项目都基于 Spring Cloud，故采用 Spring Cloud Stream 完成一次发布和订阅。 官方教程 Spring Cloud Stream Spring Cloud Stream 是一个用于构建基于消息的微服务应用框架。它基于 Spring Boot 来创建具有生产级别的单机 Spring 应用，并且使用 Spring Integration 与 Broker 进行连接。 Spring Cloud Stream 提供了消息中间件配置的统一抽象，推出了 publish-subscribe、consumer groups、partition 这些统一的概念。 Spring Cloud Stream 内部有两个概念： Binder： 跟外部消息中间件集成的组件，用来创建 Binding，各消息中间件都有自己的 Binder 实现。 Binding： 包括 Input Binding 和 Output Binding。 Binding 在消息中间件与应用程序提供的 Provider 和 Consumer 之间提供了一个桥梁，实现了开发者只需使用应用程序的 Provider 或 Consumer 生产或消费数据即可，屏蔽了开发者与底层消息中间件的接触。 解决连接超时问题 在上面部署broker的时候，此时 RocketMQ Broker 暴露的地址和端口(10909，10911)是基于容器的，会导致我们开发机无法连接，从而引发 org.apache.rocketmq.remoting.exception.RemotingTooMuchRequestException: sendDefaultImpl call timeout 异常 注意下图中的 IP 地址，这个是容器的 IP，开发机与容器不在一个局域网所以无法连接。 解决方案是在 broker.conf 配置文件中增加 brokerIP1=宿主机IP 即可。 1docker exec -it rmqbroker &#x2F;bin&#x2F;bash 找到broker.conf文件： 1cd &#x2F;etc&#x2F;rocketmq 在broker.conf文件添加以下内容： 1brokerIP1&#x3D;宿主机ip 创建rocketmq服务提供者 在项目中创建一个名为spring-cloud-alibaba-rocketmq-provider的module，pom文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-rocketmq-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-rocketmq-provider&lt;/name&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.rocketmq.provider.RocketMQProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-stream-rocketmq 依赖。 创建配置文件： 12345678910111213spring: cloud: stream: bindings: output: &#123;destination: test-topic, content-type: application/json&#125; rocketmq: binder: namesrv-addr: 宿主机ip:9876 application: name: rockermq-providerserver: port: 9093 创建启动类： 1234567891011121314151617181920212223242526272829303132package org.lee.spring.cloud.alibaba.rocketmq.provider;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.CommandLineRunner;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Source;import org.springframework.messaging.MessageChannel;import org.springframework.messaging.support.MessageBuilder;@SpringBootApplication@EnableBinding(&#123; Source.class &#125;)public class RocketMQProviderApplication implements CommandLineRunner &#123; @Autowired private MessageChannel output; // 获取name为output的binding public static void main(String[] args) &#123; SpringApplication.run(RocketMQProviderApplication.class,args); &#125; /** * 该接口的实现方法在springboot应用启动时自动执行，只用来测试demo使用 * @param args * @throws Exception */ @Override public void run(String... args) throws Exception &#123; output.send(MessageBuilder.withPayload(\"Hello rocketMQ\").build());//发一条消息 &#125;&#125; 注解解析： @EnableBinding：表明是发送信息还是订阅信息 Source.class：发送消息（提供者） Sink.class：订阅消息 启动该服务之后，去网页刷新 ： 宿主机ip:8180 网页，去到主题页面： 发现多一个test-topic的主题 去到消息页面，选择test-topic，就会看到我们刚才发的消息。 RocketMQ 消费者 创建一个名为spring-cloud-alibaba-rocketmq-consumer的module，pom文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-rocketmq-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-rocketmq-consumer&lt;/name&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.rocketmq.consumer.RocketMQConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建启动类 1234567891011121314151617181920package org.lee.spring.cloud.alibaba.rocketmq.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;@SpringBootApplication@EnableBinding(&#123;Sink.class&#125;)public class RocketMQConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RocketMQConsumerApplication.class,args); &#125; @StreamListener(\"input\")//监听名为 input的消息 public void receiveInput1(String receiveMsg) &#123; System.out.println(\"input receive: \" + receiveMsg); &#125;&#125; 配置文件： 12345678910111213spring: cloud: stream: bindings: input: &#123;destination: test-topic, content-type: application/json, group: test-group&#125; rocketmq: binder: namesrv-addr: 宿主机ip:9876 application: name: rockermq-consumerserver: port: 9094 启动该程序，看控制台打印：","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Alibaba 链路追踪","slug":"Spring-Cloud-Alibaba3","date":"2020-03-14T01:46:06.000Z","updated":"2020-03-15T01:49:16.108Z","comments":true,"path":"2020/03/14/Spring-Cloud-Alibaba3/","link":"","permalink":"http://ctrl98.github.io/2020/03/14/Spring-Cloud-Alibaba3/","excerpt":"","text":"链路追踪 什么是链路追踪 微服务架构是通过业务来划分服务的，使用 REST 调用。对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂。 随着服务的越来越多，对调用链的分析会越来越复杂。它们之间的调用关系也许如下： 面对以上情况，我们就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题，这就是所谓的 APM（应用性能管理）。 什么是 SkyWalking 目前主要的一些 APM 工具有: Cat、Zipkin、Pinpoint、SkyWalking；Apache SkyWalking 是观察性分析平台和应用性能管理系统。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 Skywalking Agent： 使用 JavaAgent 做字节码植入，无侵入式的收集，并通过 HTTP 或者 gRPC 方式发送数据到 SkyWalking Collector。 SkyWalking Collector： 链路数据收集器，对 agent 传过来的数据进行整合分析处理并落入相关的数据存储中。 Storage： SkyWalking 的存储，时间更迭，SW 已经开发迭代到了 6.x 版本，在 6.x 版本中支持以 ElasticSearch(支持 6.x)、Mysql、TiDB、H2、作为存储介质进行数据存储。 UI： Web 可视化平台，用来展示落地的数据。 SkyWalking 功能特性 多种监控手段，语言探针和服务网格(Service Mesh) 多语言自动探针，Java，.NET Core 和 Node.JS 轻量高效，不需要大数据 模块化，UI、存储、集群管理多种机制可选 支持告警 优秀的可视化方案 SkyWalking 服务端配置 基于 Docker 安装 ElasticSearch 上面介绍过 SkyWalking 存储方案有多种，官方推荐的方案是 ElasticSearch ，所以我们需要先安装 ElasticSearch。 在虚拟机centOS上进行安装。 这里使用拉取镜像并创建容器的方式进行安装： 拉取es镜像，默认拉取最新版： 1docker pull elasticsearch:7.6.1 创建并运行容器： 1docker run -di --name&#x3D;es7 -p 9200:9200 -p 9300:9300 -e &quot;discovery.type&#x3D;single-node&quot; elasticsearch:7.6.1 进入容器： 1docker exec -it es7 &#x2F;bin&#x2F;bash 修改配置： 12cd configvi elasticsearch.yml 添加修改内容如下： 12network.host: 127.0.0.1 #推荐本机IPhttp.port: 9200 打开浏览器访问： 1虚拟机ip:9200 下载并启动 SkyWalking 官方已经为我们准备好了编译过的服务端版本，下载地址为 http://skywalking.apache.org/downloads/，这里我们需要下载6.x releases 版本 配置 SkyWalking 下载完成后解压缩，进入 apache-skywalking-apm-incubating/config 目录并修改 application.yml 配置文件： 这里需要做三件事： 注释 H2 存储方案 启用 ElasticSearch 存储方案 修改 ElasticSearch 服务器地址 启动 SkyWalking 修改完配置后，进入 apache-skywalking-apm-incubating\\bin 目录，运行 startup.bat 启动服务端 通过浏览器访问 http://localhost:8080 出现如下界面即表示启动成功： SkyWalking 客户端配置 Java Agent 服务器探针 参考官网给出的帮助 Setup java agent，我们需要使用官方提供的探针为我们达到监控的目的，按照实际情况我们需要实现三种部署方式 IDEA 部署探针 Java 启动方式部署探针（我们是 Spring Boot 应用程序，需要使用 java -jar 的方式启动应用） Docker 启动方式部署探针（需要做到一次构建到处运行的持续集成效果，本章节暂不提供解决方案，到后面的实战环节再实现） 探针文件在 apache-skywalking-apm-incubating/agent 目录下： IDEA 部署探针 继续之前的案例项目Spring Cloud Alibaba 微服务框架入门，创建一个名为 hello-spring-cloud-external-skywalking 的目录，并将 agent 整个目录拷贝进来： 修改项目的 VM 运行参数，点击菜单栏中的 Run -&gt; EditConfigurations...，此处我们以 nacos-provider 项目为例，修改参数如下： 123-javaagent:D:\\Workspace\\Others\\hello-spring-cloud-alibaba\\hello-spring-cloud-external-skywalking\\agent\\skywalking-agent.jar-Dskywalking.agent.service_name&#x3D;nacos-provider-Dskywalking.collector.backend_service&#x3D;localhost:11800 -javaagent：用于指定探针路径 -Dskywalking.agent.service_name：用于重写 agent/config/agent.config 配置文件中的服务名 -Dskywalking.collector.backend_service：用于重写 agent/config/agent.config 配置文件中的服务地址 有多少个服务需要跟踪，就配置多少个 Java 启动方式 1java -javaagent:&#x2F;path&#x2F;to&#x2F;skywalking-agent&#x2F;skywalking-agent.jar -Dskywalking.agent.service_name&#x3D;nacos-provider -Dskywalking.collector.backend_service&#x3D;localhost:11800 -jar yourApp.jar 测试监控 启动 nacos-provider 、nacos-consumer-feign、gateway 项目，通过观察日志可以发现，已经成功加载探针。访问之前写好的接口： http://localhost:9000/nacos-consumer-feign/echo/hi?token=123 ，然后回来刷新 SkyWalking Web UI ，你会发现启动的三个服务已经配检测到，至此，表示 SkyWalking 链路追踪配置成功。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Alibaba 服务配置","slug":"Spring-Cloud-Alibaba2","date":"2020-03-13T11:49:38.000Z","updated":"2020-03-13T13:08:28.742Z","comments":true,"path":"2020/03/13/Spring-Cloud-Alibaba2/","link":"","permalink":"http://ctrl98.github.io/2020/03/13/Spring-Cloud-Alibaba2/","excerpt":"","text":"Nacos Config 服务端初始化 分布式配置中心 在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。之前我们写配置文件，改完就要重启服务，要是有100个服务呢？ Nacos Config Nacos 提供用于存储配置和其他元数据的 key/value 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。使用 Spring Cloud Alibaba Nacos Config，您可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置。 Spring Cloud Alibaba Nacos Config 是 Spring Cloud Config Server 和 Client 的替代方案，客户端和服务器上的概念与 Spring Environment 和 PropertySource 有着一致的抽象，在特殊的 bootstrap 阶段，配置被加载到 Spring 环境中。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容。 配置文件优先级： bootstrap.properties—&gt;bootstrap.yml—&gt;application.properties—&gt;application.yml 创建配置文件 需要在 Nacos Server 中创建配置文件，我们依然采用 YAML 的方式部署配置文件，操作流程如下： 浏览器打开 http://localhost:8848/nacos ，访问 Nacos Server 新建配置文件，此处我们以之前创建的 服务提供者Spring Cloud Alibaba 微服务框架入门 项目为例： 注意：Data ID 的默认扩展名为 .properties ，希望使用 YAML 配置，此处必须指明是 .yaml 发布成功后在 “配置列表” 一栏即可看到刚才创建的配置项 Nacos Config 客户端的使用 POM 此处我们以之前创建的服务提供者Spring Cloud Alibaba 微服务框架入门项目为例： 在 pom.xml 中增加 org.springframework.cloud:spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 完整的文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-nacos-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-nacos-provider&lt;/name&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; bootstrap.properties 创建名为 bootstrap.properties 的配置文件并删除之前创建的 application.yml 配置文件，由于已经在服务端配置，此处不再赘述： 123456# 这里的应用名对应 Nacos Config 中的 Data ID，实际应用名称以配置中心的配置为准spring.application.name=nacos-provider-config# 指定查找名为 nacos-provider-config.yaml 的配置文件spring.cloud.nacos.config.file-extension=yaml# Nacos Server 的地址spring.cloud.nacos.config.server-addr=127.0.0.1:8848 注意：在之前的 Spring Cloud Netflix 课程中有提到过 Spring Boot 配置文件的加载顺序，依次为 bootstrap.properties -&gt; bootstrap.yml -&gt; application.properties -&gt; application.yml ，其中 bootstrap.properties 配置为最高优先级 启动应用程序 启动应用后我们可以通过日志看到，已经成功加载到了配置文件： 配置的动态更新 Nacos Config 也支持配置的动态更新，操作流程如下： 修改服务端配置，增加一个 user.name 的属性 修改 Controller ，增加一个请求方法，测试配置更新效果 123456789101112131415161718192021222324252627282930package org.lee.spring.cloud.alibaba.nacos.provider.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosProviderController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(value = \"/echo/&#123;message&#125;\") public String echo(@PathVariable String message) &#123; return \"Hello Nacos Discovery \" + message + \" i am from port \" + port; &#125; // 注入配置文件上下文 @Autowired private ConfigurableApplicationContext applicationContext; // 从上下文中读取配置 @GetMapping(value = \"/hi\") public String sayHi() &#123; return \"Hello \" + applicationContext.getEnvironment().getProperty(\"user.name\"); &#125;&#125; 通过浏览器访问该接口:localhost:8081/hi，浏览器显示： 1Hello kobe 修改服务端配置： 刷新浏览器，浏览器显示 1Hello kobeAndGiGi 注意：你可以使用 spring.cloud.nacos.config.refresh.enabled=false 来关闭动态刷新 Nacos Config 多环境的配置 Spring Boot Profile 我们在做项目开发的时候，生产环境和测试环境的一些配置可能会不一样，有时候一些功能也可能会不一样，所以我们可能会在上线的时候手工修改这些配置信息。但是 Spring 中为我们提供了 Profile 这个功能。我们只需要在启动的时候添加一个虚拟机参数，激活自己环境所要用的 Profile 就可以了。 操作起来很简单，只需要为不同的环境编写专门的配置文件，如：application-dev.yml、application-prod.yml， 启动项目时只需要增加一个命令参数 --spring.profiles.active=环境配置 即可，启动命令如下： 1java -jar spring-cloud-alibaba-nacos-provider-1.0-SNAPSHOT.jar --spring.profiles.active&#x3D;prod Nacos Config Profile spring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataid 为 ${spring.application.name}.${file-extension:properties} 为前缀的基础配置，还加载了 dataid 为 ${spring.application.name}-${profile}.${file-extension:properties} 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过 Spring 提供的 ${spring.profiles.active} 这个配置项来配置。 此处我们以之前创建的服务提供者项目为例： 在 Nacos Server 中增加配置 增加一个名为 nacos-provider-config-prod.yaml 的配置： 注意：此时，我将配置文件中的端口由 8081 -&gt; 8082 在项目中增加配置 增加一个名为 bootstrap-prod.properties 的配置文件，内容如下： 1234spring.profiles.active=prodspring.application.name=nacos-provider-configspring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848 主要增加了 spring.profiles.active=prod 配置，用于指定访问 Nacos Server 中的 nacos-provider-config-prod.yaml 配置 启动应用程序 此时我们有两个配置文件，分别为 bootstrap.properties 和 bootstrap-prod.properties ，我们需要指定启动时加载哪一个配置文件，操作流程如下： 设置需要激活的配置 观察日志，判断是否成功加载配置","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Alibaba 微服务框架入门","slug":"Spring-Cloud-Alibaba1","date":"2020-03-11T07:49:49.000Z","updated":"2020-03-13T11:50:59.041Z","comments":true,"path":"2020/03/11/Spring-Cloud-Alibaba1/","link":"","permalink":"http://ctrl98.github.io/2020/03/11/Spring-Cloud-Alibaba1/","excerpt":"","text":"简介 2018 年 10 月 31 日 ，Spring Cloud Alibaba 正式入驻了 Spring Cloud 官方孵化器，并在 Maven 中央库发布了第一个版本。 Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。 主要功能 服务限流降级：默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 组件 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 服务注册与发现 概述 在 Spring Cloud Netflix 阶段我们采用 Eureka 做作为我们的服务注册与发现服务器，现利用 Spring Cloud Alibaba 提供的 Nacos 组件替代该方案。 什么是 Nacos Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 Nacos基本架构图 下载安装 准备环境 Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行 Nacos，还需要为此配置 Maven 环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+ Maven 3.2.x+ 下载 到Nacos的github项目地址： https://github.com/alibaba/nacos 找到快速开始： 点击 latest stable release 调转到压缩包下载。 选择最新的版本，以linux为内核的系统下载以 tar.gz结尾的，windows就下载 zip 的。 这里以 windows 为例，下载后解压，然后进入 /bin 目录双击 startup.cmd。 看到这个标志说明启动成功！紧接着访问： http://localhost:8848/nacos 创建服务提供者 首先创建Spring Boot父工程 在本地磁盘任意地方创建一个名为 spring_cloud_alibaba 文件夹用来存放项目 用idea软件打开该文件夹，右击项目文件夹，new一个module子项目，名为 spring-cloud-alibaba-dependencies pom.xml文件添加相关依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189&lt;groupId&gt;org.example&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;11&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; parent：继承了 Spring Boot 的 Parent，表示我们是一个 Spring Boot 工程 package：pom，表示该项目仅当做依赖项目，没有具体的实现代码 spring-cloud-alibaba-dependencies：在 properties 配置中预定义了版本号为 0.2.1.RELEASE ，表示我们的 Spring Cloud Alibaba 对应的是 Spring Cloud Finchley 版本 build：配置了项目所需的各种插件 repositories：配置项目下载依赖时的第三方库 这里需要注意的是 Spring Boot和Spring Cloud Alibaba的版本要对应 Spring Boot Spring Cloud Spring Cloud Alibaba 2.1.x Greenwich 0.9.x 2.0.x Finchley 0.2.x 1.5.x Edgware 0.1.x 1.5.x Dalston 0.1.x 接下来创建服务提供者 通过一个简单的示例来感受一下如何将服务注册到 Nacos，其实和 Eureka 没有太大差别。 右击项目，new一个名为 spring-cloud-alibaba-nacos-provider module项目，pom.xml文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-alibaba-nacos-provider&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-alibaba-nacos-provider&lt;/name&gt;&lt;inceptionYear&gt;2018-Now&lt;/inceptionYear&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在该子项目的resourses目录下创建配置文件application.yml： 12345678910111213141516spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 8081management: endpoints: web: exposure: include: \"*\" 在src目录的java下，创建 org.lee.spring.cloud.alibaba.nacos.provider包，再创建启动类： 12345678910111213package org.lee.spring.cloud.alibaba.nacos.provider;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClient//服务注册注解public class NacosProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProviderApplication.class,args); &#125;&#125; 创建controller包，添加controller方法： 1234567891011121314package org.lee.spring.cloud.alibaba.nacos.provider.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosProviderController &#123; @GetMapping(value = \"/echo/&#123;message&#125;\") public String echo(@PathVariable String message) &#123; return \"Hello Nacos Discovery \" + message; &#125;&#125; 启动该子工程，通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现一个服务已经注册在服务中了，服务名为 nacos-provider 这时打开 http://localhost:8081/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery hi 服务的端点检查 spring-cloud-starter-alibaba-nacos-discovery 在实现的时候提供了一个 EndPoint, EndPoint 的访问地址为 http://ip:port/actuator/nacos-discovery。 EndPoint 的信息主要提供了两类: 121、subscribe: 显示了当前有哪些服务订阅者2、NacosDiscoveryProperties: 显示了当前服务实例关于 Nacos 的基础配置 通过浏览器访问 http://localhost:8081/actuator/nacos-discovery 你会在浏览器上看到： 创建服务消费者 服务消费者的创建与服务提供者大同小异，这里采用最原始的一种方式，即显示的使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问。 创建一个工程名为 spring-cloud-alibaba-nacos-consumer 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-alibaba-nacos-provider&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-alibaba-nacos-provider&lt;/name&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.lee.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 创建配置文件application.yml 12345678910111213141516spring: application: name: nacos-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9091management: endpoints: web: exposure: include: \"*\" 创建启动类 12345678910111213package org.lee.spring.cloud.alibaba.nacos.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class NacosConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerApplication.class,args); &#125;&#125; 创建一个名为 NacosConsumerConfiguration 的 Java 配置类，主要作用是为了注入 RestTemplate 12345678910111213package org.lee.spring.cloud.alibaba.nacos.consumer.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class NacosConsumerConfiguration &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 创建一个名为 NacosConsumerController 测试用的 Controller 123456789101112131415161718192021222324252627282930package org.lee.spring.cloud.alibaba.nacos.consumer.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class NacosConsumerController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private RestTemplate restTemplate; @Value(\"$&#123;spring.application.name&#125;\") private String appName; @GetMapping(value = \"/echo/app/name\") public String echo() &#123; //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 ServiceInstance serviceInstance = loadBalancerClient.choose(\"nacos-provider\"); String url = String.format(\"http://%s:%s/echo/%s\", serviceInstance.getHost(), serviceInstance.getPort(), appName); return restTemplate.getForObject(url, String.class); &#125;&#125; 启动工程 通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer 的服务 这时打开 http://localhost:9091/echo/app/name ，你会在浏览器上看到： 1Hello Nacos Discovery nacos-consumer 服务的端点检查 通过浏览器访问 http://localhost:9091/actuator/nacos-discovery 你会在浏览器上看到同样的json 创建服务消费者（Feign） 概述 Feign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，Nacos 也很好的兼容了 Feign，默认实现了负载均衡的效果 Feign 采用的是基于接口的注解 Feign 整合了 ribbon 创建一个工程名为 spring-cloud-alibaba-nacos-consumer-feign 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-alibaba-nacos-consumer-feign&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-alibaba-nacos-consumer-feign&lt;/name&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.hello.spring.cloud.alibaba.nacos.consumer.feign.NacosConsumerFeignApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-openfeign 依赖 创建项目配置文件application.yml 12345678910111213141516spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9092management: endpoints: web: exposure: include: \"*\" 创建启动类 123456789101112131415package org.lee.spring.cloud.alibaba.nacos.consumer.feign;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class NacosConsumerFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerFeignApplication.class,args); &#125;&#125; 通过 @EnableFeignClients 注解开启 Feign 功能 创建 Feign 接口 1234567891011package org.lee.spring.cloud.alibaba.nacos.consumer.feign.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"nacos-provider\")public interface EchoService &#123; @GetMapping(value = \"/echo/&#123;message&#125;\") String echo(@PathVariable(\"message\") String message);&#125; 通过 @FeignClient(&quot;服务名&quot;) 注解来指定调用哪个服务。 创建controller 123456789101112131415161718package org.lee.spring.cloud.alibaba.nacos.consumer.feign.controller;import org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosConsumerFeignController &#123; @Autowired private EchoService echoService; @GetMapping(value = \"/echo/hi\") public String echo() &#123; return echoService.echo(\"Hi Feign\"); &#125;&#125; 启动工程 通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer-feign 的服务； 这时打开 http://localhost:9092/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery Hi Feign 测试负载均衡 启动多个 consumer-provider 实例，修改provider子项目的配置文件的端口为8082； 找到idea编辑器顶部菜单，找到run-----&gt;Edit Configurations…-----&gt;选择provider启动了，勾选右边的Allow parallel run 再次运行NacosProviderApplication启动类，就会创建一个新的实例。 效果图： 修改 consumer-provider 项目中的 Controller 代码，用于确定负载均衡生效 123456789101112131415161718package org.lee.spring.cloud.alibaba.nacos.provider.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class NacosProviderController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(value = \"/echo/&#123;message&#125;\") public String echo(@PathVariable String message) &#123; return \"Hello Nacos Discovery \" + message + \"i am from port \" + port; &#125;&#125; 重启8081和8082两个端口的实例 在浏览器上多次访问 http://localhost:9092/echo/hi ，浏览器交替显示端口变化。 使用熔断器防止服务雪崩 概述 在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 相互调用，在 Spring Cloud 中可以用 RestTemplate + LoadBalanceClient 和 Feign 来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证 100% 可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet 容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的 “雪崩” 效应。 为了解决这个问题，业界提出了熔断器模型。 阿里巴巴开源了 Sentinel 组件，实现了熔断器模式，Spring Cloud 对这一组件进行了整合。在微服务架构中，一个请求需要调用多个服务是非常常见的，如下图： 较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值熔断器将会被打开。 熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值。 什么是 Sentinel 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 的特征 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的 双十一大促流量 的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等。 Feign 中使用 Sentinel 如果要在您的项目中引入 Sentinel，使用 group ID 为 org.springframework.cloud 和 artifact ID 为 spring-cloud-starter-alibaba-sentinel 的 starter。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; Sentinel 适配了 Feign 组件。但默认是关闭的。需要在配置文件中配置打开它，在配置文件增加以下代码： 123feign: sentinel: enabled: true 在 Service 中增加 fallback 指定类 123456789101112package org.lee.spring.cloud.alibaba.nacos.consumer.feign.service;import org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.fallback.EchoServiceFallback;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"nacos-provider\", fallback = EchoServiceFallback.class)public interface EchoService &#123; @GetMapping(value = \"/echo/&#123;message&#125;\") String echo(@PathVariable(\"message\") String message);&#125; 创建熔断器类并实现对应的 Feign 接口 123456789101112package org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.fallback;import org.lee.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.stereotype.Component;@Componentpublic class EchoServiceFallback implements EchoService &#123; @Override public String echo(String message) &#123; return \"echo fallback\"; &#125;&#125; 测试熔断器 此时我们关闭服务提供者，再次请求 http://localhost:9092/echo/hi 浏览器会显示： 1echo fallback 使用熔断器仪表盘监控 Sentinel 控制台 Sentinel 控制台提供一个轻量级的控制台，它提供机器发现、单机资源实时监控、集群资源汇总，以及规则管理的功能。您只需要对应用进行简单的配置，就可以使用这些功能。 注意: 集群资源汇总仅支持 500 台以下的应用集群，有大概 1 - 2 秒的延时。 详细内容请到Sentinel的项目仓库查看文档： https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D 下载并打包 12345# 下载源码git clone https://github.com/alibaba/Sentinel.git# 编译打包mvn clean package 注：下载依赖时间较长，请耐心等待… 或者直接下载jar包 https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0 访问以上链接，或者直接去下载jar包： https://github.com/alibaba/Sentinel/releases 下载完成后运行： 1java -Dserver.port&#x3D;8080 -Dcsp.sentinel.dashboard.server&#x3D;localhost:8080 -Dproject.name&#x3D;sentinel-dashboard -jar sentinel-dashboard-1.7.1.jar 这里注意jar包的名称，我下载的是1.7.1版本。 启动控制台 跑起来后访问：localhost:8080，用户名密码默认：sentinel 如若 8080 端口冲突，可使用 -Dserver.port=新端口 进行设置。 配置feign消费者控制台信息 application.yml 配置文件中spring.cloud下增加如下配置： 1234sentinel: transport: port: 8719 dashboard: localhost:8080 这里的 spring.cloud.sentinel.transport.port 端口配置会在应用对应的机器上启动一个 Http Server，该 Server 会与 Sentinel 控制台做交互。比如 Sentinel 控制台添加了 1 个限流规则，会把规则数据 push 给这个 Http Server 接收，Http Server 再将规则注册到 Sentinel 中。 8719说白了就像是服务注册在nacos中一样，给应用一个端口注册到sentinel中让它监控该应用。 测试 Sentinel 使用之前的 Feign 客户端，application.yml 完整配置如下： 12345678910111213141516171819202122232425spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848 sentinel: transport: port: 8719 dashboard: localhost:8080server: port: 9092management: endpoints: web: exposure: include: \"*\"feign: sentinel: enabled: true 重启feign服务，访问sentinel控制台，发现还是原来的数据。 这里我们再次模拟熔断，访问： http://localhost:9092/echo/hi ，触发熔断。 然后再回到sentinel控制台刷新，就有监控到的数据了： 使用路由网关统一访问接口 什么是 Spring Cloud Gateway Spring Cloud Gateway 是 Spring 官方基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，Spring Cloud Gateway 旨在为微服务架构提供一种简单而有效的统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系中的网关，目标是替代 Netflix ZUUL，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 Spring Cloud Gateway 功能特征 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 Spring Cloud Gateway 工程流程 客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（pre）或之后（post）执行业务逻辑。 其实就相当于spring MVC的servletDispachter的工作流程 使用 创建新module，名为spring-cloud-gateway，pom.xml文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;parent&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- &lt;relativePath&gt;../spring-cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt;--&gt; &lt;relativePath /&gt;&lt;/parent&gt;&lt;artifactId&gt;spring-cloud-gateway&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;spring-cloud-gateway&lt;/name&gt;&lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.hello.spring.cloud.gateway.GatewayApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-gateway 依赖 特别注意 Spring Cloud Gateway 不使用 Web 作为服务器，而是 使用 WebFlux 作为服务器，Gateway 项目已经依赖了 starter-webflux，所以这里 千万不要依赖 starter-web 由于过滤器等功能依然需要 Servlet 支持，故这里还需要依赖 javax.servlet:javax.servlet-api 创建配置文件application.yml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spring: application: # 应用名称 name: spring-gateway cloud: # 使用 Naoos 作为服务注册发现 nacos: discovery: server-addr: 127.0.0.1:8848 # 使用 Sentinel 作为熔断器 sentinel: transport: port: 8721 dashboard: localhost:8080 # 路由网关配置 gateway: # 设置与服务注册发现组件结合，这样可以采用服务名的路由策略 discovery: locator: enabled: true # 配置路由规则 routes: # 采用自定义路由 ID（有固定用法，不同的 id 有不同的功能，详见：https://cloud.spring.io/spring-cloud-gateway/2.0.x/single/spring-cloud-gateway.html#gateway-route-filters） - id: NACOS-CONSUMER # 采用 LoadBalanceClient 方式请求，以 lb:// 开头，后面的是注册在 Nacos 上的服务名 uri: lb://nacos-consumer # Predicate 翻译过来是“谓词”的意思，必须，主要作用是匹配用户的请求，有很多种用法 predicates: # Method 方法谓词，这里是匹配 GET 和 POST 请求 - Method=GET,POST - id: NACOS-CONSUMER-FEIGN uri: lb://nacos-consumer-feign predicates: - Method=GET,POSTserver: port: 9000# 目前无效feign: sentinel: enabled: true# 目前无效management: endpoints: web: exposure: include: \"*\"# 配置日志级别，方别调试logging: level: org.springframework.cloud.gateway: debug 创建启动类： 123456789101112131415package org.lee.spring.cloud.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class,args); &#125;&#125; 测试访问 依次运行 Nacos 服务、NacosProviderApplication、NacosConsumerApplication、NacosConsumerFeignApplication、GatewayApplication 打开浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 浏览器显示 1Hello Nacos Discovery nacos-consumer i am from port 8082 打开浏览器访问：http://localhost:9000/nacos-consumer-feign/echo/hi 浏览器显示 1Hello Nacos Discovery Hi Feign i am from port 8082 注意：请求方式是 http://路由网关IP:路由网关Port/服务名/\\** 至此说明 Spring Cloud Gateway 的路由功能配置成功","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Security OAuth2.0 认证授权","slug":"Spring-Security-Oauth2","date":"2020-03-10T08:09:22.000Z","updated":"2020-03-10T09:00:06.959Z","comments":true,"path":"2020/03/10/Spring-Security-Oauth2/","link":"","permalink":"http://ctrl98.github.io/2020/03/10/Spring-Security-Oauth2/","excerpt":"","text":"基本概念 什么是认证？ 互联网时代，手机微信、支付宝等软件，使用前都需要进行登录，输入用户名密码进行登录某个软件得过程就叫认证。 为什么要认证？ 认证是为了保护系统得隐私数据与资源，用户身份合法才可以访问系统资源。 认证：用户认证就是判断一个用户得身份是否合法的过程，合法才能继续访问，常见的用户身份认证方式有用户名密码登录、二维码登录、手机短信验证和指纹等。 什么是会话？ 比如微信用户认证后、打开一个网页，不可能每打开一次就要用户重新登录一次，会话就是避免用户每次操作都进行认证，将用户的信息保存在会话中，会话就是系统为了保持当前用户的登录状态提供的机制，常见的有基于Session、基于Token方式等。 什么是授权？ 授权就是通过认证的用户是否有权限去使用该系统的某个功能，比如刚注册的微信用户，由于一开始没有绑定银行卡，所以是没办法使用发红包收红包的功能。 RBAC 业界通常基于RBAC实现授权 基于角色的访问控制 ​ RBAC基于角色的访问控制（Role-Based Access Control）是按角色进行授权，比如主体的角色为总经理，可以查询系统的报表、工资信息等。 代码逻辑可简单表示为： 123if (主体.hasRole(\"总经理角色id\"))&#123; 查询工资();&#125; 基于资源的访问控制 ​ RBAC基于资源的访问控制（Resourse-Based Access Control）是按资源进行授权，比如必须具有查询工资权限才能使用该功能。 代码逻辑可简单表示为： 123if (主体.hasPermission(&quot;查询工资权限标识&quot;))&#123; 查询工资();&#125;","categories":[{"name":"权限框架","slug":"权限框架","permalink":"http://ctrl98.github.io/categories/%E6%9D%83%E9%99%90%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"http://ctrl98.github.io/tags/OAuth2-0/"}]},{"title":"浅谈Spring的IOC/AOP","slug":"Spring1","date":"2020-03-09T02:14:25.000Z","updated":"2020-04-05T01:27:02.455Z","comments":true,"path":"2020/03/09/Spring1/","link":"","permalink":"http://ctrl98.github.io/2020/03/09/Spring1/","excerpt":"","text":"什么是耦合（高/低？） 耦合，就是模块间关联的程度，每个模块之间的联系越多，也就是其耦合性越强，那么独立性也就越差了，所以我们在软件设计中，应该尽量做到低耦合，高内聚。 生活中的例子： 家里有一条串灯，上面有很多灯泡，如果灯坏了，你需要将整个灯带都换掉，这就是高耦合的表现，因为灯和灯带之间是紧密相连，不可分割的，但是如果灯泡可以随意拆卸，并不影响整个灯带，那么这就叫做低耦合。 代码例子： 12Father f &#x3D; new Son();f.method(); Son类继承自Father类，通过 new来创建依赖的对象调用方法 此时如果你想把Son换成Girl类，那么所有 new Son()的地方都要修改，这只是简单的举例，在实际开发中有上百个类，你不可能这样去操作。 这时候我们把对象的创建交给Spring，那么效率就大大地提升了。 12Father f &#x3D; BeanFactory().getBean(B名称);f.method(); 只需要修改getBean里的参数即可。 Spring 框架好在哪里？ 降低耦合度：Spring神奇的 IoC 容器，可以控制对象间的依赖关系，解决了硬编码问题 AOP 编程支持：Spring 提供了面向切面编程 方便集成各种优秀框架：Spring 不排斥各种优秀的开源框架 方便程序测试：Spring 支持 junit4 声明式事务的支持：Spring 帮助我们从普通的事物管理代码中解放出来，通过配置就可以完成对事务的管理 降低 JavaEE API 的使用难度：Spring 将 JavaEE 中一些比较难用的 API (JDBC、JavaMail、远程调用等) 进行了封装，使得它们的使用难度大大降低 Spring 框架的结构 Spring框架是一个分层的架构，根据不同的功能，分成了多个模块，而这些模块都是可以单独或者组合使用。 CoreContainer是Spring框架的最核心部分，其他模块都是基于该模块建立的。 核心容器 CoreContainer 提供 Spring框架的基本功能，分为图中四个模块，核心容器中重要的组件就是 BeanFactory ，本质就是实现了工厂模式，且它使用了 IoC（控制反转）模式，将程序的配置以及依赖性规范与实际程序的代码分开。 Beans：提供了 BeanFactory，Spring中将管理对象称作 Bean Core：提供 Spring 框架的基本组成部分，包括我们首先要学习的 IoC 和 DI Context：访问定义和配置任何对象的媒介，以前两者为基础，ApplicationContext 接口是这部分的重点 spEL (Spring Expression Language)：一个比较强大的运行时查询和操作数据的表达式语言 数据访问/集成（Data Access/Integration） JDBC：提供了一个JDBC抽象层，减少了一些重复无聊的JDBC代码，提升了开发效率 ORM：提供了对流行对象关系映射API的集成层 （JPA、JDO、Hibernate、 mybatis ） OXM：提供了一个支持对象/XML映射实现的抽象层（ JAXB、Castor、XMLBeans、JiBX 、XStrea ） JMS：Java消息服务， 包含用于生产和消费消息的功能 Transactions：事务模块，用于支持实现特殊接口和所有的POJO的类的编程和声明式事物管理 Web 模块 Web：提供了基本的 Web 的集成功能，例如多部分文件上传功能，以及初始化了一个使用了Servlet监听器和面向Web应用程序上下文的 IoC 容器，它还包含一个HTTP客户端和Spring远程支持的相关部分 Servelt：包含 Spring 模型—视图—控制器 (MVC) ，用来实现Web应用 WebSocket：Spring4.0以后新增的模块，它提供了WebSocket和SocketJS的实现 Portlet：就好像是Servlet一般，它提供了Portlet环境下的MVC实现 其余模块 AOP：提供了面向切面编程的能力，允许定义方法拦截器和切入点，按功能分离代码，降低耦合性，可以实现一些面向对象编程中不太好实现的功能 Aspects：提供与 AspectJ 的继承，是一个功能强大且成熟的面向切面编程的框架 Instrumentation：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用 Messaging： 它提供了对消息传递体系结构和协议的支持 Test：其支持使用 JUnit 或者 TestNG，可以实现单元测试，集合测试等测试流程 Spring IOC原理 Inversion of Control，控制反转。是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。 通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。 IoC 内部核心原理就是反射技术，涉及到 Bean 对象的初始化构建等步骤。 Java 反射 Java反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 在日常的第三方应用开发过程中，经常会遇到某个类的某个成员变量、方法或是属性是私有的或是只对系统应用开放，这时候就可以利用Java的反射机制通过反射来获取所需的私有成员或是方法。 反射机制相关类： 类名 用途 Class类 代表类的实体，在运行的Java应用程序中表示类和接口 Field类 代表类的成员变量（成员变量也称为类的属性） Method类 代表类的方法 Constructor类 代表类的构造方法 对于每个类都有自己得子方法，这里不作过多解释，推荐一篇反射文章—详细请看 Java高级特性——反射 Spring 入门程序 使用Eclipse创建一个名为Demo的项目，添加Spring相关的依赖包，commons-logging-1.2.jar、spring-beans-4.3.6.RELEASE.jar、spring-context-4.3.6.RELEASE.jar、spring-core-4.3.6.RELEASE.jar、spring-expression-4.3.6.RELEASE.jar。 在项目的src目录下，创建一个org.ioc包，并在包下创建接口UserDao，然后接口中定义一个say()方法： 123public interface UserDao()&#123; public void say();&#125; 接着在ioc报下创建该接口的实现类UserDaoImpl，实现接口中的方法，并输出一条语句： 12345public class UserDaoImpl implements UserDao&#123; public void say()&#123; System.out.println(\"userDao say Hello World\"); &#125;&#125; 在src下创建spring的配置文件applicationContext.xml，并配置一个id为userDao的Bean： 1&lt;bean id=\"userDao\" class=\"org.ioc.UserDaoImpl\"/&gt; 该段代码表示在spring容器中创建一个id为userDao的bean实例，其中class属性用于指定需要实例化的Bean类。 在ioc包下，创建测试类TestIoc，编写main方法，在mian方法里面初始化spring容器，加载配置文件，获取userDao对象实例，最后调用say()方法输出： 12345678public class TestIoc &#123; public static void main(String[] args)&#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); UserDao userDao = (UserDao)applicationContext.getBean(\"userDao\"); userDao.say(); &#125;&#125; 最后控制台输出： 1userDao say Hello World 从测试方法可以看出，并没有通过new关键字来创建UserDao接口的实现类对象，而是通过Spring容器来获取实现类对象，这就是Spring IOC 容器的工作机制。 依赖注入DI 控制反转（IoC）是一种思想，而依赖注入（Dependency Injection）则是实现这种思想的方法。 其实泛概念上两者是接近的，可以简单的理解为一个概念的不同角度描述。 DI的作用是在使用Spring框架创建对象时，动态地将其所依赖的对象注入Bean组件中。 上面写程序的时候，通过控制反转，使得 Spring 可以创建对象，这样减低了耦合性，但是每个类或模块之间的依赖是不可能完全消失的，而这种依赖关系，我们可以完全交给 spring 来维护。 DI实现方式 构造方法注入：基于构造方法的依赖注入通过调用带参数的构造方法来实现，每个参数代表一个依赖。 这一种的前提就是：类中必须提供一个和参数列表相对应的构造函数 12345678910111213141516171819public class DemoServiceImpl implements DemoService &#123; private String username; private Integer age; private Date birthday; //构造方法 public DemoServiceImpl(String username, Integer phone, Date birthday) &#123; this.username = username; this.age = phone; this.birthday = birthday; &#125; public void addDemo() &#123; System.out.println(\"username: \" + username + \", phone: \" + age + \", birthday: \" + birthday); &#125;&#125; 在ApplicationContext.xml文件中添加如下： 123456&lt;bean id=\"demoService\" class=\"org.service.impl.DemoServiceImpl\"&gt; &lt;constructor-arg name=\"username\" value=\"詹姆斯\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"phone\" value=\"35\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"birthday\" ref=\"bir\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id=\"bir\" class=\"java.util.Date\"&gt;&lt;/bean&gt; 属性解析： constructor-arg 给谁赋值： index：指定参数在构造函数参数列表的索引位置 type：指定参数在构造函数中的数据类型 name：指定参数在构造函数中的名称（更常用） 赋什么值： value：这里可以写基本数据类型和 String ref：这里可以引入另一个bean，帮助我们给其他类型赋值（例如文中 birthday ） 测试后发现可以打印出我们在配置文件配置的value值。 上面就是使用类的构造函数给成员变量进行赋值，但特别的是，这里是通过配置，使用 Spring 框架进行注入。 setter方法注入：通过调用无参构造器或无参静态工厂方法实例化bean后调用该bean的setter。 修改以上配置文件 123456&lt;bean id=\"demoService\"class=\"cn.service.impl.DemoServiceImpl\"&gt; &lt;property name=\"username\" value=\"詹姆斯\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"35\"&gt;&lt;/property&gt; &lt;property name=\"birthday\" ref=\"bir\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"bir\" class=\"java.util.Date\"&gt;&lt;/bean&gt; property name：与成员变量名无关，与set方法后的名称有关，例如 setUsername() 获取到的就是username，并且已经小写了开头 value：这里可以写基本数据类型和 String ref：这里可以引入另一个bean，帮助我们给其他类型赋值（例如文中 birthday ） 实现的效果和上面的一样 Spring AOP原理 Aspect Oriented Programming，面向切面编程。通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP 是 OOP 的延续，是软件开发中的一个热点，也是 Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。其中，最常用的使用场景一般有日志模块、权限模块、事物模块。 AOP 的内部原理其实就是动态代理和反射了。主要涉及到的反射类： 类 说明 InvocationHandler 通过这个接口定义横切的逻辑，然后通过反射机制调用目标类的方法，这样就能动态地把非业务逻辑和业务逻辑动态得拼接在一起 proxy 提供创建动态代理类得静态方法，通常利用INvocationHandler创建代理实例，来间接得调用代理的方法 Spring 中实现动态代理有两种方式可选。 JDK 动态代理 必须实现 InvocationHandler 接口，然后通过 Proxy.newProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h) 获得动态代理对象。 CGLIB 动态代理 使用 CGLIB 动态代理，被代理类**不需要强制实现接口。**CGLIB 不能对声明为 final的方法进行代理，因为 CGLIB 原理是动态生成被代理类的子类。 Spring AOP 三种织入方式 编译时织入，需要特殊的Java编译器，如AspectJ； 类加载时织入，需要特殊的Java编译器，如AspectJ； 运行时织入，Spring采用的方式，通过动态代理，实现简单； Spring AOP主要名词概念 Aspect：通用功能的代码实现； Target：被织入Aspect的对象； Join Point：切入点，所有方法都可以作为切入点； Pointcut：Aspect实际被应用在的Join Point ，支持正则； Advice：类里的方法以及这个方法如何织入到目标方法的方式； Weaving：Aop的实现过程； Advice的种类 前置通知（Before） 后置通知（AfterReturning） 异常通知（AfterThrowing） 最终通知（After） 环绕通知（Around）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://ctrl98.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://ctrl98.github.io/tags/Spring/"}]},{"title":"Spring Cloud Netflix核心组件介绍及搭建","slug":"SpringBoot-Netflix1","date":"2020-03-08T08:08:24.000Z","updated":"2020-03-26T08:02:12.619Z","comments":true,"path":"2020/03/08/SpringBoot-Netflix1/","link":"","permalink":"http://ctrl98.github.io/2020/03/08/SpringBoot-Netflix1/","excerpt":"","text":"单体应用存在的问题(耦合度过高) 随着业务的发展，开发变得越来越复杂。 修改，新增某个功能，需要对整个系统进行测试，重新部署。 一个模块出现了问题，很可能导致整个系统崩溃。 多个开发团队同时对数据进行管理，容易发生安全漏洞。 各个模块使用同一种技术开发，各个模块很难根据实际情况选择更合适的技术架构，局限性大。 模块内容过于复杂，如果员工离职，可能需要很长时间才能完成工作交接。 分布式、集群 集群：一台服务器无法负荷高并发的数据访问，那么就设置多几台服务器一起分担压力。(物理、运维层面) 分布式：将一个复杂的问题拆分成若干个小问题，将一个大型的项目架构拆分成若干个微服务来协同完成。(软件设计、开发层面)，分别有不同的人来完成每一个微服务，最终将所有服务进行整合。 Spring Cloud Netflix核心组件 服务治理 Eureka 负载均衡 Ribbon 负载均衡 Feign 服务网关 Zuul 服务跟踪 Zipkin 服务监控 Actuator 服务配置 Config 服务熔断 Hystrix Spring Cloud Eureka 简介： Eureka是 Netflix 开源的基于REST的服务治理解决方案，Spring Cloud 集成了Eureka，提供了服务注册和 服务发现的功能，可以和基于Spring Boot 搭建的微服务应用轻松整合，开箱即用，二次封装形成Spring Cloud Eureka Eureka server：注册中心 Eureka Client：服务提供者、服务消费者，所有要进⾏注册的微服务通过 Eureka Client 连接到 Eureka Server，完成注册。 如何去理解这三者之间的关系：比如说一个外卖订餐平台，商家需要在这个平台注册了才能提供服务，客户需要注册账号才能在商家提供的外卖服务进行下单销费。 分布式系统架构中，每个微服务在启动时，将自己的信息存储在注册中心，叫做服务注册。 服务消费者从注册中心获取服务提供者的网络信息，通过该信息调用服务，叫做服务发现。 Eureka Server代码实现 第一步创建一个maven父工程 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 解决 JDK 9 以上没有 JAXB API 的问题 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt; &lt;version&gt;2.3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步在父工程下创建maven子工程—eureka server pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第三步在module—eureka server创建配置文件 application.yml ，添加eureka server相关配置。 12345678server: port: 8071eureka: client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://localhost:8071/eureka/ 属性说明： server.port：当前eureka的服务端口 eureka.client.register-with-eureka：是否将当前的eureka server服务作为客户端进行注册 eureka.client.fetch-registry：是否获取其他eureka server服务的数据 eureka.client.service-url.defaultZone：注册中心访问地址 第四步在eureka server模块创建启动类 12345678910111213package eureka.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class,args); &#125;&#125; ​ 注解说明 @SpringBootApplication：声明Spring Boot入口程序 @EnableEurekaServer：声明该类是一个Eureka Server 微服务，提供服务注册和服务发现功能，即注册中心 到这里可以访问：http://localhost:8071/eureka 来查看注册中心的微服务信息 Eureka Client 代码实现 在父工程的基础上创建Module—eureka client 在pom.xml文件添加： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Module—eureka client创建配置⽂件 application.yml，添加 Eureka Client 相关配置 1234567891011server: port: 8010spring: application: name: serverProvidereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性说明： spring.application.name：当前服务注册在 Eureka Server 上的名称 eureka.instance.prefer-ip-address：是否将当前服务的 IP 注册到 Eureka Server 创建启动类---------ServerProviderApplication.java 123456@SpringBootApplicationpublic class ServerProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServerProviderApplication.class,args); &#125;&#125; 下面在Module—eureka client模块下实现简单业务测试 在Module—eureka client模块下创建实体类 12345678910111213141516package eurekaclient.lee.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private Integer id; private String name; private Integer age;&#125; 创建业务接口类 1234567891011package eurekaclient.lee.repository;import eurekaclient.lee.entity.Student;import java.util.Collection;public interface StudentRepository &#123; public Collection&lt;Student&gt; findAll(); public Student findById(Integer id); public void saveOrUpdate(Student student); public void deleteById(Integer id);&#125; 创建业务接口实现类 123456789101112131415161718192021222324252627282930313233343536373839404142package eurekaclient.lee.repository.Impl;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.stereotype.Repository;import java.util.Collection;import java.util.HashMap;import java.util.Map;@Repositorypublic class StudentRepositoryImpl implements StudentRepository &#123; private static Map&lt;Integer,Student&gt; studentMap; static &#123; studentMap = new HashMap&lt;&gt;(); studentMap.put(1,new Student(1,\"张三\",22)); studentMap.put(2,new Student(2,\"李四\",23)); studentMap.put(3,new Student(3,\"王五\",34)); &#125; @Override public Collection&lt;Student&gt; findAll() &#123; return studentMap.values(); &#125; @Override public Student findById(Integer id) &#123; return studentMap.get(id); &#125; @Override public void saveOrUpdate(Student student) &#123; studentMap.put(student.getId(),student); &#125; @Override public void deleteById(Integer id) &#123; studentMap.remove(id); &#125;&#125; 创建控制类 123456789101112131415161718192021222324252627282930313233343536373839404142package eurekaclient.lee.controller;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentController &#123; @Autowired private StudentRepository repository; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return repository.findAll(); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return repository.findById(id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @PutMapping(\"/update\") public void update(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; repository.deleteById(id); &#125;&#125; 到这里可以访问： http://localhost:8010/student/findAll 等接口访问数据进行测试，此时该服务已经注册在服务注册中心 RestTemplate的使用 什么是RestTemplate RestTemplate 是 Spring 框架提供的基于 REST 的服务组件，底层是对 HTTP 请求及响应进⾏了封装，提供了很多访问 RETS 服务的⽅法，可以简化代码开发。 如何使⽤ RestTemplate？ 在父工程创建maven工程(new Module)—resttemplate，在其pom.xml中不需要添加额外依赖，因为父工程中已有springboot的依赖，所以其子工程(Module)自然也是一个springboot工程。 创建实体类 12345678910111213141516package resttemplate.lee.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private Integer id; private String name; private Integer age;&#125; 创建controller 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package resttemplate.lee.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import resttemplate.lee.entity.Student;import java.util.Collection;@org.springframework.web.bind.annotation.RestController@RequestMapping(\"/rest\")public class RestController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); &#125; @GetMapping(\"/findAllSec\") public Collection&lt;Student&gt; findAllSec()&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id).getBody(); &#125; @GetMapping(\"/findByIdSec/&#123;id&#125;\") public Student findByIdSec(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); &#125; @PutMapping(\"update\") public void update(@RequestBody Student student)&#123; restTemplate.put(\"http://localhost:8010/student/update\",student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; restTemplate.delete(\"http://localhost:8010/student/deleteById/&#123;id&#125;\",id); &#125;&#125; 创建启动类---------RestTemplateApplication.java 123456789101112131415161718package resttemplate.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RestTemplateApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RestTemplateApplication.class,args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 这个只是简单测试RestTemplate的用法，并不涉及到微服务，为下面实现服务消费者Consumer预热，启动RestTemplateApplication的时候端口默认为8080，所以可以通过访问：http://localhost:8080/rest/findAll 等接口访问数据，此时的数据访问调用的是Eureka Client中的数据。 服务消费者Consumer 在父工程中创建module—consumer 在pom.xml添加 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在module中创建配置文件 application.yml 1234567891011server: port: 8020spring: application: name: consumereureka: client: service-url: defaultZone: http://loaclhost:8071/eureka/ instance: prefer-ip-address: true 创建启动类---------ConsumerApplication.java 123456789101112131415161718package consumer.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class,args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 创建实体类（同上） 创建controller 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package consumer.lee.controller;import consumer.lee.entity.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import java.util.Collection;@RestController@RequestMapping(\"/consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); &#125; @GetMapping(\"/findAllSec\") public Collection&lt;Student&gt; findAllSec()&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForEntity(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id).getBody(); &#125; @GetMapping(\"/findByIdSec/&#123;id&#125;\") public Student findByIdSec(@PathVariable(\"id\")Integer id)&#123; return restTemplate.getForObject(\"http://localhost:8010/student/findById/&#123;id&#125;\",Student.class,id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); &#125; @PutMapping(\"update\") public void update(@RequestBody Student student)&#123; restTemplate.put(\"http://localhost:8010/student/update\",student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; restTemplate.delete(\"http://localhost:8010/student/deleteById/&#123;id&#125;\",id); &#125;&#125; 到此服务消费者创建完成，其实和上面的resttemplate差不多，此模块是在注册中心注册过的，在这里你可以访问http://localhost:8020/consumer/findAll 等接口访问Eureka Client中的数据。 服务网关Zuul Spring Cloud 集成了 Zuul 组件，实现服务⽹关。 什么是Zuul? Zuul 是 Netflix 提供的⼀个开源的 API ⽹关服务器，是客户端和⽹站后端所有请求的中间层，对外开放⼀个 API，将所有请求导⼊统⼀的⼊⼝，屏蔽了服务端的具体实现逻辑，Zuul 可以实现反向代理的功能，在⽹关内部实现动态路由、身份认证、IP 过滤、数据监控等。 在父工程基础上再创建module pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8030spring: application: name: gatewayeureka: client: service-url: dedaultZone: http://localhost:8071/eureka/zuul: routes: serverProvider: /p/** 属性说明 zuul.routes.serverProvider：给服务提供者 provider 设置映射，这里的 serverProvider是Eureka Client在注册中心注册的服务名称，即访问其服务提供者模块，只需在结构访问地址加上/p/即可 创建启动类 12345678910111213package zuul.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@EnableZuulProxy@EnableAutoConfigurationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125; 注解解释 @EnableZuulProxy：包含了 @EnableZuulServer，设置该类是⽹关的启动类。 @EnableAutoConfiguration：可以帮助 Spring Boot 应⽤将所有符合条件的 @Configuration 配 置加载到当前 Spring Boot 创建并使⽤的 IoC 容器中。 Zuul ⾃带了负载均衡功能，provider 创建多个实例(即多个启动类，修改配置文件的端口)，每个实例提供不同的请求，修改 provider（即eureka client中的） 的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package eurekaclient.lee.controller;import eurekaclient.lee.entity.Student;import eurekaclient.lee.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentController &#123; @Autowired private StudentRepository repository; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return repository.findAll(); &#125; @GetMapping(\"/findById/&#123;id&#125;\") public Student findById(@PathVariable(\"id\")Integer id)&#123; return repository.findById(id); &#125; @PostMapping(\"/save\") public void save(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @PutMapping(\"/update\") public void update(@RequestBody Student student)&#123; repository.saveOrUpdate(student); &#125; @DeleteMapping(\"/deleteById/&#123;id&#125;\") public void deleteById(@PathVariable(\"id\")Integer id)&#123; repository.deleteById(id); &#125; @GetMapping(\"/index\") public String index()&#123; return \"当前端口：\" + this.port; &#125;&#125; 到这里网关服务基本实现，你只需要访问：http://localhost:8030/p/student/findAll 等接口也是可以访问到服务提供者中的数据。 Ribbon 负载均衡 什么是 Ribbon？ Spring Cloud Ribbon 是⼀个负载均衡解决⽅案，Ribbon 是 Netflix 发布的负载均衡器，Spring Cloud Ribbon 是基于 Netflix Ribbon 实现的，是⼀个⽤于对 HTTP 请求进⾏控制的负载均衡客户端。 在注册中⼼对 Ribbon 进⾏注册之后，Ribbon 就可以基于某种负载均衡算法，如轮询、随机、加权轮询、加权随机等⾃动帮助服务消费者调⽤接⼝，开发者也可以根据具体需求⾃定义 Ribbon 负载均衡算法。实际开发中，Spring Cloud Ribbon 需要结合 Spring Cloud Eureka 来使⽤，Eureka Server 提供所有可以调⽤的服务提供者列表，Ribbon 基于特定的负载均衡算法从这些服务提供者中选择要调⽤的。 具体实例。 在父工程上创建Module 在pom.xml文件中添加 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Module中创建配置文件 application.yml 1234567891011server: port: 8040spring: application: name: ribboneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 创建启动类------RibbonApplication.Java 1234567891011121314151617181920package ribbon.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonApplication.class,args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 注解说明 @LoadBalanced：声明⼀个基于 Ribbon 的负载均衡。 创建实体类(同上) 创建controller 12345678910111213141516171819202122232425262728package ribbon.lee.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import ribbon.lee.entity.Student;import java.util.Collection;@RestController@RequestMapping(\"/ribbon\")public class RibbonController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return restTemplate.getForObject(\"http://serverProvider/student/findAll\",Collection.class); &#125; @GetMapping(\"/index\") public String index()&#123; return restTemplate.getForObject(\"http://serverProvider/student/index\",String.class); &#125;&#125; 到此ribbon负载均衡基本实现，你可以访问：http://localhost:8040/ribbon/findAll 来访问服务提供者的数据。 Feign 负载均衡 什么是 Feign？ 与 Ribbon ⼀样，Feign 也是由 Netflix 提供的，Feign 是⼀个声明式、模版化的 Web Service 客户端， 它简化了开发者编写 Web 服务客户端的操作，开发者可以通过简单的接⼝和注解来调⽤ HTTP API， Spring Cloud Feign，它整合了 Ribbon 和 Hystrix，具有可插拔、基于注解、负载均衡、服务熔断等⼀ 系列便捷功能。 相⽐较于 Ribbon + RestTemplate 的⽅式，Feign ⼤⼤简化了代码的开发，Feign ⽀持多种注解，包括Feign 注解、JAX-RS 注解、Spring MVC 注解等，Spring Cloud 对 Feing 进⾏了优化，整合了 Ribbon和 Eureka，从⽽让 Feign 的使⽤更加⽅便。 Ribbon 和 Feign 的区别 Ribbon 是⼀个通⽤的 HTTP 客户端⼯具，Feign 是基于 Ribbon 实现的。 Feign 的特点 Feign 是⼀个声明式的 Web Service 客户端。 ⽀持 Feign 注解、Spring MVC 注解、JAX-RS 注解。 Feign 基于 Ribbon 实现，使⽤起来更加简单。 Feign 集成了 Hystrix，具备服务熔断的功能。 在父工程的基础上创建module—feign，在pom.xml中添加 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建该模板的配置文件：application.yml 1234567891011server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 实体类也要复制过来 创建启动类---------FeignApplication.java 12345678910111213package feign.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClientspublic class FeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignApplication.class,args); &#125;&#125; 创建声明式接口---------FeignProviderClient 1234567891011121314151617package feign.lee.feign;import feign.lee.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\")public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 创建控制器 12345678910111213141516171819202122232425262728package feign.lee.controller;import feign.lee.entity.Student;import feign.lee.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/feign\")public class FeignController &#123; @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return feignProviderClient.findAll(); &#125; @GetMapping(\"/index\") public String index()&#123; return feignProviderClient.index(); &#125;&#125; 到这里可以通过：http://localhost:8050/feign/findAll 来访问eureka client中的数据。和上面的Ribbon实现的功能是一样的，但是过程是不一样的。 Feign 中的熔断机制（因为Feign 集成了 Hystrix） 比如说一个功能需要多个微服务共同完成，但是其中一个微服务崩了，导致无法完成任务，如果没有熔断机制，前端就会显示报错，用户友好度不够好，用户也看不懂。 比如说把上面开启好的两个服务提供者eureka client关了，只留下eureka注册中心和feign，然后再次访问 http://localhost:8050/feign/findAll 或者是 http://localhost:8050/feign/index 就会报500的错误。 服务熔断，application.yml 添加熔断机制。 1234567891011121314server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: true feign.hystrix.enabled：是否开启熔断器。 创建 FeignProviderClient 接⼝的实现类 FeignError，定义容错处理逻辑，通过 @Component 注 解将 FeignError 实例注⼊ IoC 容器中。 1234567891011121314151617181920package feign.lee.feign.impl;import feign.lee.entity.Student;import feign.lee.feign.FeignProviderClient;import org.springframework.stereotype.Component;import java.util.Collection;@Componentpublic class FeignError implements FeignProviderClient &#123; @Override public Collection&lt;Student&gt; findAll() &#123; return null; &#125; @Override public String index() &#123; return \"当前服务器正在维护中。。。。。。\"; &#125;&#125; 在 FeignProviderClient 定义处通过 @FeignClient 的 fallback 属性设置映射。 123456789101112131415161718package feign.lee.feign;import feign.lee.entity.Student;import feign.lee.feign.impl.FeignError;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\",fallback = FeignError.class)public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 到这里，当你再次访问 http://localhost:8050/feign/index 的时候就提示 “当前服务器正在维护中。。。。。。”。 Hystrix 容错机制 什么是Hystrix容错机制 在不改变各个微服务调⽤关系的前提下，针对错误情况进⾏预先处理。(类似于电路的保险丝) 设计原则 服务隔离机制 服务降级机制 熔断机制 提供实时的监控和报警功能 提供实时的配置修改功能 Hystrix 数据监控需要结合 Spring Boot Actuator 来使⽤，Actuator 提供了对服务的健康健康、数据统计，可以通过 hystrix.stream 节点获取监控的请求数据，提供了可视化的监控界⾯。 在父工程的基础上再创建module—hystrix，pom.xml添加依赖 12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8060spring: application: name: hystrixeureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: truemanagement: endpoints: web: exposure: include: 'hystrix.stream' 创建启动类---------HystrixApplication.java 1234567891011121314151617package hystrix.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClients@EnableCircuitBreaker@EnableHystrixDashboardpublic class HystrixApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HystrixApplication.class,args); &#125;&#125; 注解解释 @EnableCircuitBreaker：声明启⽤数据监控 @EnableHystrixDashboard：声明启⽤可视化数据监控 添加Student实体类 添加feign模块中的FeignProviderClient接口类 1234567891011121314151617package hystrix.lee.feign;import hystrix.lee.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"serverProvider\")public interface FeignProviderClient &#123; @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();&#125; 添加控制类 12345678910111213141516171819202122232425262728package hystrix.lee.controller;import hystrix.lee.entity.Student;import hystrix.lee.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/hystrix\")public class HystrixController &#123; @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll()&#123; return feignProviderClient.findAll(); &#125; @GetMapping(\"/index\") public String index()&#123; return feignProviderClient.index(); &#125;&#125; 到这里只是演示了hystrix对数据请求进行监控的功能，hystrix的熔断机制在Feign中已经演示过。然后启动注册中心，启动一个服务提供者eureka client，最后再启动hystrix，先访问 http://localhost:8060/actuator/hystrix.stream 查看hystrix对求情的监控，这个时候因为没有发生对提供者的请求，所以没有监控到数据，一直在ping: 然后再访问： http://localhost:8060/hystrix/index ，你会发现ping: 出现了数据。 当然这个网页看着监控的数据显示不是和友好，所以我们这里使用的是 hystrix-dashboard仪表盘来查看，访问： http://localhost:8060/hystrix ，然后把 http://localhost:8060/actuator/hystrix.stream地址复制过来，自己起一个监控的名字，点击Monitor Stream,就有一个可视化仪表盘了。 Spring Cloud 配置中⼼ Spring Cloud Config，通过服务端可以为多个客户端提供配置服务。Spring Cloud Config 可以将配置⽂件存储在本地，也可以将配置⽂件存储在远程 Git 仓库，创建 Config Server，通过它管理所有微服务的配置⽂件。 本地文件系统 在父工程的基础上创建module—nativeconfigserver，pom.xml添加以下 123456789&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8072spring: application: name: nativeconfigserver profiles: active: native cloud: config: server: native: search-locations: classpath:/shared 属性说明 profiles.active：配置⽂件的获取⽅式，这里的native指本地获取 cloud.config.server.native.search-locations：本地配置⽂件存放的路径 在resources 路径下创建 shared ⽂件夹，并在此路径下创建 configclient-dev.yml。 123server: port: 8070foo: foo version 1 创建启动类---------NativeConfigServerApplication.java 12345678910111213package config.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class NativeConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NativeConfigServerApplication.class,args); &#125;&#125; 注解说明 @EnableConfigServer：声明该module为配置中⼼。 以上配置文件的服务已经创建完成，下面开始创建一个congifclient来读取上面我们创建的configserver中的configclient-dev文件的内容。 创建客户端读取本地配置中⼼的配置⽂件 在父工程的基础上创建module—nativeconfigclient，pom.xml文件添加依赖： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 bookstrap.yml ，注意这里的文件名，不再是application。 123456789spring: application: name: configclient profiles: active: dev cloud: config: uri: http://localhost:8072 fail-fast: true 属性说明 cloud.config.uri：本地 Config Server 的访问路径 cloud.config.fail-fase：设置客户端优先判断 Config Server 获取是否正常 通过 spring.application.name 结合 spring.profiles.active 拼接⽬标配置⽂件名(如上拼接的结果：configclient-dev)，configclient-dev.yml，去 Config Server 中查找该⽂件。 创建启动类---------NativeConfigClientApplication.java 1234567891011package configclient.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class NativeConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NativeConfigClientApplication.class,args); &#125;&#125; 创建controller 12345678910111213141516171819202122package configclient.lee.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/native\")public class ConfigClientCtroller &#123; @Value(\"$&#123;server.port&#125;\") private String port; @Value(\"$&#123;foo&#125;\") private String foo; @GetMapping(\"/index\") public String index()&#123; return this.port+ \" - \"+this.foo; &#125;&#125; 到此获取配置文件中心的客户端已创建完成，访问的端口号为要获取的配置文件中的端口号，即：8070，所以该客户端的访问地址为： http://localhost:8070/native/index ，之后网页显示配置中心shared下的文件的内容。 Spring Cloud Config 远程配置 在工程中创建配置⽂件，上传⾄ GitHub（创建config文件夹，然后在里面创建configclient.yml文件） 123456789server: port: 8070spring: application: name: configclienteureka: client: service-url: defaultZone: http://localhost:8071/eureka/ 创建一个githubconfigserver子工程，其pom.xml添加： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011121314151617181920server: port: 8888spring: application: name: configserver cloud: config: server: git: uri: https://github.com/Ctrl08/SpringCloud_Learn.git search-paths: config username: 123456 password: 123456 label: mastereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ # instance:# prefer-ip-address: true 创建启动类---------GithubConfigServerApplication.java 12345678910111213package githubconfig.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class GithubConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GithubConfigServerApplication.class,args); &#125;&#125; 到这里配置中心服务端已创建完成 创建客户端读取远程配置中⼼的配置⽂件 在父工程中创建maven工程，githubconfigclient，pom.xml文件添加依赖 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建bootstrap.yml配置文件 1234567891011121314spring: cloud: config: name: configclient label: master discovery: enabled: true service-id: configservereureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性解释 spring.cloud.config.name：当前服务注册在 Eureka Server 上的名称，与远程仓库的配置⽂件名 对应 spring.cloud.config.label：Git Repository 的分⽀ spring.cloud.config.discovery.enabled：是否开启 Config 服务发现⽀持 spring.cloud.config.discovery.service-id：配置中⼼在 Eureka Server 上注册的名称 创建启动类---------GithubConfigClientApplication.java 1234567891011package configclient.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GithubConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GithubConfigClientApplication.class,args); &#125;&#125; 创建控制器 12345678910111213141516171819package configclient.lee.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/hello\")public class HelloController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/index\") public String index()&#123; return this.port; &#125;&#125; 到此远程配置中心基本创建完成，可以通过访问：http://localhost:8070/hello/index 查看client通过远程获取配置中心所设置的端口号。 服务跟踪 Zipkin Spring Cloud Zipkin 对请求进行跟踪 Zipkin 是⼀个可以采集并且跟踪分布式系统中请求数据的组件，让开发者可以更加直观的监控到请求在各个微服务所耗费的时间等，Zipkin：Zipkin Server(请求数据跟踪)、Zipkin Client(数据的展示)。 创建服务跟踪 Zipkin Server 在父工程创建maven子工程，pom.xml文件添加依赖： 1234567891011121314151617181920&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12server: port: 9090 创建服务端启动类---------ZipkinServerApplication.java 12345678910111213package zipkin.lee;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import zipkin.server.internal.EnableZipkinServer;@SpringBootApplication@EnableZipkinServerpublic class ZipkinServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinServerApplication.class,args); &#125;&#125; 注解说明 @EnableZipkinServer：声明启动 Zipkin Server 到这里Zipkin Server创建完成。 创建服务跟踪 Zipkin Client 在父工程创建maven子工程，pom.xml添加依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8090spring: application: name: zipkinclient sleuth: web: client: enabled: true sampler: probability: 1.0 zipkin: base-url: http://localhost:9090/eureka: client: service-url: defaultZone: http://localhost:8071/eureka/ instance: prefer-ip-address: true 属性说明 spring.sleuth.web.client.enabled：设置开启请求跟踪 spring.sleuth.sampler.probability：设置采样⽐例，默认是 1.0 srping.zipkin.base-url：Zipkin Server 地址 创建启动类---------ZipkinClientApplication.java 1234567891011package zipkinclient;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ZipkinClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinClientApplication.class,args); &#125;&#125; 创建控制器controller 12345678910111213141516171819package zipkinclient.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/zipkin\")public class ZipkinController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/index\") public String index()&#123; return this.port; &#125;&#125; 到这里基本完成Zipkin的创建。 启动注册中心、zipkin server和zipkin client，访问：http://localhost:9090/zipkin 即可进入数据请求监控的ui界面，点击 Find Traces 按钮即可开启跟踪请求，另开一个浏览页，访问：http://localhost:8090/zipkin/index ，再回头看看刚才的页面，刷新页面就可以看到有请求发生并且追踪到了。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://ctrl98.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://ctrl98.github.io/tags/Spring-Cloud/"}]},{"title":"Redis实现一个简单的分布锁","slug":"Redis3","date":"2020-03-08T01:41:07.000Z","updated":"2020-03-08T04:06:13.246Z","comments":true,"path":"2020/03/08/Redis3/","link":"","permalink":"http://ctrl98.github.io/2020/03/08/Redis3/","excerpt":"","text":"什么是分布式锁 分布式锁在分布式系统中非常常见，比如对公共资源进行操作。 如卖车票，同一时刻只能有一个节点将某个特定座位的票卖出去；如避免缓存失效带来的大量请求访问数据库的问题 分布式锁需要解决的问题 互斥性：任意时刻只能有一个客户端获取锁 安全性：锁只能被持有该锁的客户端删除 死锁：某个客户端获取到锁，因某些原因宕机，使得其他客户端再也获取不了 容错：某个redis节点宕机，客户端仍然可以获取锁 实现 SETNX key value：如果key不存在，则创建并赋值 时间复杂度：o(1) 返回值：成功返回1，失败返回0 该操作是原子性的 123456789127.0.0.1:6379&gt; get locknx(nil)127.0.0.1:6379&gt; setnx locknx test(integer) 1127.0.0.1:6379&gt; setnx locknx task(integer) 0127.0.0.1:6379&gt; get locknx&quot;test&quot;127.0.0.1:6379&gt; 开始设置成功，说明目前该线程没有被占用，可以执行目前的代码块，如果设置失败，说明该线程目前被其他程序占用该资源，等待设置成功后再释放。。。 发现再后续再赋值locknx的时候失败了，说明此时该值是长期有效的。 如何解决setnx长期有效的问题 EXPIRE key seconds 设置key的生存时间，当key过期时，会被删除 1234567127.0.0.1:6379&gt; expire locknx 2(integer) 1127.0.0.1:6379&gt; setnx locknx task(integer) 1127.0.0.1:6379&gt; get locknx&quot;task&quot;127.0.0.1:6379&gt; 发现再设置的时候已经成功了 在实际代码中可以进行对返回值的判断： 12345678RedisService redisService = SpringUtils.getBean(RedisService.Class);long status = redisService.setnx(key,\"1\");if (status == 1)&#123; redisService.expire(key,expire) //执行独占资源逻辑 doOcuppieWork();&#125; 当有客户端请求该资源时发现status的值为0，说明有程序在占用该资源，后面的就不能执行了，线程进入阻塞，直到status的返回值为1为止。 然后这段程序会有风险，如果程序在执行完setnx后直接挂掉了，并没有进入到expire设置时间，这样key就永远不会过期，一直被占用着，导致其他程序再也获取不了该线程。 解决 将setnx和expire柔和在一起 SET key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置键的过期时间为second秒 PX milliseconds：设置键的过期时间为second毫秒 NX：只有键不存在时，才对键进行设置操作 XX：只有键已经存在时，才对键进行设置操作 SET操作返回值，成功ok，失败返回nil 1234567127.0.0.1:6379&gt; set locktarget 12345 ex 10 nxOK127.0.0.1:6379&gt; set locktarget 1234 ex 10 nx(nil)127.0.0.1:6379&gt; set locktarget 54321 ex 10 nxOK127.0.0.1:6379&gt; 过了10秒之后发现设置成功，符合redis的原子性操作。 因此伪代码也可以设置成： 123456RedisService redisService = SpringUtils.getBean(RedisService.Class);String result = redisService.set(lockkey,requestId,SET_NOT_EXIST,SET_WITH_EXPIRE_TIME,expiretime);if (\"ok\".equals(result))&#123; //执行独占资源逻辑 doOcuppieWork();&#125; 这样就能保证分布式锁操作的原子性了。 大量的key同时过期的注意事项 集中过期，由于清除大量过期的key很耗时，会出现卡顿现象 解决：在设置key的过期时间的时候，给每个key加上随机值","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Redis主从、哨兵及集群模式的配置","slug":"Redis2","date":"2020-03-07T13:02:19.000Z","updated":"2020-03-08T01:44:30.300Z","comments":true,"path":"2020/03/07/Redis2/","link":"","permalink":"http://ctrl98.github.io/2020/03/07/Redis2/","excerpt":"","text":"redis主从模式的配置 redis单例提供了一种数据缓存方式和丰富的数据操作api ，但是把数据完全存储再单个redis中会有两个问题：数据备份和数据量大造成性能低下。主从模式出现就是为了解决单例所带来的问题。 主从模式指： 使用一个redis实例作为主机，其余的实例作为备份机。主机和从机的数据完全一致。主机支持数据的写入和读取等各项操作，而从机则只支持与主机数据的同步和读取，也就是说，客户端可以将数据写入到主机，由主机自动将数据的写入操作同步到从机。 主从模式很好的解决了数据备份问题，并且由于主从服务数据几乎是一致的，因而可以将写入数据的命令发送给主机执行，而读取数据的命令发送给不同的从机执行，从而达到读写分离的目的。如下图的主机和三个从机。 至此redis主从模式的配置可以理解为多个不同的redis实例通过一定的配置告知其相互之间的主从关系。 主从模式的配置主要的配置点有两个： 当前实例端口号和当前实例是主机还是从机，是从机的话其主机的ip和端口是什么？ 一般的redis目录下的redis.conf保存的是默认配置，尽量不要对其进行修改. 这里我们复制三份redis.conf文件，分别命名为6379.conf，6380.conf和6381.conf 6379.conf的配置： 12bind 127.0.0.1port 6379 6380.conf和6381.conf的配置： 123bind 127.0.0.1port 6380slaveof 127.0.0.1 6379 123bind 127.0.0.1port 6381slaveof 127.0.0.1 6379 可以看到，端口为6380和6381的实例被配置为端口为6379的实例的从机。 配置完成后使用redis-server分别执行如下命令启动三个实例： 123.\\redis-server 6379.conf.\\redis-server 6380.conf.\\redis-server 6381.conf 启动之后分别开启三个命令行工具(即redis客户端)分别执行以下命令连接redis实例： 123.\\redis-cli -p 6379.\\redis-cli -p 6380.\\redis-cli -p 6381 分别在三个命令行工具中执行一个get命令，获取键名为msg的数据，如下所示： 12127.0.0.1:6379&gt; get msg(nil) 12127.0.0.1:6380&gt; get msg(nil) 12127.0.0.1:6381&gt; get msg(nil) 可以看到，在三个redis实例中都不存在键为msg的数据，现在我们在主机6379上设置一个键为msg的数据，如下所示： 12127.0.0.1:6379&gt; set msg &quot;hello&quot;OK 可以看到设置成功了，此时我们在6380和6381的实例上执行get msg的命令，如下所示： 12127.0.0.1:6380&gt; get msg&quot;hello&quot; 12127.0.0.1:6381&gt; get msg&quot;hello&quot; 可以看到，虽然我们只是在6379的实例上设置了msg这条数据，但是在6380和6381的实例上也存有了相应的数据，说明我们成功配置了redis的主从模式。另外，如果不在配置文件中指定主从节点的关系，也可以在启动相关redis实例之后使用slaveof命令来指定当前节点称为某个节点的从节点，如： 1127.0.0.1:6380&gt; slaveof 127.0.0.1 6379 redis中sentinel(哨兵)配置 redis主从模式解决了数据备份和单例可能存在的性能问题，但是其也引入了新的问题。 主从模式配置的几个实例，每个实例都会有不同的IP(如果在不同机器上)和端口号，从上面可知，主从模式将读写分配给不同的实例进行从而提高吞吐量，但是也会有另外一个问题，因为每个客户端连接redis都指定了IP和端口号，如果所连接的redis因故障下线，就只能手动去更改客户端配置重新连接，另外如果是主节点故障，那么那些从节点的同步会中断，也需要人工去转移工作。 为了解决以上问题，redis在2.8版本正式推出sentinel(哨兵)架构。 每个sentinel节点其实就是一个redis实例。与主从节点不同的是sentinel节点作用是用于监控redis数据节点的，而sentinel节点集合则表示监控一组主从redis实例多个sentinel监控节点的集合。 比如有主节点master和从节点slave-1、slave-2，为了监控这三个主从节点，这里配置N个sentinel节点sentinel-1，sentinel-2，...，sentinel-N。 对于一组主从节点，sentinel只是在其外部额外添加的一组用于监控作用的redis实例。在主从节点和sentinel节点集合配置好之后，sentinel节点之间会相互发送消息，以检测其余sentinel节点是否正常工作，并且sentinel节点也会向主从节点发送消息，以检测监控的主从节点是否正常工作。 前面讲到，sentinel架构的主要作用是解决主从模式下主节点的故障转移工作的。这里如果主节点因为故障下线，那么某个sentinel节点发送检测消息给主节点时，如果在指定时间内收不到回复，那么该sentinel就会主观的判断该主节点已经下线，那么其会发送消息给其余的sentinel节点，询问其是否“认为”该主节点已下线，其余的sentinel收到消息后也会发送检测消息给主节点。 如果其认为该主节点已经下线，那么其会回复向其询问的sentinel节点，告知其也认为主节点已经下线，当该sentinel节点最先收到超过指定数目（配置文件中配置的数目和当前sentinel节点集合数的一半，这里两个数目的较大值）的sentinel节点回复说当前主节点已下线，那么其就会对主节点进行故障转移工作，故障转移的基本思路是在从节点中选取某个从节点向其发送slaveof no one（假设选取的从节点为127.0.0.1:6380），使其称为独立的节点（也就是新的主节点），然后sentinel向其余的从节点发送slaveof 127.0.0.1 6380命令使它们重新成为新的主节点的从节点。 重新分配之后sentinel节点集合还会继续监控已经下线的主节点（假设为127.0.0.1:6379），如果其重新上线，那么sentinel会向其发送slaveof命令，使其成为新的主机点的从节点，如此故障转移工作完成。 简单来说就是：当redis服务为主从的时候如果主节点挂掉，则会选取一个从节点为master，当以前的master重启之后不再是master而为slave。 创建并修改sentinel.conf 复制三个配置文件：sentinel-26379.conf，sentinel-26380.conf和sentinel-26381.conf。分别按照如下示例编辑这三个配置文件 123456789101112131415port 26379 daemonize yes logfile &quot;26379.log&quot; dir &#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000sentinel myid mm55d2d712b1f3f312b637f9b546f00cdcedc787#port 26379#sentinel monitor mymaster 127.0.0.1 6379 2#sentinel down-after-milliseconds mymaster 5000#sentinel failover-timeout mymaster 15000#sentinel myid 88a3f92f656984fd84c183b6b183d5d264ddc485 属性说明 port：当前Sentinel服务运行的端口 sentinel monitor mymaster 127.0.0.1 6379 2：Sentinel去监视一个名为mymaster的主redis实例，这个主实例的IP地址为本机地址127.0.0.1，端口号为6379，而将这个主实例判断为失效至少需要2个 Sentinel进程的同意，只要同意Sentinel的数量不达标，自动failover就不会执行 sentinel down-after-milliseconds mymaster 5000：指定了Sentinel认为Redis实例已经失效所需的毫秒数。当 实例超过该时间没有返回PING，或者直接返回错误，那么Sentinel将这个实例标记为主观下线。只有一个 Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移：只有在足够数量的Sentinel都将一个实例标记为主观下线之后，实例才会被标记为客观下线，这时自动故障迁移才会执行 sentinel failover-timeout mymaster 15000：如果在该时间（ms）内未能完成failover操作，则认为该failover失败 myid：区分每个监控的哨兵的身份 分别使用三个配置文件使用如下命令启用sentinel 123.&#x2F;src&#x2F;redis-sentinel sentinel-26379.conf.&#x2F;src&#x2F;redis-sentinel sentinel-26380.conf.&#x2F;src&#x2F;redis-sentinel sentinel-26381.conf 由于sentinel节点也是一个redis实例，因而我们可以通过如下命令使用redis-cli连接sentinel节点： 1.&#x2F;src&#x2F;redis-cli -p 26379 连上sentinel节点之后我们可以通过如下命令查看sentinel状态： 1127.0.0.1:26379&gt; info sentinel 结果如下： 1234567# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;127.0.0.1:6379,slaves&#x3D;2,sentinels&#x3D;3 可以看到，sentinel检测到主从节点总共有三个，其中一个主节点，两个从节点，并且sentinel节点总共也有三个。启动完成之后，我们可以通过主动下线主节点来模拟sentinel的故障转移过程。首先我们连接上端口为6379的主节点，使用如下命令查看主从节点状态： 1127.0.0.1:6379&gt; info replication 结果如下： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;45616,lag&#x3D;1slave1:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;45616,lag&#x3D;1master_repl_offset:45616repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:45615 可以看到，当前主节点有两个从节点，端口分别为6380和6381。然后我们对主节点执行如下命令： 1127.0.0.1:6379&gt; shutdown save 然后我们连接上端口号为6380的从节点，并执行如下命令： 1127.0.0.1:6380&gt; info replication 结果如下： 123456789# Replicationrole:masterconnected_slaves:1slave0:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;12344,lag&#x3D;0master_repl_offset:12477repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:12476 可以看到，当端口为6379的实例下线之后，端口为6380的实例被重新竞选为新的主节点，并且端口为6381的实例被设置为6380的实例的从节点。如果我们此时重新启用端口为6379的节点，然后再查看主从状态，结果如下： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;59918,lag&#x3D;0slave1:ip&#x3D;127.0.0.1,port&#x3D;6379,state&#x3D;online,offset&#x3D;59918,lag&#x3D;1master_repl_offset:60051repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:60050 可以看到，端口为6379的redis实例重新连接后，sentinel节点检测到其重新连接，那么对其发送命令，使其成为新的主节点的从节点。 redis集群的配置 redis集群是在redis 3.0版本推出的一个功能，其有效的解决了redis在分布式方面的需求。当遇到单机内存，并发和流量瓶颈等问题时，可采用Cluster方案达到负载均衡的目的。并且从另一方面讲，redis中sentinel有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。 对于redis集群的配置，首先将redis安装目录下的redis.conf文件复制六份，分别取名为：cluster-6379.conf、cluster-6380.conf、cluster-6381.conf、cluster-6382.conf、cluster-6383.conf、cluster-6384.conf。对于一个高可用的集群方案，集群每个节点都将为其分配一个从节点，以防止数据节点因为故障下线，这里使用六份配置文件定义六个redis实例，其中三个作为主节点，剩余三个分别作为其从节点。对于这六份配置文件，以其中一份为例，以下是其需要修改的参数： 12345678port 6379cluster-enabled yescluster-node-timeout 15000cluster-config-file &quot;nodes-6379.conf&quot;pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pidlogfile &quot;cluster-6379.log&quot;dbfilename dump-cluster-6379.rdbappendfilename &quot;appendonly-cluster-6379.aof&quot; 对于其余的配置文件，只需要将其中对应项的端口号和带有端口号的文件名修改为当前要指定的端口号和端口号的文件名即可。配置文件配置好之后使用如下命令启动集群中的每个实例： 123456.&#x2F;src&#x2F;redis-server cluster-6379.conf.&#x2F;src&#x2F;redis-server cluster-6380.conf.&#x2F;src&#x2F;redis-server cluster-6381.conf.&#x2F;src&#x2F;redis-server cluster-6382.conf.&#x2F;src&#x2F;redis-server cluster-6383.conf.&#x2F;src&#x2F;redis-server cluster-6384.conf 仔细阅读上述配置文件可发现，当前配置和启动过程中并没有指定这六个实例的主从关系，也没有对16384个槽位进行分配。因而我们还需要进行进一步的配置，槽位的分配和主从关系的设定有两种方式进行，一种是使用redis-cli连接到集群节点上后使用cluster meet命令连接其他的节点，如我们首先执行如下命令连接到6379端口的节点： 1.&#x2F;src&#x2F;redis-cli -p 6379 连接上后使用cluster meet命令分别连接其余节点： 12345127.0.0.1:6379&gt;cluster meet 127.0.0.1 6380127.0.0.1:6379&gt;cluster meet 127.0.0.1 6381127.0.0.1:6379&gt;cluster meet 127.0.0.1 6382127.0.0.1:6379&gt;cluster meet 127.0.0.1 6383127.0.0.1:6379&gt;cluster meet 127.0.0.1 6384 连接好后可以使用cluster nodes命令查看当前集群状态： 1234567127.0.0.1:6379&gt; cluster nodes4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1:6384 master - 0 1468073975551 5 connectedcfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1:6379 myself,master - 0 0 0 connectedbe9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1:6383 master - 0 1468073978579 4 connected40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1:6382 master - 0 1468073980598 3 connected8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1:6380 master - 0 1468073974541 1 connected40b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1:6381 master - 0 1468073979589 2 connected 可以看到配置的六个节点都已经加入到了集群中，但是其现在还不能使用，因为还没有将16384个槽分配到集群节点中。虚拟槽的分配可以使用redis-cli分别连接到6379，6380和6381端口的节点中，然后分别执行如下命令： 123127.0.0.1:6379&gt;cluster addslots &#123;0...5461&#125;127.0.0.1:6380&gt;cluster addslots &#123;5462...10922&#125;127.0.0.1:6381&gt;cluster addslots &#123;10923...16383&#125; 添加完槽位后可使用cluster info命令查看当前集群状态： 123456789101112127.0.0.1:6379&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:5cluster_my_epoch:0cluster_stats_messages_sent:4874cluster_stats_messages_received:4726 这里我们将16384个虚拟槽位分配给了三个节点，而剩余的三个节点我们通过如下命令将其配置为这三个节点的从节点，从而达到高可用的目的： 123456127.0.0.1:6382&gt;cluster replicate cfb28ef1deee4e0fa78da86abe5d24566744411eOK127.0.0.1:6383&gt;cluster replicate 8e41673d59c9568aa9d29fb174ce733345b3e8f1OK127.0.0.1:6384&gt;cluster replicate 40b8d09d44294d2e23c7c768efc8fcd153446746OK 如此，所有的集群节点都配置完毕，并且处于可用状态。这里可以使用cluster nodes命令查看当前节点的状态： 1234567127.0.0.1:6379&gt; cluster nodes4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1:6384 slave 40b8d09d44294d2e23c7c768efc8fcd153446746 0 1468076865939 5 connectedcfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1:6379 myself,master - 0 0 0 connected 0-5461be9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1:6383 slave 8e41673d59c9568aa9d29fb174ce733345b3e8f1 0 1468076868966 4 connected40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1:6382 slave cfb28ef1deee4e0fa78da86abe5d24566744411e 0 1468076869976 3 connected8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1:6380 master - 0 1468076870987 1 connected 5462-1092240b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1:6381 master - 0 1468076867957 2 connected 10923-16383 我们使用redis-cli使用如下命令连接集群： 1.&#x2F;src&#x2F;redis-cli -c -p 6380 注意连接集群模式的redis实例时需要加上参数-c，表示连接的是集群模式的实例。连接上后执行get命令： 123127.0.0.1:6380&gt; get hello-&gt; Redirected to slot [866] located at 127.0.0.1:6379(nil) 可以看到，在6380端口的实例上执行get命令时，其首先会为当前的键通过一致哈希算法计算其所在的槽位，并且判断该槽位不在当前redis实例中，因而重定向到目标实例上执行该命令，最后发现没有该键对应的值，因而返回了一个（nil）。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Redis数据缓存 基础知识","slug":"Redis1","date":"2020-03-06T01:12:22.000Z","updated":"2020-03-08T07:47:46.848Z","comments":true,"path":"2020/03/06/Redis1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Redis1/","excerpt":"","text":"主流应用架构 穿透查询：请求数据的时候先到缓存层查询数据，当缓存层没有数据，在穿透到存储层查询 回种：穿透查询完成后再缓存到缓存区 熔断：当存储层挂了之后，会自动从缓存层获取并返回数据，无论有没有获取到数据都返回 缓存中间件——Memcache和Redis的区别 Memcache：代码层次类似Hash 优缺点： 支持简单数据类型 不支持数据持久化存储 不支持主从 不支持分片(把数据库打碎的过程，将大数据分布到各个物理节点上) Redis 优缺点： 数据类型丰富 支持数据持久化存储 支持主从 支持分片(3.0版本后) 为什么Redis能这么快？ 100000+QPS（QPS即query per second，每秒内查询次数） 完全基于内存，绝大部分请求时纯粹的内存操作，执行效率高 数据结构简单，对数据操作也简单 采用单线程，单线程也能处理高并发请求，想多核也可以启动多实例 使用多路复用I/O复用模型，非阻塞IO redis单例的安装及配置使用 win10本地安装redis服务 进入根目录，配置redis.windows.conf： 添加配置需要密码验证 requirepass 123456 修改 appendonly 为yes 开启aof日志防止数据丢失 根目录处以管理员身份打开cmd 输入启动命令启动服务端： 12.\\redis-server.exe redis.windows.conf###注意如果提示错误，把前面的.\\请去掉再回车试试 如果需要按照指定的配置文件来启动，可在redis-server.exe后接上配置文件名 : 1.\\redis-server.exe redis1.conf 再打开一个cmd窗口启动客户端： 1.\\redis-cli.exe 然后输入认证密码命令连接服务： 1auth 123456 显示ok即连接成功，输入ping测试看是否返回pong。 如果需要连接指定ip和端口的客户端，可以使用如下方式 : 1.\\redis-cli.exe -h 127.0.0.1 -p 6379 Redis数据类型 String类型 redis最基本的数据类型，k-v存储，最大能存储512M，二进制安全(即可以包含任何数据，如jpg图片、序列化对象…) 简单操作 1234567891011121314151617127.0.0.1:6379&gt; set name &quot;redis&quot;OK127.0.0.1:6379&gt; get name&quot;redis&quot;127.0.0.1:6379&gt; set name &quot;memocache&quot;OK127.0.0.1:6379&gt; get name&quot;memocache&quot;127.0.0.1:6379&gt; set count 1OK127.0.0.1:6379&gt; get count&quot;1&quot;127.0.0.1:6379&gt; incr count(integer) 2127.0.0.1:6379&gt; get count&quot;2&quot;127.0.0.1:6379&gt; Hash类型 string元素组成的字典，适合用于存储对象 简单操作 1234567891011127.0.0.1:6379&gt; hmset lilei name &quot;lilei&quot; age 18 title &quot;senior&quot;OK127.0.0.1:6379&gt; hget lilei age&quot;18&quot;127.0.0.1:6379&gt; hget lilei title&quot;senior&quot;127.0.0.1:6379&gt; hset lilei title &quot;collge&quot;(integer) 0127.0.0.1:6379&gt; hget lilei title&quot;collge&quot;127.0.0.1:6379&gt; List类型 列表，按照String元素插入顺序排序，可以添加元素到列表的头部或尾部，元素先进后出，(最新排行榜) 简单操作 1234567891011127.0.0.1:6379&gt; lpush mylist aaa(integer) 1127.0.0.1:6379&gt; lpush mylist bbb(integer) 2127.0.0.1:6379&gt; lpush mylist ccc(integer) 3127.0.0.1:6379&gt; lrange mylist 0 101) &quot;ccc&quot;2) &quot;bbb&quot;3) &quot;aaa&quot;127.0.0.1:6379&gt; Set类型 String元素组成的无须集合，通过哈希表表现，不允许重复，(微博的互相关注) 简单操作 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; sadd myset 111(integer) 1127.0.0.1:6379&gt; sadd myset 222(integer) 1127.0.0.1:6379&gt; sadd myset 333(integer) 1127.0.0.1:6379&gt; sadd myset 333(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;111&quot;2) &quot;222&quot;3) &quot;333&quot;127.0.0.1:6379&gt; sadd myset abc(integer) 1127.0.0.1:6379&gt; sadd myset abd(integer) 1127.0.0.1:6379&gt; sadd myset abb(integer) 1127.0.0.1:6379&gt; sadd myset abd(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;abc&quot;2) &quot;222&quot;3) &quot;abd&quot;4) &quot;abb&quot;5) &quot;333&quot;6) &quot;111&quot;127.0.0.1:6379&gt; Sorted Set类型 通过分数score来为集合中的成员进行从小到大排序，去重 简单操作 12345678910111213141516127.0.0.1:6379&gt; zadd myzset 3 abc(integer) 1127.0.0.1:6379&gt; zadd myzset 1 abd(integer) 1127.0.0.1:6379&gt; zadd myzset 2 abb(integer) 1127.0.0.1:6379&gt; zadd myzset 2 abb(integer) 0127.0.0.1:6379&gt; zadd myzset 1 bgg(integer) 1127.0.0.1:6379&gt; zrangebyscore myzset 0 101) &quot;abd&quot;2) &quot;bgg&quot;3) &quot;abb&quot;4) &quot;abc&quot;127.0.0.1:6379&gt; 缓存雪崩 什么是缓存雪崩？ 如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩 由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。 有什么解决方案来防止缓存雪崩？ 加锁排队 mutex互斥锁解决，Redis的SETNX去set一个mutex key，当操作返回成功时，再进行加载数据库的操作并回设缓存，否则，就重试整个get缓存的方法 数据预热 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据。可以通过缓存reload机制，预先去更新缓存，在即将发生大并发访问前手动触发加载缓存不同的key。 双层缓存策略 C1为原始缓存，C2为拷贝缓存，C1失效时，可以访问C2，C1缓存失效时间设置为短期，C2设置为长期 定时更新缓存策略 实效性要求不高的缓存，容器启动初始化加载，采用定时任务更新或移除缓存 设置不同的过期时间，让缓存失效的时间点尽量均匀 缓存击穿 什么是缓存击穿？ 在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 会带来什么问题 会造成某一时刻数据库请求量过大，压力剧增。 如何解决 上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它，其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。 缓存穿透 什么是缓存穿透？ 缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到对应key的value，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库。 有什么解决方案来防止缓存穿透？ 缓存空值 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障）我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过5分钟。通过这个设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库。 采用布隆过滤器BloomFilter 优势：占用内存空间很小，位存储；性能特别高，使用key的hash判断key存不存在 将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力 在缓存之前在加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查询缓存，缓存中没有再去查询数据库","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ctrl98.github.io/tags/Redis/"}]},{"title":"Mysql 基础知识（一）","slug":"Mysql1","date":"2020-03-06T01:05:41.000Z","updated":"2020-03-24T12:10:02.092Z","comments":true,"path":"2020/03/06/Mysql1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Mysql1/","excerpt":"","text":"where子句 **where：**数据库中常用的是where关键字，用于在初始表中筛选查询。它是一个约束声明，用于约束数据，在返回结果集之前起作用。 **group by:**对select查询出来的结果集按照某个字段或者表达式进行分组，获得一组组的集合，然后从每组中取出一个指定字段或者表达式的值。 **having：**用于对where和group by查询出来的分组经行过滤，查出满足条件的分组结果。它是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作。 执行顺序 select –&gt;where –&gt; group by–&gt; having–&gt;order by update 当我们需要将字段中的特定字符串批量修改为其他字符串时，可已使用以下操作： 12UPDATE runoob_tbl SET runoob_title &#x3D; REPLACE(runoob_title, &#39;C++&#39;, &#39;Python&#39;) where runoob_id &#x3D; 3; delete delete，drop，truncate 都有删除表的作用，区别在于： 1、delete 和 truncate 仅仅删除表数据，drop 连表数据和表结构一起删除，打个比方，delete 是单杀，truncate 是团灭，drop 是把电脑摔了。 2、delete 是 DML 语句，操作完以后如果没有不想提交事务还可以回滚，truncate 和 drop 是 DDL 语句，操作完马上生效，不能回滚，打个比方，delete 是发微信说分手，后悔还可以撤回，truncate 和 drop 是直接扇耳光说滚，不能反悔。 3、执行的速度上，drop&gt;truncate&gt;delete，打个比方，drop 是神舟火箭，truncate 是和谐号动车，delete 是自行车。 like子句 LIKE 子句中使用百分号 **%**字符来表示任意字符，类似于UNIX或正则表达式中的星号 ***** 如果没有使用百分号 %, LIKE 子句与等号 = 的效果是一样的 like 匹配/模糊匹配，会与 % 和 _ 结合使用： 123456&#39;%a&#39; &#x2F;&#x2F;以a结尾的数据&#39;a%&#39; &#x2F;&#x2F;以a开头的数据&#39;%a%&#39; &#x2F;&#x2F;含有a的数据&#39;_a_&#39; &#x2F;&#x2F;三位且中间字母是a的&#39;_a&#39; &#x2F;&#x2F;两位且结尾字母是a的&#39;a_&#39; &#x2F;&#x2F;两位且开头字母是a的 union 操作符 UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。 union 实例： 1SELECT country FROM Websites UNION SELECT country FROM apps ORDER BY country 查两张表中的同一个字段的不同值都查询出来（去重） union all 实例： 1SELECT country FROM Websites UNION ALL SELECT country FROM apps ORDER BY country 查两张表中的同一个字段的相同的值都查出来（不去重） order by 子句排序 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列 。 1SELECT * from runoob_tbl ORDER BY submission_date ASC; 拼音排序 字符集采用的是 gbk(汉字编码字符集) ，直接 order by就行 字符集采用的是 utf8(万国码) ， 先对字段进行转码然后排序 ORDER BY CONVERT(runoob_title using gbk); group up 子句 例如： 将数据表按名字进行分组，并统计每个人有多少条记录 1SELECT name, COUNT(*) FROM employee_tbl GROUP BY name; with rollup 可以实现在分组统计数据基础上再进行相同的统计（SUM,AVG,COUNT…） 1SELECT name, SUM(singin) as singin_count FROM employee_tbl GROUP BY name WITH ROLLUP; join 连接 需要从多个数据表中读取数据，JOIN 在两个或多个表中查询数据 INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录 比如：读取runoob_tbl表中所有runoob_author字段在tcount_tbl表对应的runoob_count字段值 语法举例：Select A.Name from A INNER JOIN B ON A.id =B.id 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a INNER JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; 等价于： 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a, tcount_tbl b WHERE a.runoob_author &#x3D; b.runoob_author; **LEFT JOIN（左连接）：**获取左表所有记录，即使右表没有对应匹配的记录 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a LEFT JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录 1SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a RIGHT JOIN tcount_tbl b ON a.runoob_author &#x3D; b.runoob_author; alter 删除表字段 1ALTER TABLE testalter_tbl DROP i; 添加表字段 1ALTER TABLE testalter_tbl ADD i INT; 修改表字段类型及名称： MODIFY 或 CHANGE 子句 ​ 把字段 c 的类型从 CHAR(1) 改为 CHAR(10) 1ALTER TABLE testalter_tbl MODIFY c CHAR(10); ​ 使用 CHANGE 子句, 语法有很大的不同。 在 CHANGE 关键字之后，紧跟着的是你要修改的字段名，然后指定新字段名及类型 1ALTER TABLE testalter_tbl CHANGE i j BIGINT; 修改表名 1ALTER TABLE testalter_tbl RENAME TO alter_tbl; 删除重复数据 如果你想删除数据表中的重复数据，你可以使用以下的SQL语句： 123mysql&gt; CREATE TABLE tmp SELECT last_name, first_name, sex FROM person_tbl GROUP BY (last_name, first_name, sex);mysql&gt; DROP TABLE person_tbl;mysql&gt; ALTER TABLE tmp RENAME TO person_tbl; 也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。方法如下： 12mysql&gt; ALTER IGNORE TABLE person_tbl -&gt; ADD PRIMARY KEY (last_name, first_name);","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ctrl98.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://ctrl98.github.io/tags/MySQL/"}]},{"title":"Git Bash基础操作","slug":"Git1","date":"2020-03-06T00:48:45.000Z","updated":"2020-03-25T06:57:58.675Z","comments":true,"path":"2020/03/06/Git1/","link":"","permalink":"http://ctrl98.github.io/2020/03/06/Git1/","excerpt":"","text":"Git基本操作 安装： 根据系统自己选择下载傻瓜式安装 配置： 用户名： 1$ git config --global user.name &quot;你的账号&quot; 邮箱： 1$ git config --global user.email &quot;你的邮箱账号&quot; 查看全局配置命令： 1$ cat ~&#x2F;.gitconfig 初始化： 新建一个文件夹，再当前目录下打开git bash 执行命令： 1$ git init 查看状态： 在当前目录新建一个README.md文档； 查看当前git仓库状态： 1$ git status 提交新建文档到缓存区命令： 1$ git add README.md 再次查看当前git仓库状态： 截图中也提示，如果想取消本次提交，可执行： 1$ git rm --cached README.md 提交新文件到暂存区： 提交命令： 1$ git add README.md 当前目录下全部文件都提交： 1$ git add -A 提交新内容到git本地仓库： 提交命令： 1$ git commit -m &quot;add README.md&quot; m：message，输入你本次提交的内容或日志 设置要提交到的远程仓库： 先到自己的github创建新的空白远程仓库； 命令： 1$ git remote add origin https:&#x2F;&#x2F;github.com&#x2F;ctrl98&#x2F;git-test.git 查看当前远程仓库的信息： 1$ git remote -v 提交新内容到远程仓库命令： 1$ git push -u origin master 参数说明： -u：第一次提交的时候加上这个属性，以后提交只需要输入：git push即可 -origin：远端链接的名字，创建远程仓库时默认 -master：仓库主干分支 克隆远程仓库项目到本地： 命令： 1$ git clone https:&#x2F;&#x2F;github.com&#x2F;ctrl98&#x2F;git-test.git 更新远程仓库代码到本地： 远程仓库做了修改，本地仓库还是旧的，可执行拉取命令： 1$ git pull Git分支 分支互相独立，互不影响 创建新的分支： 1$ git branch feature1 查看当前分支列表： 1$ git branch 切换分支： 1$ git checkout feature1 查看当前分析目录信息，可发现有master主干上的文件： 在feature1分支下创建a.txt文件，并编辑文件内容：this is a.txt，保存并退出。 commit feature1的文件到本地仓库中。 再创建一个新的分支并切换到该分支： 1$ git checkout -d feature2 查看一下该分支的目录文件信息，发现有master的README.md文档和feature1的a.txt文档，也就是说是基于feature1的，新分支的内容是基于上个分支的内容。 查看文件内容命令： 1$ cat a.txt 分支简单合并 合并命令： 1$ git merge 分支名称 创建并切换到分支feature3: 1$ git checkout -b feature3 新建b.txt文件，并编写内容：hello world： 12touch b.txt;vi b.txt 提交该文件到本地仓库中： 12git add b.txtgit commit -m &quot;add b.txt&quot; 切换回master主分支中： 1$ git checkout master 删除feature3分支： 1$ git branch -d feature3 发现无法删除，因为feature3中本地仓库中有提交，提示你要么合并该分支到master，要么就强制删除分支 合并feature3到master主分支，Head指针执行master： 1$ git merge feature3 提示合并成功 远程仓库创建分支显示 切换到需要再远程仓库中显示的分支： 1$ git checkout feature1 输入设置命令： 1$ git push origin feature1 这个时候远程仓库就会有一个feature1分支显示 也可以起别名： 1$ git push origin feature1:f1 删除远程仓库分支 本地git命令行切换到要删除远程的分支 输入删除命令： 1git push origin :feature1 查看Git日志 命令： 1git log 更简洁地查看： 1git log --oneline 如果提交次数多的话，还可以指定查看最新的提交范围： 1git log --oneline -5 想要查看某一次提交了什么新的内容，可以先复制日志对应的ID，然后执行： 1git show +id 合并操作 清空上面创建的分支，只留下master –ff 方式 创建并切换至f1分支 创建fa.txt文件并提交到本地仓库 查看日志： 1git log --oneline 发现指针HEAD指向了f1 切换回master分支进行合并 (默认使用 --ff 模式) ： 12git checkout mastergit merge f1 此时使用的是 fast-forward 方式合并策略，也就是默认的 --ff 模式，可以通过 git merge --help查看相关模式， 这种方式不会创建一个新的commit，只会显示f1分支提交的message。 –no-ff 方式 保证了原有开发的提交量的完整性 切换回f1分支 创建fb.txt文件并提交到本地仓库： 123touch fb.txtgit add fb.txtgit commit -m &quot;add fb.txt&quot; 切换回master分支进行合并： 12git checkout mastergit merge f1 --no-ff 这个时候会进入一个界面，产生了一条message，叫 Merge branch ‘f1’，我们可以修改这个message，默认不修改，保存退出，这个时候发行合并的策略变为：Merge made by the ‘recursive’ strategy，此时查看log日志会出现拐弯现象，把f1的commit和合并时的message两个commit都显示出来了。 提交到远程仓库，并创建远程仓库分支f1： 12git pushgit push origin f1:f1 打开github的远程仓库，添加master下的a.txt文件内容： 1update 这个时候远程仓库是最新的版本，本地是较旧的版本 回到本地仓库，同步远程master分支的内容到本地： 1git pull 切换到f1分支，f1分支想要拿到master的最新版本，需要merger一下master，才能和master保持同步： 1git merge master 再查看一下日志，发现日志对于本次同步只显示了一条 update a.txt 的信息，并没有出现拐弯 这个时候master有人作了修改，且回到master分支： 12345git checkout mastertouch m1.txtgit add m1.txtgit commit -m &quot;add m1.txt&quot;git log --oneline rebase命令 再回到f1分支，如果我们使用git rebase命令来合并，将f1这个分支移动到master分支的最后一次提交，会把master所有提交并入过来： 12git rebase masterll 再次查看log日志，会发现在f1中会产生一条新的提交，叫&quot;add m1.txt&quot;，重写了项目的提交历史，并且不会带来一条 merge 的commit. rebase最大的好处： 就是使得提交的历史不会出现分叉，项目提交历史看着非常整齐，他不会像 git merge 那样引入一条分叉 rebase的缺点：安全性和可跟踪性，不要在master上使用rebase命令，rebase命令他不是合并操作，而是复制操作，而merge命令是把两个分支的内容合并到一起。 简单处理合并冲突 在f1分支基础上再创建一个f2分支，并随便修改一下a.txt的内容，保存退出提交到本地仓库： 12git checkout -b f2vi a.txt 回到f1分支，同样修改a.txt文件内容并提交到本地仓库： 12git chrckout f1vi a.txt 再次回到f2分支，这个时候想拉取一下f1同学写的代码： 12git checkout f2git merge f1 这个时候会出现文件冲突，需要解决冲突，查看一下a.txt文件： 1cat a.txt 发现文件内容很乱，显示两个分支上对这个文件的不同修改的内容，要么使用f1的要么使用f2的，然后修改a.txt，就会看到刚才查看到的内容： 1vi a.txt 这样修改很麻烦，实际开发中会用工具下来修改 使用mergetool命令来检测冲突并解决冲突： 1git mergetool 再次回车使用vimdiff来解决冲突，把不需要保留的内容删除，然后保存退出，再看一下a.txt文件： 1cat a.txt 发现内容已经修改为刚才保留下来的内容，然后再commit一下： 1git commit -m &quot;update a.txt&quot; Git的回滚撤销 git reset 分支名^ 回到上一次提交的版本，他只是把HEAD指针移动了，并没有删除东西，默认是–mixed模式（本次提交的东西从暂存区撤销，但仍留在工作区中），在master分支下： 123touch hello.javagit add hello.javagit commit -m &quot;add hello.java&quot; 此时查看log，会发现已经有本条提交记录，这个时候想回退上个版本： 1git reset master^ # ^符号代表上一次的意思 查看状态： 1git status 发现hello.java文件处于未提交状态 同样也可以直接： 1git reset 版本码(查看每条日志前的唯一标识) hard模式简单粗暴，直接还原上个版本的东西，暂存区、工作目录都清空本次更新的内容： 1git reset --hard 版本号 git revert 此次操作之前和之后的commit和history都会保留，并且把这次撤销作为一次最新的提交，用新的commit来回滚上一个版本； 1git revert 版本号 执行后会产生一次commit，填写提交的message，直接保存退出，他就把删除了revert那个版本的东西，比如那次提交是新建了一个文件，执行revert后，那个文件就不存在，但是那次提交commit的message就更新为 revert … 所以，在公共分支上使用 git revert，会把提交的信息记录保存下来，可以回溯，在其他分支，可以直接 git reset回退 Git 工作基本流程 最后附上Git命令大全","categories":[{"name":"Git","slug":"Git","permalink":"http://ctrl98.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://ctrl98.github.io/tags/Git/"},{"name":"版本控制工具","slug":"版本控制工具","permalink":"http://ctrl98.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"使用Dockerfile创建镜像","slug":"Docker6","date":"2020-02-27T05:43:51.000Z","updated":"2020-02-27T06:38:09.608Z","comments":true,"path":"2020/02/27/Docker6/","link":"","permalink":"http://ctrl98.github.io/2020/02/27/Docker6/","excerpt":"","text":"什么是Dockerfile文件 Dockerfile文件其实就是一个文本文件，由一系列命令和参数构成，Docker可以读取Dockerfile文件并根据Dockerfile文件的描述构建镜像。 Dockerfile文件内容一般为4个部分 基础镜像信息 维护者信息 镜像操作命令 容器启动时执行的命令 Dockerfile常用命令 命令 作用 FROM image_name:tag 定义了使用哪个基础镜像启动构建流程 MAINTAINER user_name 声明镜像的创建者 EVN key value 声明环境变量(可以多条) RUN command 是Dockerfile核心部分(可以写多条) ADD source_dir/file dest_dir/file 将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压 COPY source_dir/file dest_dir/file 和上一条一样，不同的是不自动解压 WORKDIR path_dir 设置工作目录 目标 使用Dockerfile构建一个包含jdk11环境的centos7镜像。 分析： ​ 假设以centos7作为基础镜像，添加jdk11并构建一个包含jdk1.8的centos7新镜像，使用Dockerfile可以实现。 步骤： 拉取centos7镜像 上传jdk11压缩包 编写Dockerfile文件 构建镜像 测试（基于新镜像创建并启动容器，测试jdk版本） 拉取centos7镜像 这个不作过多解释，直接使用 docker pull centos:7命令拉取。 上传jdk文件到宿主机 创建目录： 1mkdir &#x2F;usr&#x2F;local&#x2F;dockerjdk11 使用 WinSCP 软件来上传本地电脑文件到虚拟机centos系统dockerjdk11目录下，也不作过多解释，下载软件后直接输入虚拟机的IP地址，用户名和密码即可登录，端口默认是 22； 编写Dockerfile文件 在/usr/local/dockerjdk11目录下使用vi命令进行编写： 1vi Dockerfile 内容为： 123456789FROM centos:7MAINTAINER 23h59m59sWORKDIR &#x2F;usrRUN mkdir &#x2F;usr&#x2F;local&#x2F;javaADD jdk-11.0.5_linux-x64_bin.tar.gz &#x2F;usr&#x2F;local&#x2F;java&#x2F;ENV JAVA_HOME &#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk-11.0.5ENV JRE_HOME $JAVA_HOME&#x2F;jreENV CLASSPATH $JAVA_HOME&#x2F;lib&#x2F;dt.jar:JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;lib:$CLASSPATHENV PATH $JAVA_HOME&#x2F;bin:$PATH 按Esc键，然后英文状态下输入 : 键，然后紧接着输入 wq 保存并退出。 构建镜像 输入构建镜像命令： 1docker build -t&#x3D;&#39;jdk11&#39; . -t：要构建的镜像的名称 .：这个点不能省略，表示当前目录下 等到successfully 查看当前镜像列表是否构建成功： 1docker images 测试（基于新镜像创建并启动容器，测试jdk版本） 基于构建的新镜像jdk11创建并启动容器： 1docker run -it --name&#x3D;newtestjdk11 jdk11 &#x2F;bin&#x2F;bash 创建成功后自动进入该容器，测试jdk版本： 1java -version 发现显示jdk的版本为11.0.5","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker容器的备份、迁移与恢复","slug":"Docker5","date":"2020-02-27T04:13:17.000Z","updated":"2020-02-27T05:08:04.763Z","comments":true,"path":"2020/02/27/Docker5/","link":"","permalink":"http://ctrl98.github.io/2020/02/27/Docker5/","excerpt":"","text":"容器的备份、迁移与恢复 其中涉及到的命令： docker commit：将容器保存为镜像 docker save：将镜像备份为tar文件 docker load：根据tar文件恢复为镜像 容器备份 目标：能够将服务器A的某个容器保存为镜像，备份成tar文件，迁移到服务器B恢复镜像再启动以恢复的镜像作为基础的容器来运行。 需求：在当前的容器中安装了各种组件，期望在其他服务器上也能快速拥有该容器的一切环境。 可以将当前的容器制作为一个镜像，再将该镜像复制到其他服务器，其他服务器再基于镜像运行容器。 镜像制作 将容器保存为一个镜像，通过 commit命令： 1docker commit myredis myredis 第一个mytomcat：容器名称 第二个mytomcat：创建的镜像名称 查看镜像列表是否制作成功： 1docker images 成功制作 备份镜像 通过save命令，在当前目录下保存tar文件： 1docker save -o myredis.tar(生成的文件名) myredis(要备份的镜像名) 通过ll命令查看当前路径下的文件，发现已有myredis.tar文件： 迁移镜像 由于环境限制，只能通过 docker rm命令 把本机的myredis容器删除，从而 使用 docker rmi命令 把上面制作的myredis镜像删除，模拟另一台服务器，实际环境可以把tar文件复制到另一台服务器。 恢复镜像 在当前目录下拿到了tar文件 通过 docker load命令恢复镜像： 1docker load -i myredis.tar(镜像备份的名称) 恢复之后可以查看一下镜像列表： 基于镜像运行容器 创建基于刚才恢复的myredis镜像的容器： 1docker run -di --name&#x3D;myredis -p 6379:6379 myredis 执行之后查看容器列表： 迁移成功。","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker部署Tomcat容器","slug":"Docker4","date":"2020-02-26T11:58:21.000Z","updated":"2020-02-26T12:23:52.774Z","comments":true,"path":"2020/02/26/Docker4/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker4/","excerpt":"","text":"分析 创建容器的时候对容器中的webapps目录（存放web项目的目录）进行目录挂载，发布web项目只需要把项目上传到宿主机的挂载目录即可，tomcat会自动解压包。 拉取Tomcat镜像 拉取镜像的时候不指定版本号，默认下载tomcat最新版的，这里默认就行。 拉取Tomcat镜像： 1docker pull tomcat 等待Pull complete： 查看镜像列表： 1docker images 拉取成功 创建并启动Tomcat容器 执行一下命令进行创建： 1docker run -di --name&#x3D;mytomcat -p 9000:8080 -v &#x2F;usr&#x2F;local&#x2F;mytomcat&#x2F;webapps:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps tomcat 属性解释： -di：创建守护式容器 –name：容器名字 -p：端口映射 -v：目录挂载（映射） 注意 创建容器的时候如出现ipv4的警告信息： 修改配置文件： 1vi &#x2F;etc&#x2F;sysctl.conf 在这文件上添加： 1net.ipv4.ip_forward&#x3D;1 重启网络： 1systemctl restart network 查看一下容器列表： 1docker ps 创建成功","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"},{"name":"Tomcat","slug":"容器引擎/Tomcat","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/Tomcat/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker部署mysql Navicat远程连接","slug":"Docker3","date":"2020-02-26T10:53:17.000Z","updated":"2020-02-26T12:01:13.768Z","comments":true,"path":"2020/02/26/Docker3/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker3/","excerpt":"","text":"拉取Mysql5.7镜像 这里拉取的Mysql版本是5.7版本 这里不再作搜索，直接拉取： 1docker pull centos&#x2F;mysql-57-centos7 查看镜像列表： 1docker images -----------------------------------------拉取成功------------------------------------------- 创建并启动Mysql守护式容器 1docker run -di --name&#x3D;mysql5.7 -p 4100:3306 -e MYSQL_ROOT_PASSWORD&#x3D;root centos&#x2F;mysql-57-centos7 -di：守护式容器 –name：容器名称 -p：端口映射，前面的是宿主机，后面是容器的端口 -e：设置密码 centos/mysql-57-centos7：基于哪个镜像创建 镜像创建成功，进入该容器，输入用户名，密码不用输直接回车（我也不是很清楚为什么）： 1docker exec -it mysql5.7 &#x2F;bin&#x2F;bash 想要让外部工具连接Mysql容器，需要给用户权限： 1grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; ; 等待Query OK后，再刷新权限： 1flush privileges; 使用Navicat12工具测试连接 打开软件，点击左上角的连接，选择Mysql -连接名：随意 -主机：宿主机的IP地址 -密码：你创建容器时设置的密码 输入之后点击测试连接： 提示连接成功","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"},{"name":"MySQL","slug":"容器引擎/MySQL","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/MySQL/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker基础知识之镜像与容器","slug":"Docker2","date":"2020-02-26T02:26:40.000Z","updated":"2020-02-27T04:10:33.214Z","comments":true,"path":"2020/02/26/Docker2/","link":"","permalink":"http://ctrl98.github.io/2020/02/26/Docker2/","excerpt":"","text":"废话不多说，前提条件是你的电脑已安装Docker和完成了基本的配置，还没有的话开车送你去Docker基础知识 Docker镜像 容器的运行是建立在镜像基础之上，当然前提是docker服务已启动。 先用 查看镜像 的命令查看一下本机有什么镜像，不出意外应该啥也没有： 1docker images 镜像没有没关系，从共有仓库 拉取镜像 下来就行了，先来搜索你需要拉取的镜像，比如我们想搜索一个centos7的镜像： 1docker search +你要搜索的镜像名称(如：centos7) 搜索出来的结果： 搜索到之后就拉取我们需要的镜像，比如我们拉取一个centos7镜像： 1docker pull centos:7(镜像的名字:版本号)&#x2F;(若不指定版本号，默认拉取最新版本) 过了一小会之后就会提示 Pull complete，说明拉取成功。 这时候我们再回头使用查看镜像的命令就会看到centos7的镜像了： 镜像可以拉取当然也可以删除： 1docker rmi centos(要删除的镜像名或者镜像id) 或者哪天不开心想把全部镜像删了： 1docker rmi &#96;docker images -q&#96; Docker容器 首先我们要知道docker容器分为两种，一种是 交互式容器，一种是 守护式容器，实际开发中一般采用守护式容器。 两者本质区别 交互式容器随容器的创建、启动而启动，随容器的退出而关闭。 守护式容器随容器的创建、启动而启动，但退出容器后，容器依然在后台运行。 上面我们已经拉取了centos7镜像，下面我们先了解一下创建容器的相关命令属性： 属性 说明 -i 表示运行 -t 表示容器启动后会进入其命令行，加入这两个参数后，容器创建就能登录进去，即分配一个伪终端 –name 为创建容器的名字 -v 表示目录挂载、映射关系 -d 在run后面加上-d参数，则会创建一个守护式容器在后台运行 -p 表示端口映射 -e 表示添加环境变量 查看容器命令（只能查出正在运行的容器）： 1docker ps 查看全部容器命令： 1docker ps -a 查看容器的IP地址： 1docker inspect 容器名字或id 创建一个交互式容器： 1docker run -it --name&#x3D;mycentos7 centos:7 &#x2F;bin&#x2F;bash 执行后会自动进入我们所创建好的容器—mycentos7，使用 ll 命令，然后退出就会回到本机： 创建一个守护式容器： 1docker run -di --name&#x3D;mycentos2 centos:7 创建成功后查看一下容器列表，发现已经在后台运行了： 下面进入该容器看看（exec表示进入的意思）： 1docker exec -it mycentos2 &#x2F;bin&#x2F;bash 可以看出来和交互式容器没什么区别，当我们执行 exit 命令退出该容器后，再查看一下容器列表，发现该容器依旧在后台运行，刚才创建的交互式容器可以通过 docker ps -a命令查看。 停止守护式容器运行： 1docker stop 容器名称或者id 启动容器： 1docker start 容器名称或者id 目录挂载 将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器 创建映射目录 1mkdir &#x2F;usr&#x2F;local&#x2F;test 创建并启动一个守护式容器并挂载test目录： 1docker run -di -v &#x2F;usr&#x2F;local&#x2F;test:&#x2F;usr&#x2F;local&#x2F;test --name&#x3D;mycentos3 centos:7 查看容器列表： 我们在宿主机的test目录下新建一个文件： 1touch test.txt 然后进入 mycentos3容器： 1docker exec -it mycentos3 &#x2F;bin&#x2F;bash 进入test目录下查看文件信息： 1cd &#x2F;usr&#x2F;local&#x2F;test 发现在宿主机创建的test.txt文件也同样被创建在容器中挂载的目录下。 删除容器 1docker rm 容器名称 (注意，正在运行中的容器是无法删除的)","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]},{"title":"Docker基础知识","slug":"Docker1","date":"2020-02-25T07:46:30.000Z","updated":"2020-02-26T09:33:27.998Z","comments":true,"path":"2020/02/25/Docker1/","link":"","permalink":"http://ctrl98.github.io/2020/02/25/Docker1/","excerpt":"","text":"Docker 什么是Docker 百度百科：Docker容器是一个应用容器引擎， 让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 linux 或 Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 说白了就是把应用（项目）部署到Docker容器中运行，就好像放在真实的物理机上运行一样，不用担心开发环境和生产环境的不一致。 为什么要使用Docker Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多 。 性能很高 ， 系统的开销尽量小 。 环境一致，让开发人员专注于开发。 应用迁移更便捷。 应用更好维护。 应用场景 web应用的自动打包和发布 自动化测试 可持续集成 安装各种组件 Docker的组成部分 Docker客户端：个人电脑安装的docker软件、用来连接操作docker。 Docker守护进程：例如有容器A、镜像1 （容器时基于镜像来运行的,镜像相当于类，容器则是类的实例）。 Docker镜像：从docker仓库中拉去过来，而docker仓库又分共有(docker hub)和私有仓库。 以下以 centOS7 系统为基础环境讲述 卸载旧的版本 如果你的系统中已经有旧版本，那么就卸载他吧， 较旧的 Docker 版本称为 docker 或 docker-engine，卸载后记得要删除相关依赖项。 更新 yum 源： 1sudo yum update 查看已安装软件是否有Docker： 1yum list installed 或者直接查看有没有安装Docker： 1yum list installed | grep docker 如果有的话卸载及相关依赖： 1yum -y remove docker.x86_64#软件名看你自己的 安装Docker社区版(个人和中小型企业基本够用) 安装先安装需要的软件包： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源： 1sudo yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo 如果返回结果如下图表明设置成功： 安装docker： 1sudo yum install -y docker-ce 如果返回结果如下图表明安装成功： 查看docker安装版本： 1docker -v 配置Docker镜像源 创建文件夹： 1mkdir &#x2F;etc&#x2F;docker 使用一下命令编辑内容并创建文件—daemon.json 1cd &#x2F;etc&#x2F;docker 1vi daemon.json 文件内容为： 1&#123;&quot;registry-mirrors&quot;:[&quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;]&#125; 镜像也可以用自己的阿里云镜像加速(建议) 编辑完后，按 Esc键，然后按 :，输入 wq，保存文件并退出。 在/etc/docker目录下使用 ll命令查看文件是否创建成功？ Docker基础命令 下面我们来了解一下docker的基础命令 首先是启动docker服务： 1systemctl start docker 停止docker服务： 1systemctl stop docker 查看docker当前状态： 1systemctl status docker 重启docker服务： 1systemctl restart docker 把docker服务设置成开机自动启动： 1systemctl enable docker 到这里说明你已经距离入门还有一大段距离~~~干巴爹斯！！！！","categories":[{"name":"容器引擎","slug":"容器引擎","permalink":"http://ctrl98.github.io/categories/%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ctrl98.github.io/tags/Docker/"}]}]}